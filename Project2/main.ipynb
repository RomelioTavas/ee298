{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras.layers import (Conv1D, Dense, Dropout, Input, Concatenate,\n",
    "                          LeakyReLU, Flatten, Activation, BatchNormalization, UpSampling1D)\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras.models import Model\n",
    "from custom.dataloader import DataLoader\n",
    "\n",
    "np.random.seed(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2, n_classes=41,\n",
    "                 n_folds=10, learning_rate=0.0001,\n",
    "                 max_epochs=50):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        self.dim = (self.audio_length, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "\n",
    "    def __init__(self, config, data_loader):\n",
    "\n",
    "        self.config = config\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = 32\n",
    "        self.df = 64\n",
    "\n",
    "        self.train_steps = 40000\n",
    "        self.latent_size = self.config.audio_length\n",
    "        self.model_name = 'cyclegan_audio'\n",
    "        self.batch_size = 8\n",
    "\n",
    "        # Loss weights\n",
    "        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n",
    "        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n",
    "\n",
    "        # checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        # early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "        # tb = TensorBoard(log_dir='./logs/', write_graph=True)\n",
    "\n",
    "        # callbacks_list = [checkpoint, early, tb]\n",
    "        # callbacks_list = [tb]\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminators\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss='mse',\n",
    "                         optimizer=optimizer,\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "        print(\"d_A: \")\n",
    "        self.d_A.summary()\n",
    "\n",
    "        self.d_B.compile(loss='mse',\n",
    "                         optimizer=optimizer,\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "        print(\"d_B: \")\n",
    "        self.d_B.summary()\n",
    "\n",
    "        # -------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        # -------------------------\n",
    "\n",
    "        # Build the generators\n",
    "        self.g_AB = self.build_generator()\n",
    "        print(\"g_AB: \")\n",
    "        self.g_AB.summary()\n",
    "        \n",
    "        self.g_BA = self.build_generator()\n",
    "        print(\"g_BA: \")\n",
    "        self.g_BA.summary()\n",
    "\n",
    "        print(\"Constructing Adversarial network\")\n",
    "        # Input audio from both domains\n",
    "        audio_A = Input(shape=(self.config.audio_length, 1))\n",
    "        audio_B = Input(shape=(self.config.audio_length, 1))\n",
    "\n",
    "        # Translate audios to the other domain\n",
    "        fake_B = self.g_AB(audio_A)\n",
    "        fake_A = self.g_BA(audio_B)\n",
    "        # Translate audios back to original domain\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # Identity mapping of audios\n",
    "        audio_A_id = self.g_BA(audio_A)\n",
    "        audio_B_id = self.g_AB(audio_B)\n",
    "\n",
    "        # For the combined model we will only train the generators\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated audios\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # Combined model trains generators to fool discriminators\n",
    "        self.combined = Model(inputs=[audio_A, audio_B],\n",
    "                              outputs=[valid_A, valid_B,\n",
    "                                       reconstr_A, reconstr_B,\n",
    "                                       audio_A_id, audio_B_id])\n",
    "        print(\"Compiling Adversarial Network\")\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                              loss_weights=[1, 1,\n",
    "                                            self.lambda_cycle, self.lambda_cycle,\n",
    "                                            self.lambda_id, self.lambda_id],\n",
    "                              optimizer=optimizer)\n",
    "        print(\"CycleGAN: \")\n",
    "        self.combined.summary()\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
    "            \"\"\"Discriminator layer\"\"\"\n",
    "            d = Conv1D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            if normalization:\n",
    "                d = InstanceNormalization()(d)\n",
    "            return d\n",
    "\n",
    "        audio = Input(shape=(self.config.audio_length, 1))\n",
    "\n",
    "        d1 = d_layer(audio, self.df, normalization=False)\n",
    "        d2 = d_layer(d1, self.df*2)\n",
    "        d3 = d_layer(d2, self.df*4)\n",
    "        d4 = d_layer(d3, self.df*8)\n",
    "\n",
    "        x = Flatten()(d4)\n",
    "        x = Dense(1)(x)\n",
    "        out = Activation('sigmoid')(x)\n",
    "\n",
    "        return Model(audio, out)\n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "        def conv1d(layer_input, filters, f_size=4):\n",
    "            \"\"\"Layers used during downsampling\"\"\"\n",
    "            d = Conv1D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            d = InstanceNormalization()(d)\n",
    "            return d\n",
    "\n",
    "        def deconv1d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            \"\"\"Layers used during upsampling\"\"\"\n",
    "            u = UpSampling1D(size=2)(layer_input)\n",
    "            u = Conv1D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            u = InstanceNormalization()(u)\n",
    "            u = Concatenate()([u, skip_input])\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=(self.config.audio_length, 1))\n",
    "\n",
    "        # Downsampling\n",
    "        d1 = conv1d(d0, self.gf)\n",
    "        d2 = conv1d(d1, self.gf*2)\n",
    "        d3 = conv1d(d2, self.gf*4)\n",
    "        d4 = conv1d(d3, self.gf*8)\n",
    "\n",
    "        # Upsampling\n",
    "        u1 = deconv1d(d4, d3, self.gf*4)\n",
    "        u2 = deconv1d(u1, d2, self.gf*2)\n",
    "        u3 = deconv1d(u2, d1, self.gf)\n",
    "\n",
    "        u4 = UpSampling1D(size=2)(u3)\n",
    "        output_audio = Conv1D(1, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "        return Model(d0, output_audio)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "    valid = np.ones((batch_size,))\n",
    "    fake = np.zeros((batch_size,))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_i, (audios_A, audios_B) in enumerate(data_loader.load_batch(batch_size)):\n",
    "\n",
    "            # ----------------------\n",
    "            #  Train Discriminators\n",
    "            # ----------------------\n",
    "            # Translate images to opposite domain\n",
    "            fake_B = model.g_AB.predict(audios_A)\n",
    "            fake_A = model.g_BA.predict(audios_B)\n",
    "\n",
    "            # Train the discriminators (original audio = real / translated = Fake)\n",
    "            print(\"audios_A shape:\", audios_A.shape)\n",
    "            print(\"valid shape\", valid.shape)\n",
    "            dA_loss_real = model.d_A.train_on_batch(audios_A, valid)\n",
    "            dA_loss_fake = model.d_A.train_on_batch(fake_A, fake)\n",
    "            dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "            dB_loss_real = model.d_B.train_on_batch(audios_B, valid)\n",
    "            dB_loss_fake = model.d_B.train_on_batch(fake_B, fake)\n",
    "            dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "            # Total disciminator loss\n",
    "            d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "            # ------------------\n",
    "            #  Train Generators\n",
    "            # ------------------\n",
    "\n",
    "            # Train the generators\n",
    "            g_loss = model.combined.train_on_batch([audios_A, audios_B],\n",
    "                                                  [valid, valid,\n",
    "                                                   audios_A, audios_B,\n",
    "                                                   audios_A, audios_B])\n",
    "\n",
    "            elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "            # Plot the progress\n",
    "            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \"\n",
    "                  % (epoch, epochs,\n",
    "                      batch_i, data_loader.n_batches,\n",
    "                      d_loss[0], 100*d_loss[1],\n",
    "                      g_loss[0],\n",
    "                      np.mean(g_loss[1:3]),\n",
    "                      np.mean(g_loss[3:5]),\n",
    "                      np.mean(g_loss[5:6]),\n",
    "                      elapsed_time))\n",
    "\n",
    "            # If at save interval => save generated audio samples\n",
    "            # if batch_i % sample_interval == 0:\n",
    "            #     self.sample_audio(epoch, batch_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_A: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8000, 128)         32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8000, 128)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 8000, 128)         2         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4000, 256)         131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4000, 256)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 4000, 256)         2         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2000, 512)         524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 2000, 512)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 2000, 512)         2         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1024001   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,713,351\n",
      "Trainable params: 1,713,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "d_B: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 8000, 128)         32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8000, 128)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_4 (In (None, 8000, 128)         2         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 4000, 256)         131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4000, 256)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_5 (In (None, 4000, 256)         2         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 2000, 512)         524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2000, 512)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_6 (In (None, 2000, 512)         2         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1024001   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,713,351\n",
      "Trainable params: 1,713,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "g_AB: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 16000, 32)    160         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 16000, 32)    0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_7 (Insta (None, 16000, 32)    2           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 8000, 64)     8256        instance_normalization_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 8000, 64)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_8 (Insta (None, 8000, 64)     2           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 4000, 128)    32896       instance_normalization_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 4000, 128)    0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_9 (Insta (None, 4000, 128)    2           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 2000, 256)    131328      instance_normalization_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 2000, 256)    0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_10 (Inst (None, 2000, 256)    2           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 4000, 256)    0           instance_normalization_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 4000, 128)    131200      up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_11 (Inst (None, 4000, 128)    2           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4000, 256)    0           instance_normalization_11[0][0]  \n",
      "                                                                 instance_normalization_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 8000, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 8000, 64)     65600       up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_12 (Inst (None, 8000, 64)     2           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8000, 128)    0           instance_normalization_12[0][0]  \n",
      "                                                                 instance_normalization_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1D)  (None, 16000, 128)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 16000, 32)    16416       up_sampling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_13 (Inst (None, 16000, 32)    2           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16000, 64)    0           instance_normalization_13[0][0]  \n",
      "                                                                 instance_normalization_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1D)  (None, 32000, 64)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 32000, 1)     257         up_sampling1d_4[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 386,127\n",
      "Trainable params: 386,127\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_BA: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 32000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 16000, 32)    160         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 16000, 32)    0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_14 (Inst (None, 16000, 32)    2           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 8000, 64)     8256        instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 8000, 64)     0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_15 (Inst (None, 8000, 64)     2           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 4000, 128)    32896       instance_normalization_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 4000, 128)    0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_16 (Inst (None, 4000, 128)    2           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 2000, 256)    131328      instance_normalization_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 2000, 256)    0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_17 (Inst (None, 2000, 256)    2           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1D)  (None, 4000, 256)    0           instance_normalization_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 4000, 128)    131200      up_sampling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_18 (Inst (None, 4000, 128)    2           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4000, 256)    0           instance_normalization_18[0][0]  \n",
      "                                                                 instance_normalization_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1D)  (None, 8000, 256)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 8000, 64)     65600       up_sampling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_19 (Inst (None, 8000, 64)     2           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8000, 128)    0           instance_normalization_19[0][0]  \n",
      "                                                                 instance_normalization_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_7 (UpSampling1D)  (None, 16000, 128)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 16000, 32)    16416       up_sampling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "instance_normalization_20 (Inst (None, 16000, 32)    2           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16000, 64)    0           instance_normalization_20[0][0]  \n",
      "                                                                 instance_normalization_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_8 (UpSampling1D)  (None, 32000, 64)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 32000, 1)     257         up_sampling1d_8[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 386,127\n",
      "Trainable params: 386,127\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Constructing Adversarial network\n",
      "Compiling Adversarial Network\n",
      "CycleGAN: \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 32000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 32000, 1)     386127      input_6[0][0]                    \n",
      "                                                                 model_3[1][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 32000, 1)     386127      input_5[0][0]                    \n",
      "                                                                 model_4[1][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            1713351     model_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 1)            1713351     model_3[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,198,956\n",
      "Trainable params: 772,254\n",
      "Non-trainable params: 3,426,702\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "config = Config(sampling_rate=16000, audio_duration=2, n_folds=10, learning_rate=0.001)\n",
    "data_loader = DataLoader(config)\n",
    "    \n",
    "cycleGAN = CycleGAN(config, data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audios_A shape: (8, 32000, 1)\n",
      "valid shape (8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bong/.virtualenvs/tf/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "train(cycleGAN, data_loader, 32, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
