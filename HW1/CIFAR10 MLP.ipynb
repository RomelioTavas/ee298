{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR 10 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Batch Norm and LR Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3502
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1521835,
     "status": "ok",
     "timestamp": 1551623297016,
     "user": {
      "displayName": "Romelio Tavas Jr.",
      "photoUrl": "https://lh5.googleusercontent.com/-nndHCVmsqPk/AAAAAAAAAAI/AAAAAAAAAUU/qrN4dDRSnrE/s64/photo.jpg",
      "userId": "11762601391443792117"
     },
     "user_tz": -480
    },
    "id": "rvomnvC4sJdi",
    "outputId": "1074630c-49c1-427e-9faf-f34f18275415"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 3072)\n",
      "x_test shape: (10000, 3072)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 1.8127 - acc: 0.3595 - val_loss: 1.6257 - val_acc: 0.4151\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.5770 - acc: 0.4419 - val_loss: 1.6275 - val_acc: 0.4148\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 18s 360us/step - loss: 1.4714 - acc: 0.4778 - val_loss: 1.5686 - val_acc: 0.4407\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.4121 - acc: 0.4989 - val_loss: 1.4754 - val_acc: 0.4832\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 1.3649 - acc: 0.5171 - val_loss: 1.5483 - val_acc: 0.4594\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.3323 - acc: 0.5318 - val_loss: 1.6794 - val_acc: 0.4162\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 1.2897 - acc: 0.5488 - val_loss: 1.3770 - val_acc: 0.5145\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 18s 362us/step - loss: 1.2633 - acc: 0.5563 - val_loss: 1.3678 - val_acc: 0.5232\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.2368 - acc: 0.5655 - val_loss: 1.4372 - val_acc: 0.4985\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 1.2139 - acc: 0.5737 - val_loss: 1.3131 - val_acc: 0.5391\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.1902 - acc: 0.5820 - val_loss: 1.3959 - val_acc: 0.5181\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 1.1703 - acc: 0.5897 - val_loss: 1.4107 - val_acc: 0.5061\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 1.1520 - acc: 0.5976 - val_loss: 1.3619 - val_acc: 0.5379\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.1280 - acc: 0.6051 - val_loss: 1.4794 - val_acc: 0.5065\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.1090 - acc: 0.6134 - val_loss: 1.3992 - val_acc: 0.5246\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 1.0147 - acc: 0.6429 - val_loss: 1.2196 - val_acc: 0.5751\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.9831 - acc: 0.6545 - val_loss: 1.2257 - val_acc: 0.5729\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.9650 - acc: 0.6614 - val_loss: 1.2229 - val_acc: 0.5817\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.9535 - acc: 0.6666 - val_loss: 1.2243 - val_acc: 0.5775\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.9457 - acc: 0.6690 - val_loss: 1.2100 - val_acc: 0.5825\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 18s 365us/step - loss: 0.9241 - acc: 0.6759 - val_loss: 1.2182 - val_acc: 0.5808\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.9171 - acc: 0.6765 - val_loss: 1.2416 - val_acc: 0.5832\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.9080 - acc: 0.6799 - val_loss: 1.3244 - val_acc: 0.5636\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.8977 - acc: 0.6864 - val_loss: 1.2685 - val_acc: 0.5796\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.8913 - acc: 0.6874 - val_loss: 1.2580 - val_acc: 0.5774\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.8484 - acc: 0.7000 - val_loss: 1.2111 - val_acc: 0.5941\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.8431 - acc: 0.7037 - val_loss: 1.2008 - val_acc: 0.5940\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.8334 - acc: 0.7031 - val_loss: 1.2120 - val_acc: 0.5936\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.8313 - acc: 0.7067 - val_loss: 1.2419 - val_acc: 0.5893\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.8243 - acc: 0.7112 - val_loss: 1.2130 - val_acc: 0.5889\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.8196 - acc: 0.7115 - val_loss: 1.2249 - val_acc: 0.5906\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.8167 - acc: 0.7144 - val_loss: 1.2263 - val_acc: 0.5920\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.7985 - acc: 0.7177 - val_loss: 1.2151 - val_acc: 0.5929\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.7974 - acc: 0.7179 - val_loss: 1.2102 - val_acc: 0.5954\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.7960 - acc: 0.7187 - val_loss: 1.2142 - val_acc: 0.5957\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.7873 - acc: 0.7225 - val_loss: 1.2101 - val_acc: 0.5951\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7932 - acc: 0.7202 - val_loss: 1.2195 - val_acc: 0.5955\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7867 - acc: 0.7220 - val_loss: 1.2165 - val_acc: 0.5972\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.7938 - acc: 0.7211 - val_loss: 1.2119 - val_acc: 0.5975\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.7906 - acc: 0.7201 - val_loss: 1.2121 - val_acc: 0.5966\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7906 - acc: 0.7213 - val_loss: 1.2167 - val_acc: 0.5958\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.7886 - acc: 0.7210 - val_loss: 1.2188 - val_acc: 0.5954\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7872 - acc: 0.7221 - val_loss: 1.2144 - val_acc: 0.5967\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7853 - acc: 0.7235 - val_loss: 1.2179 - val_acc: 0.5958\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7838 - acc: 0.7239 - val_loss: 1.2151 - val_acc: 0.5969\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7869 - acc: 0.7229 - val_loss: 1.2137 - val_acc: 0.5987\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.7791 - acc: 0.7242 - val_loss: 1.2112 - val_acc: 0.5970\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7870 - acc: 0.7255 - val_loss: 1.2118 - val_acc: 0.5973\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7828 - acc: 0.7243 - val_loss: 1.2151 - val_acc: 0.5963\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7843 - acc: 0.7257 - val_loss: 1.2134 - val_acc: 0.5949\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7852 - acc: 0.7206 - val_loss: 1.2168 - val_acc: 0.5965\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7788 - acc: 0.7239 - val_loss: 1.2180 - val_acc: 0.5982\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 17s 347us/step - loss: 0.7885 - acc: 0.7218 - val_loss: 1.2133 - val_acc: 0.5968\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 0.7795 - acc: 0.7257 - val_loss: 1.2129 - val_acc: 0.5968\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7828 - acc: 0.7250 - val_loss: 1.2135 - val_acc: 0.5965\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7826 - acc: 0.7233 - val_loss: 1.2116 - val_acc: 0.5972\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7835 - acc: 0.7233 - val_loss: 1.2131 - val_acc: 0.5979\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7820 - acc: 0.7246 - val_loss: 1.2187 - val_acc: 0.5983\n",
      "Epoch 59/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7790 - acc: 0.7243 - val_loss: 1.2169 - val_acc: 0.5978\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7842 - acc: 0.7227 - val_loss: 1.2143 - val_acc: 0.5964\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7883 - acc: 0.7216 - val_loss: 1.2144 - val_acc: 0.5968\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7803 - acc: 0.7254 - val_loss: 1.2161 - val_acc: 0.5960\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7894 - acc: 0.7201 - val_loss: 1.2172 - val_acc: 0.5968\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7872 - acc: 0.7227 - val_loss: 1.2172 - val_acc: 0.5970\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7840 - acc: 0.7248 - val_loss: 1.2170 - val_acc: 0.5957\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7870 - acc: 0.7237 - val_loss: 1.2155 - val_acc: 0.5978\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7801 - acc: 0.7236 - val_loss: 1.2140 - val_acc: 0.5981\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7846 - acc: 0.7218 - val_loss: 1.2141 - val_acc: 0.5974\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7833 - acc: 0.7223 - val_loss: 1.2146 - val_acc: 0.5979\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7817 - acc: 0.7236 - val_loss: 1.2157 - val_acc: 0.5961\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7842 - acc: 0.7227 - val_loss: 1.2179 - val_acc: 0.5971\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7775 - acc: 0.7253 - val_loss: 1.2156 - val_acc: 0.5979\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7820 - acc: 0.7233 - val_loss: 1.2163 - val_acc: 0.5988\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7871 - acc: 0.7224 - val_loss: 1.2183 - val_acc: 0.5962\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7784 - acc: 0.7240 - val_loss: 1.2154 - val_acc: 0.5972\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7782 - acc: 0.7232 - val_loss: 1.2151 - val_acc: 0.5980\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7810 - acc: 0.7237 - val_loss: 1.2158 - val_acc: 0.5965\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7853 - acc: 0.7228 - val_loss: 1.2162 - val_acc: 0.5978\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7838 - acc: 0.7211 - val_loss: 1.2134 - val_acc: 0.5966\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7837 - acc: 0.7228 - val_loss: 1.2159 - val_acc: 0.5965\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7829 - acc: 0.7253 - val_loss: 1.2152 - val_acc: 0.5960\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7809 - acc: 0.7230 - val_loss: 1.2148 - val_acc: 0.5954\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7789 - acc: 0.7263 - val_loss: 1.2193 - val_acc: 0.5974\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7793 - acc: 0.7242 - val_loss: 1.2174 - val_acc: 0.5977\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7839 - acc: 0.7226 - val_loss: 1.2118 - val_acc: 0.5975\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7833 - acc: 0.7239 - val_loss: 1.2158 - val_acc: 0.5966\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7729 - acc: 0.7277 - val_loss: 1.2160 - val_acc: 0.5961\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7830 - acc: 0.7240 - val_loss: 1.2172 - val_acc: 0.5959\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7791 - acc: 0.7274 - val_loss: 1.2147 - val_acc: 0.5987\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7766 - acc: 0.7279 - val_loss: 1.2134 - val_acc: 0.5963\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7803 - acc: 0.7248 - val_loss: 1.2145 - val_acc: 0.5973\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7844 - acc: 0.7240 - val_loss: 1.2160 - val_acc: 0.5962\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7919 - acc: 0.7220 - val_loss: 1.2177 - val_acc: 0.5961\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7814 - acc: 0.7240 - val_loss: 1.2150 - val_acc: 0.5977\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7842 - acc: 0.7227 - val_loss: 1.2178 - val_acc: 0.5981\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.7847 - acc: 0.7230 - val_loss: 1.2159 - val_acc: 0.5968\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7834 - acc: 0.7229 - val_loss: 1.2165 - val_acc: 0.5978\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7781 - acc: 0.7245 - val_loss: 1.2163 - val_acc: 0.5968\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7807 - acc: 0.7245 - val_loss: 1.2168 - val_acc: 0.5966\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7806 - acc: 0.7246 - val_loss: 1.2163 - val_acc: 0.5965\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7824 - acc: 0.7235 - val_loss: 1.2157 - val_acc: 0.5975\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7824 - acc: 0.7237 - val_loss: 1.2160 - val_acc: 0.5968\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7813 - acc: 0.7242 - val_loss: 1.2176 - val_acc: 0.5979\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.7731 - acc: 0.7248 - val_loss: 1.2165 - val_acc: 0.5974\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7792 - acc: 0.7231 - val_loss: 1.2159 - val_acc: 0.5985\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7780 - acc: 0.7246 - val_loss: 1.2158 - val_acc: 0.5972\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7755 - acc: 0.7247 - val_loss: 1.2163 - val_acc: 0.5960\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7777 - acc: 0.7252 - val_loss: 1.2155 - val_acc: 0.5969\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7818 - acc: 0.7249 - val_loss: 1.2161 - val_acc: 0.5971\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.7792 - acc: 0.7252 - val_loss: 1.2153 - val_acc: 0.5975\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7850 - acc: 0.7235 - val_loss: 1.2156 - val_acc: 0.5959\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7818 - acc: 0.7220 - val_loss: 1.2133 - val_acc: 0.5984\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7785 - acc: 0.7257 - val_loss: 1.2215 - val_acc: 0.5971\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7776 - acc: 0.7247 - val_loss: 1.2152 - val_acc: 0.5967\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 0.7829 - acc: 0.7228 - val_loss: 1.2153 - val_acc: 0.5969\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7754 - acc: 0.7275 - val_loss: 1.2169 - val_acc: 0.5971\n",
      "Epoch 117/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7743 - acc: 0.7265 - val_loss: 1.2167 - val_acc: 0.5973\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7807 - acc: 0.7270 - val_loss: 1.2155 - val_acc: 0.5971\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7765 - acc: 0.7260 - val_loss: 1.2180 - val_acc: 0.5981\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7735 - acc: 0.7268 - val_loss: 1.2161 - val_acc: 0.5968\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7731 - acc: 0.7271 - val_loss: 1.2154 - val_acc: 0.5971\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7799 - acc: 0.7237 - val_loss: 1.2167 - val_acc: 0.5966\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7812 - acc: 0.7232 - val_loss: 1.2169 - val_acc: 0.5968\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7831 - acc: 0.7240 - val_loss: 1.2148 - val_acc: 0.5966\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7790 - acc: 0.7243 - val_loss: 1.2171 - val_acc: 0.5978\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7781 - acc: 0.7264 - val_loss: 1.2171 - val_acc: 0.5971\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7773 - acc: 0.7271 - val_loss: 1.2176 - val_acc: 0.5969\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7851 - acc: 0.7233 - val_loss: 1.2154 - val_acc: 0.5969\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7746 - acc: 0.7255 - val_loss: 1.2155 - val_acc: 0.5961\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7823 - acc: 0.7235 - val_loss: 1.2201 - val_acc: 0.5956\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7826 - acc: 0.7257 - val_loss: 1.2152 - val_acc: 0.5978\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 0.7766 - acc: 0.7249 - val_loss: 1.2156 - val_acc: 0.5970\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 18s 364us/step - loss: 0.7773 - acc: 0.7254 - val_loss: 1.2164 - val_acc: 0.5966\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 19s 371us/step - loss: 0.7777 - acc: 0.7263 - val_loss: 1.2188 - val_acc: 0.5974\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 18s 367us/step - loss: 0.7805 - acc: 0.7245 - val_loss: 1.2174 - val_acc: 0.5954\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.7775 - acc: 0.7253 - val_loss: 1.2166 - val_acc: 0.5976\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7798 - acc: 0.7239 - val_loss: 1.2117 - val_acc: 0.5972\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 18s 362us/step - loss: 0.7821 - acc: 0.7254 - val_loss: 1.2172 - val_acc: 0.5969\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.7788 - acc: 0.7241 - val_loss: 1.2123 - val_acc: 0.5968\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 19s 373us/step - loss: 0.7797 - acc: 0.7251 - val_loss: 1.2212 - val_acc: 0.5979\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 18s 368us/step - loss: 0.7781 - acc: 0.7245 - val_loss: 1.2165 - val_acc: 0.5968\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 18s 363us/step - loss: 0.7771 - acc: 0.7280 - val_loss: 1.2156 - val_acc: 0.5965\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.7750 - acc: 0.7263 - val_loss: 1.2210 - val_acc: 0.5968\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.7782 - acc: 0.7241 - val_loss: 1.2186 - val_acc: 0.5965\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.7818 - acc: 0.7238 - val_loss: 1.2179 - val_acc: 0.5965\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.7756 - acc: 0.7244 - val_loss: 1.2179 - val_acc: 0.5973\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.7791 - acc: 0.7273 - val_loss: 1.2196 - val_acc: 0.5971\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.7762 - acc: 0.7258 - val_loss: 1.2155 - val_acc: 0.5969\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.7794 - acc: 0.7269 - val_loss: 1.2191 - val_acc: 0.5970\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.7761 - acc: 0.7237 - val_loss: 1.2212 - val_acc: 0.5961\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.7760 - acc: 0.7245 - val_loss: 1.2167 - val_acc: 0.5974\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.7777 - acc: 0.7250 - val_loss: 1.2155 - val_acc: 0.5976\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.7778 - acc: 0.7230 - val_loss: 1.2219 - val_acc: 0.5966\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.7793 - acc: 0.7246 - val_loss: 1.2175 - val_acc: 0.5971\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.7724 - acc: 0.7295 - val_loss: 1.2174 - val_acc: 0.5976\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.7807 - acc: 0.7229 - val_loss: 1.2195 - val_acc: 0.5981\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 0.7792 - acc: 0.7241 - val_loss: 1.2195 - val_acc: 0.5949\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 0.7733 - acc: 0.7261 - val_loss: 1.2191 - val_acc: 0.5973\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 0.7801 - acc: 0.7270 - val_loss: 1.2211 - val_acc: 0.5967\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7783 - acc: 0.7263 - val_loss: 1.2187 - val_acc: 0.5961\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.7778 - acc: 0.7254 - val_loss: 1.2197 - val_acc: 0.5979\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.7776 - acc: 0.7258 - val_loss: 1.2172 - val_acc: 0.5977\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 0.7783 - acc: 0.7259 - val_loss: 1.2178 - val_acc: 0.5980\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7722 - acc: 0.7250 - val_loss: 1.2179 - val_acc: 0.5976\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 0.7764 - acc: 0.7252 - val_loss: 1.2157 - val_acc: 0.5968\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7739 - acc: 0.7261 - val_loss: 1.2178 - val_acc: 0.5976\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 0.7789 - acc: 0.7257 - val_loss: 1.2158 - val_acc: 0.5967\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7776 - acc: 0.7257 - val_loss: 1.2186 - val_acc: 0.5971\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.7760 - acc: 0.7260 - val_loss: 1.2185 - val_acc: 0.5984\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 0.7780 - acc: 0.7222 - val_loss: 1.2173 - val_acc: 0.5968\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7711 - acc: 0.7286 - val_loss: 1.2172 - val_acc: 0.5979\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 0.7746 - acc: 0.7275 - val_loss: 1.2182 - val_acc: 0.5969\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 0.7717 - acc: 0.7291 - val_loss: 1.2228 - val_acc: 0.5978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7756 - acc: 0.7277 - val_loss: 1.2195 - val_acc: 0.5975\n",
      "Epoch 175/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7773 - acc: 0.7253 - val_loss: 1.2162 - val_acc: 0.5985\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7769 - acc: 0.7248 - val_loss: 1.2171 - val_acc: 0.5968\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7708 - acc: 0.7278 - val_loss: 1.2194 - val_acc: 0.5971\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7782 - acc: 0.7253 - val_loss: 1.2212 - val_acc: 0.5970\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7771 - acc: 0.7258 - val_loss: 1.2205 - val_acc: 0.5974\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 0.7766 - acc: 0.7254 - val_loss: 1.2211 - val_acc: 0.5963\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 0.7746 - acc: 0.7265 - val_loss: 1.2197 - val_acc: 0.5978\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 0.7801 - acc: 0.7250 - val_loss: 1.2194 - val_acc: 0.5985\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 17s 341us/step - loss: 0.7809 - acc: 0.7233 - val_loss: 1.2174 - val_acc: 0.5983\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 0.7757 - acc: 0.7265 - val_loss: 1.2179 - val_acc: 0.5976\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.7772 - acc: 0.7243 - val_loss: 1.2176 - val_acc: 0.5977\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 0.7801 - acc: 0.7228 - val_loss: 1.2183 - val_acc: 0.5985\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 18s 361us/step - loss: 0.7788 - acc: 0.7231 - val_loss: 1.2198 - val_acc: 0.5980\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 0.7767 - acc: 0.7263 - val_loss: 1.2221 - val_acc: 0.5978\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.7722 - acc: 0.7263 - val_loss: 1.2193 - val_acc: 0.5977\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.7729 - acc: 0.7309 - val_loss: 1.2173 - val_acc: 0.5973\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.7716 - acc: 0.7266 - val_loss: 1.2197 - val_acc: 0.5972\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 0.7699 - acc: 0.7287 - val_loss: 1.2212 - val_acc: 0.5995\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 0.7744 - acc: 0.7258 - val_loss: 1.2214 - val_acc: 0.5971\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 0.7759 - acc: 0.7250 - val_loss: 1.2166 - val_acc: 0.5981\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 18s 362us/step - loss: 0.7799 - acc: 0.7247 - val_loss: 1.2207 - val_acc: 0.5974\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 18s 364us/step - loss: 0.7774 - acc: 0.7258 - val_loss: 1.2201 - val_acc: 0.5978\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 18s 368us/step - loss: 0.7751 - acc: 0.7260 - val_loss: 1.2208 - val_acc: 0.5968\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 18s 369us/step - loss: 0.7707 - acc: 0.7285 - val_loss: 1.2183 - val_acc: 0.5969\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 18s 360us/step - loss: 0.7741 - acc: 0.7257 - val_loss: 1.2188 - val_acc: 0.5974\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 18s 369us/step - loss: 0.7785 - acc: 0.7242 - val_loss: 1.2202 - val_acc: 0.5976\n",
      "Saved trained model at /home/bong/Projects/ee298/HW1/saved_models/keras_cifar10_mlp_trained_model.h5 \n",
      "10000/10000 [==============================] - 1s 67us/step\n",
      "Test loss: 1.2201702209472656\n",
      "Test accuracy: 0.5976\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "# Training Params\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_mlp_trained_model.h5'\n",
    "initial_lr=0.0004\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Reshape x_train and x_test to a flattened vector so we can feed it to MLP\n",
    "image_size = x_train.shape[1]\n",
    "input_size = image_size * image_size * 3\n",
    "x_train = np.reshape(x_train, (-1, input_size))\n",
    "x_test = np.reshape(x_test, (-1, input_size))\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1024, input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "          \n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "          \n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "   \n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=initial_lr, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Tensorboard Callback\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "    batch_size=batch_size,\n",
    "    log_dir=\"logs/{}\".format(time()),\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='batch'\n",
    ")\n",
    "\n",
    "# Use learning rate reducer on plateau\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [tbCallBack, lr_reducer]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR10 MLP.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
