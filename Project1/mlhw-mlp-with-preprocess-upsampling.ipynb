{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, Embedding, Input, Reshape, Concatenate\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name='mlhw-mlp-with-preprocess'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('dataset/train_values.csv')\n",
    "y_train = pd.read_csv('dataset/train_labels.csv')\n",
    "x_test = pd.read_csv('dataset/test_values.csv')\n",
    "\n",
    "\n",
    "# Convert string values to integers\n",
    "x_train[\"thal\"] = x_train[\"thal\"].astype('category')\n",
    "x_train[\"thal\"] = x_train[\"thal\"].cat.codes\n",
    "\n",
    "x_test[\"thal\"] = x_test[\"thal\"].astype('category')\n",
    "x_test[\"thal\"] = x_test[\"thal\"].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "# Drop column\n",
    "x_train = x_train.drop(\"patient_id\", axis=1)\n",
    "y_train = y_train.drop(\"patient_id\", axis=1)\n",
    "\n",
    "xsize = x_train.shape[1]\n",
    "ysize = 1\n",
    "label_column = 'heart_disease_present'\n",
    "cols = list(x_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slope_of_peak_exercise_st_segment  thal  resting_blood_pressure  \\\n",
       "0                                  1     1                     128   \n",
       "1                                  2     1                     110   \n",
       "2                                  1     1                     125   \n",
       "3                                  1     2                     152   \n",
       "4                                  3     2                     178   \n",
       "\n",
       "   chest_pain_type  num_major_vessels  fasting_blood_sugar_gt_120_mg_per_dl  \\\n",
       "0                2                  0                                     0   \n",
       "1                3                  0                                     0   \n",
       "2                4                  3                                     0   \n",
       "3                4                  0                                     0   \n",
       "4                1                  0                                     0   \n",
       "\n",
       "   resting_ekg_results  serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  \\\n",
       "0                    2                          308                       0.0   \n",
       "1                    0                          214                       1.6   \n",
       "2                    2                          304                       0.0   \n",
       "3                    0                          223                       0.0   \n",
       "4                    2                          270                       4.2   \n",
       "\n",
       "   sex  age  max_heart_rate_achieved  exercise_induced_angina  \n",
       "0    1   45                      170                        0  \n",
       "1    0   54                      158                        0  \n",
       "2    1   77                      162                        1  \n",
       "3    1   40                      181                        0  \n",
       "4    1   59                      145                        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Whitening\n",
    "This will normalize our values so higher order values won't dominate other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.888762</td>\n",
       "      <td>-0.645259</td>\n",
       "      <td>-0.194652</td>\n",
       "      <td>-1.231340</td>\n",
       "      <td>-0.716404</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>0.951196</td>\n",
       "      <td>1.115158</td>\n",
       "      <td>-0.900694</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>-1.051032</td>\n",
       "      <td>0.929891</td>\n",
       "      <td>-0.678852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.727169</td>\n",
       "      <td>-0.645259</td>\n",
       "      <td>-1.252825</td>\n",
       "      <td>-0.165757</td>\n",
       "      <td>-0.716404</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>-1.051322</td>\n",
       "      <td>-0.667915</td>\n",
       "      <td>0.526148</td>\n",
       "      <td>-1.483908</td>\n",
       "      <td>-0.086892</td>\n",
       "      <td>0.386007</td>\n",
       "      <td>-0.678852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.888762</td>\n",
       "      <td>-0.645259</td>\n",
       "      <td>-0.371014</td>\n",
       "      <td>0.899825</td>\n",
       "      <td>2.378462</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>0.951196</td>\n",
       "      <td>1.039283</td>\n",
       "      <td>-0.900694</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>2.377024</td>\n",
       "      <td>0.567302</td>\n",
       "      <td>1.464891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.888762</td>\n",
       "      <td>1.114538</td>\n",
       "      <td>1.216246</td>\n",
       "      <td>0.899825</td>\n",
       "      <td>-0.716404</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>-1.051322</td>\n",
       "      <td>-0.497195</td>\n",
       "      <td>-0.900694</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>-1.586666</td>\n",
       "      <td>1.428452</td>\n",
       "      <td>-0.678852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.343100</td>\n",
       "      <td>1.114538</td>\n",
       "      <td>2.744719</td>\n",
       "      <td>-2.296923</td>\n",
       "      <td>-0.716404</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>0.951196</td>\n",
       "      <td>0.394342</td>\n",
       "      <td>2.844768</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>0.448742</td>\n",
       "      <td>-0.203201</td>\n",
       "      <td>-0.678852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slope_of_peak_exercise_st_segment      thal  resting_blood_pressure  \\\n",
       "0                          -0.888762 -0.645259               -0.194652   \n",
       "1                           0.727169 -0.645259               -1.252825   \n",
       "2                          -0.888762 -0.645259               -0.371014   \n",
       "3                          -0.888762  1.114538                1.216246   \n",
       "4                           2.343100  1.114538                2.744719   \n",
       "\n",
       "   chest_pain_type  num_major_vessels  fasting_blood_sugar_gt_120_mg_per_dl  \\\n",
       "0        -1.231340          -0.716404                             -0.437019   \n",
       "1        -0.165757          -0.716404                             -0.437019   \n",
       "2         0.899825           2.378462                             -0.437019   \n",
       "3         0.899825          -0.716404                             -0.437019   \n",
       "4        -2.296923          -0.716404                             -0.437019   \n",
       "\n",
       "   resting_ekg_results  serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  \\\n",
       "0             0.951196                     1.115158                 -0.900694   \n",
       "1            -1.051322                    -0.667915                  0.526148   \n",
       "2             0.951196                     1.039283                 -0.900694   \n",
       "3            -1.051322                    -0.497195                 -0.900694   \n",
       "4             0.951196                     0.394342                  2.844768   \n",
       "\n",
       "        sex       age  max_heart_rate_achieved  exercise_induced_angina  \n",
       "0  0.670152 -1.051032                 0.929891                -0.678852  \n",
       "1 -1.483908 -0.086892                 0.386007                -0.678852  \n",
       "2  0.670152  2.377024                 0.567302                 1.464891  \n",
       "3  0.670152 -1.586666                 1.428452                -0.678852  \n",
       "4  0.670152  0.448742                -0.203201                -0.678852  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_mean = x_train[cols].mean(axis=0)\n",
    "x_train_std = x_train[cols].std(axis=0)\n",
    "x_train[cols] = (x_train[cols] - x_train_mean) / x_train_std\n",
    "\n",
    "x_test[cols] = (x_test[cols] - x_train_mean) / x_train_std\n",
    "\n",
    "\n",
    "display(x_train[cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-arrange Data for Categorical and Continous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = [\n",
    "    'thal',\n",
    "    'chest_pain_type',\n",
    "    'fasting_blood_sugar_gt_120_mg_per_dl',\n",
    "    'resting_ekg_results',\n",
    "    'sex',\n",
    "    'exercise_induced_angina'\n",
    "]\n",
    "cont_cols = [\n",
    "    'slope_of_peak_exercise_st_segment',\n",
    "    'num_major_vessels',\n",
    "    'resting_blood_pressure',\n",
    "    'serum_cholesterol_mg_per_dl',\n",
    "    'oldpeak_eq_st_depression',\n",
    "    'age',\n",
    "    'max_heart_rate_achieved',\n",
    "]\n",
    "\n",
    "\n",
    "def preproc_input(input_data):\n",
    "    input_list = []\n",
    "    for cat_col in cat_cols:\n",
    "        input_list.append(input_data[cat_col].values)\n",
    "\n",
    "    input_list.append(input_data[cont_cols].values)\n",
    "    return input_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.001\n",
    "opt_name = 'adam'\n",
    "# opt_name = 'rmsprop'\n",
    "\n",
    "def create_model():\n",
    "    inputs = []\n",
    "    embeddings = []\n",
    "\n",
    "    # For Categorical Variables\n",
    "    for cat_col in cat_cols :\n",
    "\n",
    "        no_of_unique_cat  = x_train[cat_col].nunique()\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50)\n",
    "        embedding_size = int(embedding_size)\n",
    "        vocab  = no_of_unique_cat + 1\n",
    "\n",
    "        emb_input = Input(shape=(1,))\n",
    "        emb = Embedding(vocab, embedding_size, input_length = 1)(emb_input)\n",
    "        emb = Dropout(.01)(emb)\n",
    "        emb = Reshape(target_shape=(embedding_size, ))(emb)\n",
    "        inputs.append(emb_input)\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    # Continuous variables\n",
    "    input_cont = Input(shape=(len(cont_cols),))\n",
    "    embedding_cont = BatchNormalization()(input_cont) \n",
    "    inputs.append(input_cont)\n",
    "    embeddings.append(embedding_cont)\n",
    "\n",
    "    x = Concatenate()(embeddings)\n",
    "    x = Dense(100)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.15)(x)\n",
    "\n",
    "    x = Dense(50)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.15)(x)\n",
    "\n",
    "    x = Dense(20)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.15)(x)\n",
    "\n",
    "    x = Dense(1)(x)\n",
    "    output = Activation('sigmoid')(x)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=inputs, \n",
    "        outputs=[output]\n",
    "    )\n",
    "\n",
    "\n",
    "#     opt = rmsprop(lr=initial_lr, decay=1e-6)\n",
    "\n",
    "    opt = Adam(lr=initial_lr)\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=[metrics.binary_accuracy]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  1\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 22s 86ms/step - loss: 0.8613 - binary_accuracy: 0.6111 - val_loss: 0.8293 - val_binary_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 574us/step - loss: 0.6353 - binary_accuracy: 0.7143 - val_loss: 0.7272 - val_binary_accuracy: 0.6111\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 553us/step - loss: 0.5766 - binary_accuracy: 0.7421 - val_loss: 0.6673 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 535us/step - loss: 0.4747 - binary_accuracy: 0.8016 - val_loss: 0.6484 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 573us/step - loss: 0.4323 - binary_accuracy: 0.8095 - val_loss: 0.5895 - val_binary_accuracy: 0.7778\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 609us/step - loss: 0.5023 - binary_accuracy: 0.7659 - val_loss: 0.5168 - val_binary_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 615us/step - loss: 0.5151 - binary_accuracy: 0.7619 - val_loss: 0.4455 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 565us/step - loss: 0.4521 - binary_accuracy: 0.8016 - val_loss: 0.4213 - val_binary_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 578us/step - loss: 0.4935 - binary_accuracy: 0.8175 - val_loss: 0.3996 - val_binary_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 640us/step - loss: 0.4015 - binary_accuracy: 0.8492 - val_loss: 0.4088 - val_binary_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 564us/step - loss: 0.3969 - binary_accuracy: 0.8413 - val_loss: 0.4026 - val_binary_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 711us/step - loss: 0.4429 - binary_accuracy: 0.8056 - val_loss: 0.3763 - val_binary_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 639us/step - loss: 0.3536 - binary_accuracy: 0.8651 - val_loss: 0.3528 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 635us/step - loss: 0.3775 - binary_accuracy: 0.8413 - val_loss: 0.3255 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 608us/step - loss: 0.3018 - binary_accuracy: 0.8730 - val_loss: 0.3048 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 561us/step - loss: 0.3749 - binary_accuracy: 0.8175 - val_loss: 0.2895 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 542us/step - loss: 0.3489 - binary_accuracy: 0.8333 - val_loss: 0.2762 - val_binary_accuracy: 0.8889\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 601us/step - loss: 0.3046 - binary_accuracy: 0.8730 - val_loss: 0.2716 - val_binary_accuracy: 0.8889\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 650us/step - loss: 0.3314 - binary_accuracy: 0.8690 - val_loss: 0.2647 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 594us/step - loss: 0.2759 - binary_accuracy: 0.8770 - val_loss: 0.2581 - val_binary_accuracy: 0.9444\n",
      "18/18 [==============================] - 0s 401us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 21s 84ms/step - loss: 0.8158 - binary_accuracy: 0.5079 - val_loss: 0.7393 - val_binary_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 661us/step - loss: 0.6717 - binary_accuracy: 0.6349 - val_loss: 0.7032 - val_binary_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 631us/step - loss: 0.5170 - binary_accuracy: 0.7778 - val_loss: 0.6834 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 650us/step - loss: 0.5335 - binary_accuracy: 0.7579 - val_loss: 0.6412 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 646us/step - loss: 0.4478 - binary_accuracy: 0.7778 - val_loss: 0.6003 - val_binary_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 640us/step - loss: 0.4495 - binary_accuracy: 0.8175 - val_loss: 0.5882 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 668us/step - loss: 0.4218 - binary_accuracy: 0.8413 - val_loss: 0.5807 - val_binary_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 638us/step - loss: 0.4322 - binary_accuracy: 0.8294 - val_loss: 0.5741 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 583us/step - loss: 0.4012 - binary_accuracy: 0.8413 - val_loss: 0.5645 - val_binary_accuracy: 0.7222\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 632us/step - loss: 0.4304 - binary_accuracy: 0.8214 - val_loss: 0.5680 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 661us/step - loss: 0.3899 - binary_accuracy: 0.8333 - val_loss: 0.5660 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 664us/step - loss: 0.3970 - binary_accuracy: 0.8175 - val_loss: 0.5555 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 684us/step - loss: 0.3661 - binary_accuracy: 0.8690 - val_loss: 0.5311 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 659us/step - loss: 0.3834 - binary_accuracy: 0.8532 - val_loss: 0.5042 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 610us/step - loss: 0.3924 - binary_accuracy: 0.8095 - val_loss: 0.4812 - val_binary_accuracy: 0.7778\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 603us/step - loss: 0.3571 - binary_accuracy: 0.8492 - val_loss: 0.4647 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 570us/step - loss: 0.3317 - binary_accuracy: 0.8810 - val_loss: 0.4560 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 585us/step - loss: 0.3603 - binary_accuracy: 0.8730 - val_loss: 0.4392 - val_binary_accuracy: 0.7778\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 614us/step - loss: 0.3447 - binary_accuracy: 0.8452 - val_loss: 0.4283 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 593us/step - loss: 0.3534 - binary_accuracy: 0.8452 - val_loss: 0.4159 - val_binary_accuracy: 0.7778\n",
      "18/18 [==============================] - 0s 574us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 23s 92ms/step - loss: 0.7750 - binary_accuracy: 0.5437 - val_loss: 0.5663 - val_binary_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 596us/step - loss: 0.5948 - binary_accuracy: 0.7143 - val_loss: 0.5863 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 578us/step - loss: 0.5338 - binary_accuracy: 0.7302 - val_loss: 0.5647 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 585us/step - loss: 0.4894 - binary_accuracy: 0.7619 - val_loss: 0.5235 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 592us/step - loss: 0.4930 - binary_accuracy: 0.7659 - val_loss: 0.5065 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 589us/step - loss: 0.4249 - binary_accuracy: 0.7937 - val_loss: 0.4634 - val_binary_accuracy: 0.7222\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 576us/step - loss: 0.4535 - binary_accuracy: 0.8135 - val_loss: 0.4415 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 590us/step - loss: 0.4349 - binary_accuracy: 0.8056 - val_loss: 0.4158 - val_binary_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 572us/step - loss: 0.4336 - binary_accuracy: 0.8214 - val_loss: 0.3877 - val_binary_accuracy: 0.7778\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 782us/step - loss: 0.4554 - binary_accuracy: 0.7897 - val_loss: 0.3746 - val_binary_accuracy: 0.7778\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 769us/step - loss: 0.4060 - binary_accuracy: 0.8532 - val_loss: 0.3591 - val_binary_accuracy: 0.7778\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 761us/step - loss: 0.4305 - binary_accuracy: 0.8135 - val_loss: 0.3510 - val_binary_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 632us/step - loss: 0.3755 - binary_accuracy: 0.8333 - val_loss: 0.3395 - val_binary_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 599us/step - loss: 0.4129 - binary_accuracy: 0.8175 - val_loss: 0.3372 - val_binary_accuracy: 0.8333\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 582us/step - loss: 0.3859 - binary_accuracy: 0.8294 - val_loss: 0.3332 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 609us/step - loss: 0.3431 - binary_accuracy: 0.8770 - val_loss: 0.3193 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 639us/step - loss: 0.3571 - binary_accuracy: 0.8175 - val_loss: 0.3069 - val_binary_accuracy: 0.8889\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 611us/step - loss: 0.3164 - binary_accuracy: 0.8611 - val_loss: 0.3010 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 591us/step - loss: 0.3022 - binary_accuracy: 0.8730 - val_loss: 0.2942 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 598us/step - loss: 0.3209 - binary_accuracy: 0.8611 - val_loss: 0.2890 - val_binary_accuracy: 0.8889\n",
      "18/18 [==============================] - 0s 446us/step\n",
      "\n",
      "Fold  2\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 23s 91ms/step - loss: 0.7833 - binary_accuracy: 0.5238 - val_loss: 0.4733 - val_binary_accuracy: 0.7778\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 611us/step - loss: 0.5925 - binary_accuracy: 0.7302 - val_loss: 0.4177 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 626us/step - loss: 0.5453 - binary_accuracy: 0.7937 - val_loss: 0.3681 - val_binary_accuracy: 0.8333\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 588us/step - loss: 0.4728 - binary_accuracy: 0.8056 - val_loss: 0.3606 - val_binary_accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 605us/step - loss: 0.4564 - binary_accuracy: 0.8095 - val_loss: 0.3507 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 601us/step - loss: 0.4454 - binary_accuracy: 0.8175 - val_loss: 0.3455 - val_binary_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 599us/step - loss: 0.4429 - binary_accuracy: 0.8294 - val_loss: 0.3298 - val_binary_accuracy: 0.8889\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 583us/step - loss: 0.4318 - binary_accuracy: 0.8333 - val_loss: 0.3162 - val_binary_accuracy: 0.8889\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 615us/step - loss: 0.3959 - binary_accuracy: 0.8492 - val_loss: 0.3048 - val_binary_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 576us/step - loss: 0.4088 - binary_accuracy: 0.8333 - val_loss: 0.2932 - val_binary_accuracy: 0.8889\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 577us/step - loss: 0.3534 - binary_accuracy: 0.8730 - val_loss: 0.2790 - val_binary_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 613us/step - loss: 0.3724 - binary_accuracy: 0.8492 - val_loss: 0.2790 - val_binary_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 591us/step - loss: 0.3891 - binary_accuracy: 0.8413 - val_loss: 0.2786 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 593us/step - loss: 0.3334 - binary_accuracy: 0.8611 - val_loss: 0.2809 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 597us/step - loss: 0.3728 - binary_accuracy: 0.8730 - val_loss: 0.2857 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 619us/step - loss: 0.3052 - binary_accuracy: 0.8532 - val_loss: 0.2946 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 601us/step - loss: 0.3541 - binary_accuracy: 0.8492 - val_loss: 0.2945 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 587us/step - loss: 0.3265 - binary_accuracy: 0.8611 - val_loss: 0.2751 - val_binary_accuracy: 0.8889\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 554us/step - loss: 0.2947 - binary_accuracy: 0.8889 - val_loss: 0.2564 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 627us/step - loss: 0.2854 - binary_accuracy: 0.8929 - val_loss: 0.2455 - val_binary_accuracy: 0.9444\n",
      "18/18 [==============================] - 0s 452us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 24s 95ms/step - loss: 0.7614 - binary_accuracy: 0.5159 - val_loss: 0.4697 - val_binary_accuracy: 0.8889\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 640us/step - loss: 0.5489 - binary_accuracy: 0.7579 - val_loss: 0.4371 - val_binary_accuracy: 0.8333\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 664us/step - loss: 0.4811 - binary_accuracy: 0.7897 - val_loss: 0.4183 - val_binary_accuracy: 0.8333\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 635us/step - loss: 0.4907 - binary_accuracy: 0.7738 - val_loss: 0.3971 - val_binary_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 617us/step - loss: 0.4414 - binary_accuracy: 0.8016 - val_loss: 0.3724 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 617us/step - loss: 0.4195 - binary_accuracy: 0.8214 - val_loss: 0.3488 - val_binary_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 611us/step - loss: 0.4268 - binary_accuracy: 0.8175 - val_loss: 0.3329 - val_binary_accuracy: 0.8889\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 607us/step - loss: 0.4367 - binary_accuracy: 0.8016 - val_loss: 0.3264 - val_binary_accuracy: 0.8889\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 624us/step - loss: 0.4158 - binary_accuracy: 0.8095 - val_loss: 0.3236 - val_binary_accuracy: 0.8889\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 569us/step - loss: 0.3858 - binary_accuracy: 0.8254 - val_loss: 0.3146 - val_binary_accuracy: 0.8889\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 569us/step - loss: 0.3486 - binary_accuracy: 0.8413 - val_loss: 0.2982 - val_binary_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 585us/step - loss: 0.4297 - binary_accuracy: 0.8135 - val_loss: 0.2891 - val_binary_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 604us/step - loss: 0.3487 - binary_accuracy: 0.8452 - val_loss: 0.2883 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 610us/step - loss: 0.3779 - binary_accuracy: 0.8175 - val_loss: 0.2798 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 590us/step - loss: 0.3257 - binary_accuracy: 0.8532 - val_loss: 0.2792 - val_binary_accuracy: 0.9444\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 613us/step - loss: 0.3299 - binary_accuracy: 0.8810 - val_loss: 0.2744 - val_binary_accuracy: 0.9444\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 620us/step - loss: 0.3328 - binary_accuracy: 0.8770 - val_loss: 0.2718 - val_binary_accuracy: 0.9444\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 605us/step - loss: 0.3513 - binary_accuracy: 0.8492 - val_loss: 0.2614 - val_binary_accuracy: 0.9444\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 636us/step - loss: 0.3156 - binary_accuracy: 0.8532 - val_loss: 0.2539 - val_binary_accuracy: 0.9444\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 611us/step - loss: 0.3258 - binary_accuracy: 0.8690 - val_loss: 0.2489 - val_binary_accuracy: 0.8889\n",
      "18/18 [==============================] - 0s 537us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 25s 99ms/step - loss: 0.7037 - binary_accuracy: 0.6310 - val_loss: 0.5420 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 602us/step - loss: 0.6242 - binary_accuracy: 0.6667 - val_loss: 0.4462 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 580us/step - loss: 0.4833 - binary_accuracy: 0.8016 - val_loss: 0.3969 - val_binary_accuracy: 0.8333\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 560us/step - loss: 0.4469 - binary_accuracy: 0.7937 - val_loss: 0.3627 - val_binary_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 549us/step - loss: 0.4763 - binary_accuracy: 0.7937 - val_loss: 0.3476 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 557us/step - loss: 0.4315 - binary_accuracy: 0.8214 - val_loss: 0.3482 - val_binary_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 570us/step - loss: 0.4007 - binary_accuracy: 0.8214 - val_loss: 0.3437 - val_binary_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 590us/step - loss: 0.4344 - binary_accuracy: 0.8214 - val_loss: 0.3274 - val_binary_accuracy: 0.8889\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 578us/step - loss: 0.4043 - binary_accuracy: 0.8135 - val_loss: 0.3152 - val_binary_accuracy: 0.8889\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 591us/step - loss: 0.3963 - binary_accuracy: 0.8056 - val_loss: 0.3168 - val_binary_accuracy: 0.8889\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 593us/step - loss: 0.4060 - binary_accuracy: 0.8294 - val_loss: 0.3096 - val_binary_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 564us/step - loss: 0.3982 - binary_accuracy: 0.8373 - val_loss: 0.3080 - val_binary_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 570us/step - loss: 0.3613 - binary_accuracy: 0.8770 - val_loss: 0.3127 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 582us/step - loss: 0.3298 - binary_accuracy: 0.8810 - val_loss: 0.3124 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 570us/step - loss: 0.3715 - binary_accuracy: 0.8452 - val_loss: 0.3106 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 557us/step - loss: 0.3787 - binary_accuracy: 0.8214 - val_loss: 0.3025 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 577us/step - loss: 0.3548 - binary_accuracy: 0.8492 - val_loss: 0.2906 - val_binary_accuracy: 0.8889\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 574us/step - loss: 0.3482 - binary_accuracy: 0.8571 - val_loss: 0.2816 - val_binary_accuracy: 0.8889\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 576us/step - loss: 0.3159 - binary_accuracy: 0.8849 - val_loss: 0.2824 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 573us/step - loss: 0.3208 - binary_accuracy: 0.8452 - val_loss: 0.2703 - val_binary_accuracy: 0.8889\n",
      "18/18 [==============================] - 0s 408us/step\n",
      "\n",
      "Fold  3\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 26s 104ms/step - loss: 0.9309 - binary_accuracy: 0.4444 - val_loss: 0.7534 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 629us/step - loss: 0.6726 - binary_accuracy: 0.6667 - val_loss: 0.8224 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 573us/step - loss: 0.5460 - binary_accuracy: 0.7698 - val_loss: 0.8210 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 600us/step - loss: 0.5205 - binary_accuracy: 0.7421 - val_loss: 0.8369 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 615us/step - loss: 0.5099 - binary_accuracy: 0.7698 - val_loss: 0.8425 - val_binary_accuracy: 0.7222\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 594us/step - loss: 0.4794 - binary_accuracy: 0.8016 - val_loss: 0.8417 - val_binary_accuracy: 0.7222\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 590us/step - loss: 0.4753 - binary_accuracy: 0.7897 - val_loss: 0.8420 - val_binary_accuracy: 0.7222\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 588us/step - loss: 0.4384 - binary_accuracy: 0.8056 - val_loss: 0.8496 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 581us/step - loss: 0.4001 - binary_accuracy: 0.8373 - val_loss: 0.8509 - val_binary_accuracy: 0.7222\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 606us/step - loss: 0.4479 - binary_accuracy: 0.8135 - val_loss: 0.8484 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 579us/step - loss: 0.4462 - binary_accuracy: 0.8214 - val_loss: 0.8449 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 590us/step - loss: 0.4355 - binary_accuracy: 0.8373 - val_loss: 0.8329 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 589us/step - loss: 0.4026 - binary_accuracy: 0.8571 - val_loss: 0.8182 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 588us/step - loss: 0.3942 - binary_accuracy: 0.8333 - val_loss: 0.8027 - val_binary_accuracy: 0.7222\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 578us/step - loss: 0.3991 - binary_accuracy: 0.8571 - val_loss: 0.7907 - val_binary_accuracy: 0.7222\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 604us/step - loss: 0.3646 - binary_accuracy: 0.8373 - val_loss: 0.7662 - val_binary_accuracy: 0.7222\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 591us/step - loss: 0.3431 - binary_accuracy: 0.8690 - val_loss: 0.7481 - val_binary_accuracy: 0.7222\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 553us/step - loss: 0.3259 - binary_accuracy: 0.8849 - val_loss: 0.7192 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 577us/step - loss: 0.3270 - binary_accuracy: 0.8651 - val_loss: 0.7072 - val_binary_accuracy: 0.7222\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 592us/step - loss: 0.3144 - binary_accuracy: 0.8690 - val_loss: 0.6750 - val_binary_accuracy: 0.7222\n",
      "18/18 [==============================] - 0s 492us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 29s 114ms/step - loss: 0.7769 - binary_accuracy: 0.5833 - val_loss: 0.6481 - val_binary_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 685us/step - loss: 0.6020 - binary_accuracy: 0.6984 - val_loss: 0.6545 - val_binary_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 662us/step - loss: 0.4754 - binary_accuracy: 0.7857 - val_loss: 0.6341 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 639us/step - loss: 0.4794 - binary_accuracy: 0.7937 - val_loss: 0.6441 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 674us/step - loss: 0.4420 - binary_accuracy: 0.7937 - val_loss: 0.6597 - val_binary_accuracy: 0.7222\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 626us/step - loss: 0.4613 - binary_accuracy: 0.8095 - val_loss: 0.6419 - val_binary_accuracy: 0.7222\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 682us/step - loss: 0.4512 - binary_accuracy: 0.8016 - val_loss: 0.6446 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 654us/step - loss: 0.4104 - binary_accuracy: 0.8294 - val_loss: 0.6623 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 626us/step - loss: 0.4469 - binary_accuracy: 0.8056 - val_loss: 0.6637 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 610us/step - loss: 0.3526 - binary_accuracy: 0.8492 - val_loss: 0.6702 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 664us/step - loss: 0.3973 - binary_accuracy: 0.8294 - val_loss: 0.6486 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 577us/step - loss: 0.3779 - binary_accuracy: 0.8333 - val_loss: 0.6225 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 618us/step - loss: 0.3734 - binary_accuracy: 0.8254 - val_loss: 0.6052 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 613us/step - loss: 0.3962 - binary_accuracy: 0.8571 - val_loss: 0.5889 - val_binary_accuracy: 0.7222\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 624us/step - loss: 0.3683 - binary_accuracy: 0.8452 - val_loss: 0.5653 - val_binary_accuracy: 0.7222\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 618us/step - loss: 0.3738 - binary_accuracy: 0.8333 - val_loss: 0.5461 - val_binary_accuracy: 0.7222\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 665us/step - loss: 0.3482 - binary_accuracy: 0.8571 - val_loss: 0.5342 - val_binary_accuracy: 0.7222\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 605us/step - loss: 0.3876 - binary_accuracy: 0.8492 - val_loss: 0.5255 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 580us/step - loss: 0.3337 - binary_accuracy: 0.8651 - val_loss: 0.5093 - val_binary_accuracy: 0.7222\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 611us/step - loss: 0.3370 - binary_accuracy: 0.8571 - val_loss: 0.5084 - val_binary_accuracy: 0.7222\n",
      "18/18 [==============================] - 0s 450us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 30s 119ms/step - loss: 0.7766 - binary_accuracy: 0.6230 - val_loss: 0.6776 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 652us/step - loss: 0.6607 - binary_accuracy: 0.7341 - val_loss: 0.7156 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 681us/step - loss: 0.5946 - binary_accuracy: 0.7381 - val_loss: 0.7190 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 720us/step - loss: 0.5136 - binary_accuracy: 0.7817 - val_loss: 0.7028 - val_binary_accuracy: 0.6111\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 687us/step - loss: 0.5045 - binary_accuracy: 0.7937 - val_loss: 0.7143 - val_binary_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 633us/step - loss: 0.4549 - binary_accuracy: 0.8056 - val_loss: 0.7053 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 645us/step - loss: 0.4160 - binary_accuracy: 0.8413 - val_loss: 0.7032 - val_binary_accuracy: 0.7222\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 615us/step - loss: 0.4087 - binary_accuracy: 0.8254 - val_loss: 0.7326 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 665us/step - loss: 0.3997 - binary_accuracy: 0.8373 - val_loss: 0.7805 - val_binary_accuracy: 0.7222\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 670us/step - loss: 0.3913 - binary_accuracy: 0.8532 - val_loss: 0.7832 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 617us/step - loss: 0.4127 - binary_accuracy: 0.8214 - val_loss: 0.7753 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 626us/step - loss: 0.4286 - binary_accuracy: 0.8214 - val_loss: 0.7734 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 671us/step - loss: 0.3567 - binary_accuracy: 0.8492 - val_loss: 0.7552 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 669us/step - loss: 0.3679 - binary_accuracy: 0.8294 - val_loss: 0.7640 - val_binary_accuracy: 0.7222\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 609us/step - loss: 0.3638 - binary_accuracy: 0.8611 - val_loss: 0.6949 - val_binary_accuracy: 0.7222\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 677us/step - loss: 0.3561 - binary_accuracy: 0.8452 - val_loss: 0.6593 - val_binary_accuracy: 0.7222\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 679us/step - loss: 0.3364 - binary_accuracy: 0.8413 - val_loss: 0.6288 - val_binary_accuracy: 0.7222\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 612us/step - loss: 0.3231 - binary_accuracy: 0.8690 - val_loss: 0.6058 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 624us/step - loss: 0.3453 - binary_accuracy: 0.8492 - val_loss: 0.5843 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 633us/step - loss: 0.2985 - binary_accuracy: 0.8968 - val_loss: 0.5485 - val_binary_accuracy: 0.7778\n",
      "18/18 [==============================] - 0s 566us/step\n",
      "\n",
      "Fold  4\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 29s 115ms/step - loss: 0.7482 - binary_accuracy: 0.6151 - val_loss: 0.6067 - val_binary_accuracy: 0.7778\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 626us/step - loss: 0.6026 - binary_accuracy: 0.7024 - val_loss: 0.5611 - val_binary_accuracy: 0.8333\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 564us/step - loss: 0.5369 - binary_accuracy: 0.7460 - val_loss: 0.5605 - val_binary_accuracy: 0.7778\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 624us/step - loss: 0.5214 - binary_accuracy: 0.7738 - val_loss: 0.5622 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 644us/step - loss: 0.4680 - binary_accuracy: 0.8135 - val_loss: 0.5690 - val_binary_accuracy: 0.7222\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 611us/step - loss: 0.4587 - binary_accuracy: 0.7817 - val_loss: 0.5643 - val_binary_accuracy: 0.6111\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 607us/step - loss: 0.4357 - binary_accuracy: 0.7738 - val_loss: 0.5588 - val_binary_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 591us/step - loss: 0.4342 - binary_accuracy: 0.8175 - val_loss: 0.5363 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 629us/step - loss: 0.3779 - binary_accuracy: 0.8532 - val_loss: 0.5102 - val_binary_accuracy: 0.7778\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 602us/step - loss: 0.4389 - binary_accuracy: 0.8135 - val_loss: 0.5064 - val_binary_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 610us/step - loss: 0.4068 - binary_accuracy: 0.8056 - val_loss: 0.4814 - val_binary_accuracy: 0.8333\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 596us/step - loss: 0.4101 - binary_accuracy: 0.8095 - val_loss: 0.4731 - val_binary_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 589us/step - loss: 0.4329 - binary_accuracy: 0.8056 - val_loss: 0.4659 - val_binary_accuracy: 0.7778\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 617us/step - loss: 0.3806 - binary_accuracy: 0.8294 - val_loss: 0.4648 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 612us/step - loss: 0.4054 - binary_accuracy: 0.8333 - val_loss: 0.4525 - val_binary_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 592us/step - loss: 0.3461 - binary_accuracy: 0.8492 - val_loss: 0.4319 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 635us/step - loss: 0.3240 - binary_accuracy: 0.8651 - val_loss: 0.4214 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 602us/step - loss: 0.3673 - binary_accuracy: 0.8452 - val_loss: 0.4022 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 605us/step - loss: 0.3215 - binary_accuracy: 0.8690 - val_loss: 0.3934 - val_binary_accuracy: 0.8333\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 602us/step - loss: 0.2857 - binary_accuracy: 0.8651 - val_loss: 0.3716 - val_binary_accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 493us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 31s 121ms/step - loss: 0.8176 - binary_accuracy: 0.6190 - val_loss: 0.7156 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 628us/step - loss: 0.6389 - binary_accuracy: 0.6786 - val_loss: 0.6619 - val_binary_accuracy: 0.5556\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 603us/step - loss: 0.5689 - binary_accuracy: 0.7540 - val_loss: 0.6331 - val_binary_accuracy: 0.5556\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 637us/step - loss: 0.5415 - binary_accuracy: 0.7222 - val_loss: 0.6093 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 640us/step - loss: 0.4526 - binary_accuracy: 0.8095 - val_loss: 0.5902 - val_binary_accuracy: 0.6111\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 604us/step - loss: 0.4201 - binary_accuracy: 0.7897 - val_loss: 0.5463 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 590us/step - loss: 0.4337 - binary_accuracy: 0.8095 - val_loss: 0.5321 - val_binary_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 610us/step - loss: 0.3938 - binary_accuracy: 0.8452 - val_loss: 0.5176 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 607us/step - loss: 0.4254 - binary_accuracy: 0.8175 - val_loss: 0.4928 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 624us/step - loss: 0.4283 - binary_accuracy: 0.8254 - val_loss: 0.4909 - val_binary_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 621us/step - loss: 0.3493 - binary_accuracy: 0.8532 - val_loss: 0.4810 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 612us/step - loss: 0.3681 - binary_accuracy: 0.8333 - val_loss: 0.4634 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 601us/step - loss: 0.4061 - binary_accuracy: 0.8095 - val_loss: 0.4569 - val_binary_accuracy: 0.7778\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 627us/step - loss: 0.3474 - binary_accuracy: 0.8611 - val_loss: 0.4605 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 612us/step - loss: 0.3211 - binary_accuracy: 0.8492 - val_loss: 0.4478 - val_binary_accuracy: 0.7778\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 612us/step - loss: 0.3753 - binary_accuracy: 0.8492 - val_loss: 0.4237 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 594us/step - loss: 0.3724 - binary_accuracy: 0.8333 - val_loss: 0.3999 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 586us/step - loss: 0.3390 - binary_accuracy: 0.8413 - val_loss: 0.3852 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 633us/step - loss: 0.2980 - binary_accuracy: 0.8770 - val_loss: 0.3814 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 628us/step - loss: 0.3782 - binary_accuracy: 0.8373 - val_loss: 0.3721 - val_binary_accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 512us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 31s 124ms/step - loss: 0.9722 - binary_accuracy: 0.4008 - val_loss: 0.5888 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 627us/step - loss: 0.6916 - binary_accuracy: 0.6468 - val_loss: 0.5798 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 619us/step - loss: 0.5857 - binary_accuracy: 0.7460 - val_loss: 0.5683 - val_binary_accuracy: 0.6111\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 624us/step - loss: 0.5238 - binary_accuracy: 0.7619 - val_loss: 0.5741 - val_binary_accuracy: 0.6111\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 643us/step - loss: 0.5013 - binary_accuracy: 0.7937 - val_loss: 0.5729 - val_binary_accuracy: 0.6111\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 647us/step - loss: 0.4882 - binary_accuracy: 0.7738 - val_loss: 0.5662 - val_binary_accuracy: 0.6111\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 634us/step - loss: 0.4626 - binary_accuracy: 0.7857 - val_loss: 0.5447 - val_binary_accuracy: 0.6111\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 620us/step - loss: 0.4623 - binary_accuracy: 0.7937 - val_loss: 0.5011 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 607us/step - loss: 0.4188 - binary_accuracy: 0.8135 - val_loss: 0.4668 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 597us/step - loss: 0.4457 - binary_accuracy: 0.7937 - val_loss: 0.4651 - val_binary_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 634us/step - loss: 0.3710 - binary_accuracy: 0.8492 - val_loss: 0.4782 - val_binary_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 631us/step - loss: 0.3994 - binary_accuracy: 0.8254 - val_loss: 0.4830 - val_binary_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 631us/step - loss: 0.3453 - binary_accuracy: 0.8571 - val_loss: 0.4752 - val_binary_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 640us/step - loss: 0.3936 - binary_accuracy: 0.8452 - val_loss: 0.4832 - val_binary_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 659us/step - loss: 0.3952 - binary_accuracy: 0.8175 - val_loss: 0.4639 - val_binary_accuracy: 0.7222\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 615us/step - loss: 0.3840 - binary_accuracy: 0.8492 - val_loss: 0.4553 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 601us/step - loss: 0.3763 - binary_accuracy: 0.8333 - val_loss: 0.4706 - val_binary_accuracy: 0.7222\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 664us/step - loss: 0.3611 - binary_accuracy: 0.8254 - val_loss: 0.4744 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 657us/step - loss: 0.3779 - binary_accuracy: 0.8413 - val_loss: 0.4471 - val_binary_accuracy: 0.7222\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 634us/step - loss: 0.3266 - binary_accuracy: 0.8849 - val_loss: 0.4309 - val_binary_accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 447us/step\n",
      "\n",
      "Fold  5\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 32s 127ms/step - loss: 0.7381 - binary_accuracy: 0.5992 - val_loss: 0.6732 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 625us/step - loss: 0.6306 - binary_accuracy: 0.7222 - val_loss: 0.4546 - val_binary_accuracy: 0.8333\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 614us/step - loss: 0.5733 - binary_accuracy: 0.7103 - val_loss: 0.3314 - val_binary_accuracy: 0.8333\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 635us/step - loss: 0.4936 - binary_accuracy: 0.7937 - val_loss: 0.2792 - val_binary_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 623us/step - loss: 0.4812 - binary_accuracy: 0.8135 - val_loss: 0.2540 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 627us/step - loss: 0.4833 - binary_accuracy: 0.7897 - val_loss: 0.2415 - val_binary_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 621us/step - loss: 0.5069 - binary_accuracy: 0.8016 - val_loss: 0.2262 - val_binary_accuracy: 0.9444\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 630us/step - loss: 0.4494 - binary_accuracy: 0.8214 - val_loss: 0.2230 - val_binary_accuracy: 0.9444\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 648us/step - loss: 0.4041 - binary_accuracy: 0.8452 - val_loss: 0.2175 - val_binary_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 614us/step - loss: 0.4621 - binary_accuracy: 0.8175 - val_loss: 0.2229 - val_binary_accuracy: 0.9444\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 630us/step - loss: 0.3799 - binary_accuracy: 0.8373 - val_loss: 0.2176 - val_binary_accuracy: 0.9444\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 612us/step - loss: 0.3847 - binary_accuracy: 0.8532 - val_loss: 0.2162 - val_binary_accuracy: 0.9444\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 591us/step - loss: 0.3749 - binary_accuracy: 0.8532 - val_loss: 0.2131 - val_binary_accuracy: 0.9444\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 616us/step - loss: 0.3914 - binary_accuracy: 0.8294 - val_loss: 0.2162 - val_binary_accuracy: 0.9444\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 609us/step - loss: 0.3933 - binary_accuracy: 0.8492 - val_loss: 0.2019 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 619us/step - loss: 0.3374 - binary_accuracy: 0.8651 - val_loss: 0.1871 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 617us/step - loss: 0.2968 - binary_accuracy: 0.8730 - val_loss: 0.1788 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 616us/step - loss: 0.3221 - binary_accuracy: 0.8532 - val_loss: 0.1764 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 643us/step - loss: 0.3514 - binary_accuracy: 0.8452 - val_loss: 0.1715 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 652us/step - loss: 0.3154 - binary_accuracy: 0.8651 - val_loss: 0.1869 - val_binary_accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 461us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 34s 134ms/step - loss: 0.8902 - binary_accuracy: 0.4921 - val_loss: 0.6398 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 658us/step - loss: 0.6402 - binary_accuracy: 0.6865 - val_loss: 0.4942 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 686us/step - loss: 0.5453 - binary_accuracy: 0.7183 - val_loss: 0.4112 - val_binary_accuracy: 0.8889\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 642us/step - loss: 0.4971 - binary_accuracy: 0.7937 - val_loss: 0.3607 - val_binary_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 611us/step - loss: 0.4562 - binary_accuracy: 0.8056 - val_loss: 0.3363 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 634us/step - loss: 0.4644 - binary_accuracy: 0.7698 - val_loss: 0.3144 - val_binary_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 624us/step - loss: 0.4250 - binary_accuracy: 0.8254 - val_loss: 0.3024 - val_binary_accuracy: 0.9444\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 652us/step - loss: 0.4159 - binary_accuracy: 0.8333 - val_loss: 0.2953 - val_binary_accuracy: 0.9444\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 644us/step - loss: 0.4004 - binary_accuracy: 0.8056 - val_loss: 0.2836 - val_binary_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 621us/step - loss: 0.4202 - binary_accuracy: 0.8214 - val_loss: 0.2701 - val_binary_accuracy: 0.9444\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 623us/step - loss: 0.3865 - binary_accuracy: 0.8333 - val_loss: 0.2475 - val_binary_accuracy: 0.9444\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 639us/step - loss: 0.3817 - binary_accuracy: 0.8135 - val_loss: 0.2323 - val_binary_accuracy: 0.9444\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 631us/step - loss: 0.3668 - binary_accuracy: 0.8294 - val_loss: 0.2220 - val_binary_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 645us/step - loss: 0.3477 - binary_accuracy: 0.8849 - val_loss: 0.2149 - val_binary_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 643us/step - loss: 0.3480 - binary_accuracy: 0.8690 - val_loss: 0.2056 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 639us/step - loss: 0.3721 - binary_accuracy: 0.8611 - val_loss: 0.1957 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 668us/step - loss: 0.3558 - binary_accuracy: 0.8532 - val_loss: 0.1890 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 650us/step - loss: 0.3401 - binary_accuracy: 0.8810 - val_loss: 0.1770 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 625us/step - loss: 0.3295 - binary_accuracy: 0.8413 - val_loss: 0.1615 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 685us/step - loss: 0.2976 - binary_accuracy: 0.8849 - val_loss: 0.1544 - val_binary_accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 536us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 34s 137ms/step - loss: 0.9244 - binary_accuracy: 0.4722 - val_loss: 0.5939 - val_binary_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 656us/step - loss: 0.7060 - binary_accuracy: 0.6548 - val_loss: 0.3299 - val_binary_accuracy: 0.8889\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 623us/step - loss: 0.5752 - binary_accuracy: 0.6984 - val_loss: 0.2619 - val_binary_accuracy: 0.9444\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 644us/step - loss: 0.5174 - binary_accuracy: 0.7421 - val_loss: 0.2463 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 676us/step - loss: 0.4896 - binary_accuracy: 0.7659 - val_loss: 0.2415 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 619us/step - loss: 0.4637 - binary_accuracy: 0.7976 - val_loss: 0.2398 - val_binary_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 642us/step - loss: 0.4434 - binary_accuracy: 0.7937 - val_loss: 0.2400 - val_binary_accuracy: 0.9444\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 641us/step - loss: 0.4064 - binary_accuracy: 0.8056 - val_loss: 0.2307 - val_binary_accuracy: 0.9444\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 630us/step - loss: 0.4116 - binary_accuracy: 0.7897 - val_loss: 0.2213 - val_binary_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 621us/step - loss: 0.4667 - binary_accuracy: 0.7857 - val_loss: 0.2078 - val_binary_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 653us/step - loss: 0.3713 - binary_accuracy: 0.8095 - val_loss: 0.1999 - val_binary_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 665us/step - loss: 0.4071 - binary_accuracy: 0.8016 - val_loss: 0.1966 - val_binary_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 628us/step - loss: 0.3733 - binary_accuracy: 0.8532 - val_loss: 0.1934 - val_binary_accuracy: 0.9444\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 622us/step - loss: 0.3325 - binary_accuracy: 0.8611 - val_loss: 0.1865 - val_binary_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 638us/step - loss: 0.4094 - binary_accuracy: 0.8214 - val_loss: 0.1818 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 623us/step - loss: 0.3620 - binary_accuracy: 0.8492 - val_loss: 0.1750 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 626us/step - loss: 0.3202 - binary_accuracy: 0.8571 - val_loss: 0.1635 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 619us/step - loss: 0.3674 - binary_accuracy: 0.8532 - val_loss: 0.1584 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 647us/step - loss: 0.3442 - binary_accuracy: 0.8452 - val_loss: 0.1519 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 635us/step - loss: 0.3363 - binary_accuracy: 0.8492 - val_loss: 0.1475 - val_binary_accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 543us/step\n",
      "\n",
      "Fold  6\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 36s 143ms/step - loss: 0.7945 - binary_accuracy: 0.5952 - val_loss: 0.6076 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 679us/step - loss: 0.6832 - binary_accuracy: 0.6905 - val_loss: 0.4992 - val_binary_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 695us/step - loss: 0.5409 - binary_accuracy: 0.7500 - val_loss: 0.4687 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 697us/step - loss: 0.5228 - binary_accuracy: 0.7698 - val_loss: 0.4214 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 676us/step - loss: 0.4536 - binary_accuracy: 0.7976 - val_loss: 0.3864 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 678us/step - loss: 0.4634 - binary_accuracy: 0.7619 - val_loss: 0.3548 - val_binary_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 666us/step - loss: 0.4409 - binary_accuracy: 0.8333 - val_loss: 0.3421 - val_binary_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 696us/step - loss: 0.4569 - binary_accuracy: 0.8016 - val_loss: 0.3158 - val_binary_accuracy: 0.8333\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 690us/step - loss: 0.3880 - binary_accuracy: 0.8452 - val_loss: 0.2984 - val_binary_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 704us/step - loss: 0.4111 - binary_accuracy: 0.8135 - val_loss: 0.2816 - val_binary_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 673us/step - loss: 0.3793 - binary_accuracy: 0.8333 - val_loss: 0.2713 - val_binary_accuracy: 0.9444\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 678us/step - loss: 0.3890 - binary_accuracy: 0.8135 - val_loss: 0.2568 - val_binary_accuracy: 0.9444\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 689us/step - loss: 0.3868 - binary_accuracy: 0.8214 - val_loss: 0.2515 - val_binary_accuracy: 0.9444\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 695us/step - loss: 0.3660 - binary_accuracy: 0.8135 - val_loss: 0.2478 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 675us/step - loss: 0.4013 - binary_accuracy: 0.8294 - val_loss: 0.2357 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 712us/step - loss: 0.3470 - binary_accuracy: 0.8611 - val_loss: 0.2265 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 689us/step - loss: 0.3518 - binary_accuracy: 0.8651 - val_loss: 0.2291 - val_binary_accuracy: 0.9444\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 685us/step - loss: 0.3524 - binary_accuracy: 0.8532 - val_loss: 0.2292 - val_binary_accuracy: 0.8889\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 681us/step - loss: 0.3290 - binary_accuracy: 0.8730 - val_loss: 0.2239 - val_binary_accuracy: 0.9444\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 685us/step - loss: 0.2904 - binary_accuracy: 0.8770 - val_loss: 0.2158 - val_binary_accuracy: 0.9444\n",
      "18/18 [==============================] - 0s 541us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 38s 151ms/step - loss: 0.9228 - binary_accuracy: 0.4722 - val_loss: 0.7463 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 668us/step - loss: 0.5968 - binary_accuracy: 0.7024 - val_loss: 0.6166 - val_binary_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 651us/step - loss: 0.5853 - binary_accuracy: 0.7063 - val_loss: 0.5823 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 653us/step - loss: 0.4778 - binary_accuracy: 0.7937 - val_loss: 0.5418 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 641us/step - loss: 0.4708 - binary_accuracy: 0.7857 - val_loss: 0.5101 - val_binary_accuracy: 0.7778\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 684us/step - loss: 0.4195 - binary_accuracy: 0.8016 - val_loss: 0.4568 - val_binary_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 677us/step - loss: 0.4424 - binary_accuracy: 0.8135 - val_loss: 0.4287 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 628us/step - loss: 0.4485 - binary_accuracy: 0.8413 - val_loss: 0.4044 - val_binary_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 627us/step - loss: 0.4246 - binary_accuracy: 0.8016 - val_loss: 0.3916 - val_binary_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 673us/step - loss: 0.3781 - binary_accuracy: 0.8413 - val_loss: 0.3795 - val_binary_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 701us/step - loss: 0.3914 - binary_accuracy: 0.8413 - val_loss: 0.3618 - val_binary_accuracy: 0.8333\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 664us/step - loss: 0.3331 - binary_accuracy: 0.8452 - val_loss: 0.3429 - val_binary_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 647us/step - loss: 0.3838 - binary_accuracy: 0.8214 - val_loss: 0.3184 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 680us/step - loss: 0.3657 - binary_accuracy: 0.8452 - val_loss: 0.3059 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 640us/step - loss: 0.3613 - binary_accuracy: 0.8452 - val_loss: 0.2926 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 678us/step - loss: 0.3567 - binary_accuracy: 0.8571 - val_loss: 0.2854 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 689us/step - loss: 0.3559 - binary_accuracy: 0.8532 - val_loss: 0.2708 - val_binary_accuracy: 0.8889\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 689us/step - loss: 0.2961 - binary_accuracy: 0.8730 - val_loss: 0.2466 - val_binary_accuracy: 0.9444\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 662us/step - loss: 0.2863 - binary_accuracy: 0.8929 - val_loss: 0.2353 - val_binary_accuracy: 0.9444\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 669us/step - loss: 0.3293 - binary_accuracy: 0.8333 - val_loss: 0.2184 - val_binary_accuracy: 0.9444\n",
      "18/18 [==============================] - 0s 511us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 41s 163ms/step - loss: 0.7780 - binary_accuracy: 0.5754 - val_loss: 0.6027 - val_binary_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 714us/step - loss: 0.5753 - binary_accuracy: 0.7341 - val_loss: 0.5603 - val_binary_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 693us/step - loss: 0.5183 - binary_accuracy: 0.7778 - val_loss: 0.5189 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 693us/step - loss: 0.4763 - binary_accuracy: 0.7937 - val_loss: 0.4595 - val_binary_accuracy: 0.7778\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 674us/step - loss: 0.4672 - binary_accuracy: 0.8135 - val_loss: 0.4092 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 661us/step - loss: 0.4512 - binary_accuracy: 0.8254 - val_loss: 0.3863 - val_binary_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 652us/step - loss: 0.4527 - binary_accuracy: 0.8056 - val_loss: 0.3750 - val_binary_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 648us/step - loss: 0.4800 - binary_accuracy: 0.8016 - val_loss: 0.3678 - val_binary_accuracy: 0.8333\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 643us/step - loss: 0.4372 - binary_accuracy: 0.8135 - val_loss: 0.3692 - val_binary_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 639us/step - loss: 0.3889 - binary_accuracy: 0.8413 - val_loss: 0.3633 - val_binary_accuracy: 0.8333\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 659us/step - loss: 0.3987 - binary_accuracy: 0.8373 - val_loss: 0.3648 - val_binary_accuracy: 0.8333\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 667us/step - loss: 0.3385 - binary_accuracy: 0.8730 - val_loss: 0.3655 - val_binary_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 679us/step - loss: 0.3846 - binary_accuracy: 0.8452 - val_loss: 0.3530 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 654us/step - loss: 0.3515 - binary_accuracy: 0.8373 - val_loss: 0.3490 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 677us/step - loss: 0.3872 - binary_accuracy: 0.8294 - val_loss: 0.3356 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 663us/step - loss: 0.3683 - binary_accuracy: 0.8532 - val_loss: 0.3189 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 669us/step - loss: 0.3834 - binary_accuracy: 0.8413 - val_loss: 0.3028 - val_binary_accuracy: 0.8889\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 689us/step - loss: 0.2921 - binary_accuracy: 0.8810 - val_loss: 0.2892 - val_binary_accuracy: 0.8889\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 674us/step - loss: 0.3537 - binary_accuracy: 0.8413 - val_loss: 0.2802 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 673us/step - loss: 0.3280 - binary_accuracy: 0.8651 - val_loss: 0.2758 - val_binary_accuracy: 0.8889\n",
      "18/18 [==============================] - 0s 594us/step\n",
      "\n",
      "Fold  7\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 41s 165ms/step - loss: 0.9431 - binary_accuracy: 0.4286 - val_loss: 0.6112 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 680us/step - loss: 0.6209 - binary_accuracy: 0.6825 - val_loss: 0.5400 - val_binary_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 688us/step - loss: 0.5530 - binary_accuracy: 0.7659 - val_loss: 0.5290 - val_binary_accuracy: 0.7778\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 670us/step - loss: 0.4505 - binary_accuracy: 0.8214 - val_loss: 0.5335 - val_binary_accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 657us/step - loss: 0.4576 - binary_accuracy: 0.8056 - val_loss: 0.5363 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 683us/step - loss: 0.4268 - binary_accuracy: 0.8095 - val_loss: 0.5355 - val_binary_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 702us/step - loss: 0.4059 - binary_accuracy: 0.8175 - val_loss: 0.5206 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 684us/step - loss: 0.3938 - binary_accuracy: 0.8254 - val_loss: 0.5102 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 668us/step - loss: 0.4377 - binary_accuracy: 0.8095 - val_loss: 0.5018 - val_binary_accuracy: 0.7222\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 688us/step - loss: 0.3925 - binary_accuracy: 0.8214 - val_loss: 0.4919 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 685us/step - loss: 0.3779 - binary_accuracy: 0.8571 - val_loss: 0.4934 - val_binary_accuracy: 0.7778\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 651us/step - loss: 0.3461 - binary_accuracy: 0.8373 - val_loss: 0.4856 - val_binary_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 688us/step - loss: 0.3473 - binary_accuracy: 0.8611 - val_loss: 0.4712 - val_binary_accuracy: 0.7778\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 712us/step - loss: 0.3340 - binary_accuracy: 0.8532 - val_loss: 0.4565 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 668us/step - loss: 0.3616 - binary_accuracy: 0.8452 - val_loss: 0.4347 - val_binary_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 687us/step - loss: 0.3568 - binary_accuracy: 0.8611 - val_loss: 0.4101 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 692us/step - loss: 0.3576 - binary_accuracy: 0.8532 - val_loss: 0.3959 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 700us/step - loss: 0.3529 - binary_accuracy: 0.8333 - val_loss: 0.3810 - val_binary_accuracy: 0.7778\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 678us/step - loss: 0.3386 - binary_accuracy: 0.8651 - val_loss: 0.3847 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 659us/step - loss: 0.2878 - binary_accuracy: 0.8889 - val_loss: 0.3766 - val_binary_accuracy: 0.7778\n",
      "18/18 [==============================] - 0s 533us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 40s 158ms/step - loss: 0.8226 - binary_accuracy: 0.5516 - val_loss: 0.5575 - val_binary_accuracy: 0.7222\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 693us/step - loss: 0.6328 - binary_accuracy: 0.6786 - val_loss: 0.4400 - val_binary_accuracy: 0.9444\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 706us/step - loss: 0.5322 - binary_accuracy: 0.7381 - val_loss: 0.3944 - val_binary_accuracy: 0.9444\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 702us/step - loss: 0.4897 - binary_accuracy: 0.7817 - val_loss: 0.3540 - val_binary_accuracy: 0.9444\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 701us/step - loss: 0.4713 - binary_accuracy: 0.8016 - val_loss: 0.3445 - val_binary_accuracy: 0.9444\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 671us/step - loss: 0.4398 - binary_accuracy: 0.8214 - val_loss: 0.3547 - val_binary_accuracy: 0.9444\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 689us/step - loss: 0.4534 - binary_accuracy: 0.8214 - val_loss: 0.3675 - val_binary_accuracy: 0.9444\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 675us/step - loss: 0.4208 - binary_accuracy: 0.8373 - val_loss: 0.3871 - val_binary_accuracy: 0.9444\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 644us/step - loss: 0.4155 - binary_accuracy: 0.8175 - val_loss: 0.3855 - val_binary_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 687us/step - loss: 0.4084 - binary_accuracy: 0.8571 - val_loss: 0.3677 - val_binary_accuracy: 0.8889\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 683us/step - loss: 0.4144 - binary_accuracy: 0.7857 - val_loss: 0.3591 - val_binary_accuracy: 0.9444\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 683us/step - loss: 0.3839 - binary_accuracy: 0.8373 - val_loss: 0.3402 - val_binary_accuracy: 0.9444\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 669us/step - loss: 0.3377 - binary_accuracy: 0.8651 - val_loss: 0.3368 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 677us/step - loss: 0.3308 - binary_accuracy: 0.8413 - val_loss: 0.3300 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 714us/step - loss: 0.3458 - binary_accuracy: 0.8730 - val_loss: 0.3304 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 709us/step - loss: 0.3610 - binary_accuracy: 0.8532 - val_loss: 0.3234 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 700us/step - loss: 0.3259 - binary_accuracy: 0.8571 - val_loss: 0.3077 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 725us/step - loss: 0.3271 - binary_accuracy: 0.8571 - val_loss: 0.3014 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 698us/step - loss: 0.3097 - binary_accuracy: 0.8690 - val_loss: 0.2871 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 723us/step - loss: 0.3373 - binary_accuracy: 0.8651 - val_loss: 0.2861 - val_binary_accuracy: 0.8889\n",
      "18/18 [==============================] - 0s 609us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 42s 168ms/step - loss: 0.7327 - binary_accuracy: 0.6111 - val_loss: 0.5300 - val_binary_accuracy: 0.8889\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 701us/step - loss: 0.6389 - binary_accuracy: 0.6865 - val_loss: 0.4341 - val_binary_accuracy: 0.8889\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 705us/step - loss: 0.5197 - binary_accuracy: 0.7897 - val_loss: 0.4266 - val_binary_accuracy: 0.8889\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 675us/step - loss: 0.5102 - binary_accuracy: 0.7857 - val_loss: 0.4263 - val_binary_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 685us/step - loss: 0.4649 - binary_accuracy: 0.8135 - val_loss: 0.4095 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 685us/step - loss: 0.4833 - binary_accuracy: 0.7976 - val_loss: 0.4131 - val_binary_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 642us/step - loss: 0.4362 - binary_accuracy: 0.8135 - val_loss: 0.4260 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 643us/step - loss: 0.4318 - binary_accuracy: 0.8175 - val_loss: 0.4247 - val_binary_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 657us/step - loss: 0.4307 - binary_accuracy: 0.8214 - val_loss: 0.4078 - val_binary_accuracy: 0.7778\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 694us/step - loss: 0.3891 - binary_accuracy: 0.8294 - val_loss: 0.3925 - val_binary_accuracy: 0.7778\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 673us/step - loss: 0.4093 - binary_accuracy: 0.8175 - val_loss: 0.3958 - val_binary_accuracy: 0.7778\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 672us/step - loss: 0.3708 - binary_accuracy: 0.8571 - val_loss: 0.3898 - val_binary_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 666us/step - loss: 0.3950 - binary_accuracy: 0.8373 - val_loss: 0.3763 - val_binary_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 654us/step - loss: 0.4059 - binary_accuracy: 0.8254 - val_loss: 0.3723 - val_binary_accuracy: 0.8333\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 694us/step - loss: 0.3785 - binary_accuracy: 0.8294 - val_loss: 0.3635 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 683us/step - loss: 0.3505 - binary_accuracy: 0.8294 - val_loss: 0.3746 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 652us/step - loss: 0.3637 - binary_accuracy: 0.8730 - val_loss: 0.3706 - val_binary_accuracy: 0.8889\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 664us/step - loss: 0.3297 - binary_accuracy: 0.8571 - val_loss: 0.3572 - val_binary_accuracy: 0.8889\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 662us/step - loss: 0.3122 - binary_accuracy: 0.8651 - val_loss: 0.3534 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 661us/step - loss: 0.3221 - binary_accuracy: 0.8294 - val_loss: 0.3493 - val_binary_accuracy: 0.8889\n",
      "18/18 [==============================] - 0s 587us/step\n",
      "\n",
      "Fold  8\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 43s 170ms/step - loss: 0.9685 - binary_accuracy: 0.5278 - val_loss: 0.6299 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 696us/step - loss: 0.6857 - binary_accuracy: 0.7103 - val_loss: 0.4694 - val_binary_accuracy: 0.7222\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 667us/step - loss: 0.5306 - binary_accuracy: 0.7698 - val_loss: 0.3968 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 681us/step - loss: 0.5592 - binary_accuracy: 0.7540 - val_loss: 0.3381 - val_binary_accuracy: 0.8333\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 715us/step - loss: 0.4644 - binary_accuracy: 0.8135 - val_loss: 0.3063 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 701us/step - loss: 0.4740 - binary_accuracy: 0.8016 - val_loss: 0.2872 - val_binary_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 671us/step - loss: 0.4856 - binary_accuracy: 0.8056 - val_loss: 0.2732 - val_binary_accuracy: 0.8889\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 701us/step - loss: 0.4282 - binary_accuracy: 0.8294 - val_loss: 0.2532 - val_binary_accuracy: 0.8889\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 661us/step - loss: 0.4570 - binary_accuracy: 0.7817 - val_loss: 0.2337 - val_binary_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 694us/step - loss: 0.4160 - binary_accuracy: 0.8413 - val_loss: 0.2288 - val_binary_accuracy: 0.9444\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 697us/step - loss: 0.3845 - binary_accuracy: 0.8294 - val_loss: 0.2236 - val_binary_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 711us/step - loss: 0.3385 - binary_accuracy: 0.8333 - val_loss: 0.2134 - val_binary_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 700us/step - loss: 0.3735 - binary_accuracy: 0.8413 - val_loss: 0.2065 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 680us/step - loss: 0.3583 - binary_accuracy: 0.8413 - val_loss: 0.2056 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 712us/step - loss: 0.3503 - binary_accuracy: 0.8532 - val_loss: 0.2097 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 684us/step - loss: 0.3772 - binary_accuracy: 0.8333 - val_loss: 0.2063 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 672us/step - loss: 0.3194 - binary_accuracy: 0.8730 - val_loss: 0.2022 - val_binary_accuracy: 0.8889\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 709us/step - loss: 0.4065 - binary_accuracy: 0.8254 - val_loss: 0.2017 - val_binary_accuracy: 0.8889\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 729us/step - loss: 0.3953 - binary_accuracy: 0.8254 - val_loss: 0.2012 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 698us/step - loss: 0.3533 - binary_accuracy: 0.8611 - val_loss: 0.2063 - val_binary_accuracy: 0.8889\n",
      "18/18 [==============================] - 0s 611us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 44s 175ms/step - loss: 0.8706 - binary_accuracy: 0.6071 - val_loss: 0.5745 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 671us/step - loss: 0.5840 - binary_accuracy: 0.7341 - val_loss: 0.4037 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 742us/step - loss: 0.4959 - binary_accuracy: 0.7857 - val_loss: 0.3243 - val_binary_accuracy: 0.7778\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 743us/step - loss: 0.4915 - binary_accuracy: 0.7937 - val_loss: 0.2860 - val_binary_accuracy: 0.7778\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 700us/step - loss: 0.4860 - binary_accuracy: 0.7857 - val_loss: 0.2608 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 716us/step - loss: 0.4410 - binary_accuracy: 0.7976 - val_loss: 0.2398 - val_binary_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 750us/step - loss: 0.4236 - binary_accuracy: 0.8016 - val_loss: 0.2245 - val_binary_accuracy: 0.8889\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 714us/step - loss: 0.4198 - binary_accuracy: 0.7976 - val_loss: 0.2170 - val_binary_accuracy: 0.8889\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 728us/step - loss: 0.4061 - binary_accuracy: 0.8254 - val_loss: 0.2187 - val_binary_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 725us/step - loss: 0.3774 - binary_accuracy: 0.8492 - val_loss: 0.2112 - val_binary_accuracy: 0.9444\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 746us/step - loss: 0.3973 - binary_accuracy: 0.8333 - val_loss: 0.2040 - val_binary_accuracy: 0.9444\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 773us/step - loss: 0.3751 - binary_accuracy: 0.8333 - val_loss: 0.2025 - val_binary_accuracy: 0.9444\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 730us/step - loss: 0.3702 - binary_accuracy: 0.8492 - val_loss: 0.1888 - val_binary_accuracy: 0.9444\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 721us/step - loss: 0.3942 - binary_accuracy: 0.8175 - val_loss: 0.1875 - val_binary_accuracy: 0.9444\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 731us/step - loss: 0.3264 - binary_accuracy: 0.8730 - val_loss: 0.1794 - val_binary_accuracy: 0.9444\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 746us/step - loss: 0.3367 - binary_accuracy: 0.8214 - val_loss: 0.1627 - val_binary_accuracy: 0.9444\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 748us/step - loss: 0.3324 - binary_accuracy: 0.8690 - val_loss: 0.1566 - val_binary_accuracy: 0.9444\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 716us/step - loss: 0.3192 - binary_accuracy: 0.8294 - val_loss: 0.1544 - val_binary_accuracy: 0.9444\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 711us/step - loss: 0.2978 - binary_accuracy: 0.8690 - val_loss: 0.1475 - val_binary_accuracy: 0.9444\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 746us/step - loss: 0.3380 - binary_accuracy: 0.8373 - val_loss: 0.1416 - val_binary_accuracy: 1.0000\n",
      "18/18 [==============================] - 0s 601us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 46s 183ms/step - loss: 0.9134 - binary_accuracy: 0.5079 - val_loss: 0.6433 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 709us/step - loss: 0.5899 - binary_accuracy: 0.7460 - val_loss: 0.5704 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 683us/step - loss: 0.5735 - binary_accuracy: 0.7579 - val_loss: 0.4895 - val_binary_accuracy: 0.8333\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 696us/step - loss: 0.5545 - binary_accuracy: 0.7500 - val_loss: 0.3716 - val_binary_accuracy: 0.8889\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 703us/step - loss: 0.4971 - binary_accuracy: 0.7857 - val_loss: 0.3074 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 671us/step - loss: 0.4346 - binary_accuracy: 0.8254 - val_loss: 0.2486 - val_binary_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 668us/step - loss: 0.4720 - binary_accuracy: 0.7976 - val_loss: 0.2235 - val_binary_accuracy: 0.8889\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 672us/step - loss: 0.3809 - binary_accuracy: 0.8452 - val_loss: 0.2025 - val_binary_accuracy: 0.9444\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 670us/step - loss: 0.3969 - binary_accuracy: 0.8452 - val_loss: 0.2044 - val_binary_accuracy: 0.9444\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 674us/step - loss: 0.4017 - binary_accuracy: 0.8413 - val_loss: 0.2231 - val_binary_accuracy: 0.8889\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 686us/step - loss: 0.3825 - binary_accuracy: 0.8413 - val_loss: 0.2250 - val_binary_accuracy: 0.8889\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 697us/step - loss: 0.3441 - binary_accuracy: 0.8690 - val_loss: 0.2281 - val_binary_accuracy: 0.8889\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 675us/step - loss: 0.3530 - binary_accuracy: 0.8214 - val_loss: 0.2288 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 667us/step - loss: 0.3616 - binary_accuracy: 0.8611 - val_loss: 0.2181 - val_binary_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 681us/step - loss: 0.3362 - binary_accuracy: 0.8571 - val_loss: 0.2053 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 670us/step - loss: 0.3655 - binary_accuracy: 0.8452 - val_loss: 0.1992 - val_binary_accuracy: 0.9444\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 672us/step - loss: 0.3433 - binary_accuracy: 0.8373 - val_loss: 0.1913 - val_binary_accuracy: 0.9444\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 662us/step - loss: 0.3459 - binary_accuracy: 0.8492 - val_loss: 0.1827 - val_binary_accuracy: 0.9444\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 673us/step - loss: 0.3313 - binary_accuracy: 0.8571 - val_loss: 0.1814 - val_binary_accuracy: 0.9444\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 668us/step - loss: 0.3110 - binary_accuracy: 0.8929 - val_loss: 0.1813 - val_binary_accuracy: 0.9444\n",
      "18/18 [==============================] - 0s 538us/step\n",
      "\n",
      "Fold  9\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 47s 185ms/step - loss: 0.6939 - binary_accuracy: 0.6508 - val_loss: 0.7515 - val_binary_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 746us/step - loss: 0.5842 - binary_accuracy: 0.7183 - val_loss: 0.6786 - val_binary_accuracy: 0.5556\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 718us/step - loss: 0.5501 - binary_accuracy: 0.7540 - val_loss: 0.6320 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 711us/step - loss: 0.4968 - binary_accuracy: 0.7817 - val_loss: 0.6061 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 701us/step - loss: 0.4402 - binary_accuracy: 0.7937 - val_loss: 0.5944 - val_binary_accuracy: 0.7778\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 727us/step - loss: 0.5093 - binary_accuracy: 0.7897 - val_loss: 0.5823 - val_binary_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 717us/step - loss: 0.4708 - binary_accuracy: 0.7897 - val_loss: 0.5764 - val_binary_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 750us/step - loss: 0.4035 - binary_accuracy: 0.8135 - val_loss: 0.5577 - val_binary_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 710us/step - loss: 0.3883 - binary_accuracy: 0.8373 - val_loss: 0.5253 - val_binary_accuracy: 0.7778\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 776us/step - loss: 0.4440 - binary_accuracy: 0.7857 - val_loss: 0.4946 - val_binary_accuracy: 0.7778\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 727us/step - loss: 0.4084 - binary_accuracy: 0.8056 - val_loss: 0.5063 - val_binary_accuracy: 0.7778\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 736us/step - loss: 0.3569 - binary_accuracy: 0.8730 - val_loss: 0.5058 - val_binary_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 719us/step - loss: 0.3954 - binary_accuracy: 0.8095 - val_loss: 0.4991 - val_binary_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 748us/step - loss: 0.4123 - binary_accuracy: 0.8016 - val_loss: 0.5019 - val_binary_accuracy: 0.8333\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 716us/step - loss: 0.3669 - binary_accuracy: 0.8492 - val_loss: 0.4979 - val_binary_accuracy: 0.7778\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 756us/step - loss: 0.3611 - binary_accuracy: 0.8333 - val_loss: 0.4841 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 723us/step - loss: 0.3848 - binary_accuracy: 0.8492 - val_loss: 0.4653 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 727us/step - loss: 0.3665 - binary_accuracy: 0.8214 - val_loss: 0.4482 - val_binary_accuracy: 0.7778\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 763us/step - loss: 0.3505 - binary_accuracy: 0.8651 - val_loss: 0.4529 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 727us/step - loss: 0.2919 - binary_accuracy: 0.8929 - val_loss: 0.4501 - val_binary_accuracy: 0.7778\n",
      "18/18 [==============================] - 0s 546us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 48s 190ms/step - loss: 0.6809 - binary_accuracy: 0.6468 - val_loss: 0.6280 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 757us/step - loss: 0.6220 - binary_accuracy: 0.7103 - val_loss: 0.5999 - val_binary_accuracy: 0.5556\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 741us/step - loss: 0.5437 - binary_accuracy: 0.7183 - val_loss: 0.5684 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 761us/step - loss: 0.4917 - binary_accuracy: 0.7698 - val_loss: 0.5312 - val_binary_accuracy: 0.7778\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 747us/step - loss: 0.4436 - binary_accuracy: 0.7857 - val_loss: 0.5074 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 749us/step - loss: 0.4786 - binary_accuracy: 0.8056 - val_loss: 0.4947 - val_binary_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 736us/step - loss: 0.4457 - binary_accuracy: 0.7976 - val_loss: 0.4925 - val_binary_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 748us/step - loss: 0.4339 - binary_accuracy: 0.7897 - val_loss: 0.4605 - val_binary_accuracy: 0.8333\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 755us/step - loss: 0.4248 - binary_accuracy: 0.8135 - val_loss: 0.4474 - val_binary_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 758us/step - loss: 0.3912 - binary_accuracy: 0.8373 - val_loss: 0.4396 - val_binary_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 737us/step - loss: 0.3815 - binary_accuracy: 0.8294 - val_loss: 0.4504 - val_binary_accuracy: 0.8333\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 760us/step - loss: 0.3688 - binary_accuracy: 0.8333 - val_loss: 0.4557 - val_binary_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 745us/step - loss: 0.3851 - binary_accuracy: 0.8214 - val_loss: 0.4450 - val_binary_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 747us/step - loss: 0.3870 - binary_accuracy: 0.8373 - val_loss: 0.4384 - val_binary_accuracy: 0.8333\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 753us/step - loss: 0.3918 - binary_accuracy: 0.8413 - val_loss: 0.4195 - val_binary_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 746us/step - loss: 0.3307 - binary_accuracy: 0.8492 - val_loss: 0.4111 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 734us/step - loss: 0.3419 - binary_accuracy: 0.8651 - val_loss: 0.3893 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 742us/step - loss: 0.3102 - binary_accuracy: 0.8651 - val_loss: 0.3767 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 740us/step - loss: 0.3159 - binary_accuracy: 0.8889 - val_loss: 0.3754 - val_binary_accuracy: 0.8333\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 769us/step - loss: 0.2740 - binary_accuracy: 0.9048 - val_loss: 0.3589 - val_binary_accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 668us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 50s 200ms/step - loss: 0.8982 - binary_accuracy: 0.5238 - val_loss: 0.9026 - val_binary_accuracy: 0.5556\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 758us/step - loss: 0.7896 - binary_accuracy: 0.6389 - val_loss: 0.7612 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 743us/step - loss: 0.5613 - binary_accuracy: 0.7341 - val_loss: 0.6805 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 751us/step - loss: 0.4984 - binary_accuracy: 0.7857 - val_loss: 0.6256 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 745us/step - loss: 0.4813 - binary_accuracy: 0.7698 - val_loss: 0.5743 - val_binary_accuracy: 0.7222\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 756us/step - loss: 0.4529 - binary_accuracy: 0.8135 - val_loss: 0.5227 - val_binary_accuracy: 0.7222\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 745us/step - loss: 0.4757 - binary_accuracy: 0.7937 - val_loss: 0.4573 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 750us/step - loss: 0.4493 - binary_accuracy: 0.8095 - val_loss: 0.4368 - val_binary_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 790us/step - loss: 0.3981 - binary_accuracy: 0.8452 - val_loss: 0.4335 - val_binary_accuracy: 0.7778\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 783us/step - loss: 0.4224 - binary_accuracy: 0.8095 - val_loss: 0.4225 - val_binary_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 764us/step - loss: 0.3631 - binary_accuracy: 0.8532 - val_loss: 0.4134 - val_binary_accuracy: 0.8333\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 747us/step - loss: 0.3944 - binary_accuracy: 0.8294 - val_loss: 0.4064 - val_binary_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 811us/step - loss: 0.3863 - binary_accuracy: 0.8611 - val_loss: 0.3998 - val_binary_accuracy: 0.7778\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 756us/step - loss: 0.3982 - binary_accuracy: 0.8492 - val_loss: 0.3817 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 761us/step - loss: 0.3841 - binary_accuracy: 0.8492 - val_loss: 0.3716 - val_binary_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 730us/step - loss: 0.3630 - binary_accuracy: 0.8413 - val_loss: 0.3547 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 733us/step - loss: 0.3557 - binary_accuracy: 0.8492 - val_loss: 0.3582 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 768us/step - loss: 0.3247 - binary_accuracy: 0.8611 - val_loss: 0.3613 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 720us/step - loss: 0.3668 - binary_accuracy: 0.8333 - val_loss: 0.3633 - val_binary_accuracy: 0.8333\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 714us/step - loss: 0.3687 - binary_accuracy: 0.8413 - val_loss: 0.3436 - val_binary_accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 733us/step\n",
      "\n",
      "Fold  10\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 52s 205ms/step - loss: 0.7218 - binary_accuracy: 0.7143 - val_loss: 0.4997 - val_binary_accuracy: 0.8333\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 751us/step - loss: 0.6197 - binary_accuracy: 0.7500 - val_loss: 0.4746 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 738us/step - loss: 0.5506 - binary_accuracy: 0.7659 - val_loss: 0.4932 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 754us/step - loss: 0.5259 - binary_accuracy: 0.7817 - val_loss: 0.5404 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 814us/step - loss: 0.4446 - binary_accuracy: 0.7976 - val_loss: 0.5537 - val_binary_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 753us/step - loss: 0.4245 - binary_accuracy: 0.8016 - val_loss: 0.5381 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 751us/step - loss: 0.4212 - binary_accuracy: 0.8175 - val_loss: 0.5093 - val_binary_accuracy: 0.7222\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 750us/step - loss: 0.4505 - binary_accuracy: 0.8056 - val_loss: 0.4779 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 740us/step - loss: 0.4027 - binary_accuracy: 0.8333 - val_loss: 0.4590 - val_binary_accuracy: 0.7222\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 784us/step - loss: 0.3878 - binary_accuracy: 0.8373 - val_loss: 0.4494 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 780us/step - loss: 0.4282 - binary_accuracy: 0.8175 - val_loss: 0.4329 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 742us/step - loss: 0.3763 - binary_accuracy: 0.8532 - val_loss: 0.4235 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 773us/step - loss: 0.3911 - binary_accuracy: 0.8294 - val_loss: 0.4228 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 749us/step - loss: 0.3574 - binary_accuracy: 0.8294 - val_loss: 0.4115 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 749us/step - loss: 0.4208 - binary_accuracy: 0.8175 - val_loss: 0.4127 - val_binary_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 744us/step - loss: 0.3201 - binary_accuracy: 0.8611 - val_loss: 0.4117 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 760us/step - loss: 0.3654 - binary_accuracy: 0.8413 - val_loss: 0.4087 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 748us/step - loss: 0.3374 - binary_accuracy: 0.8571 - val_loss: 0.3971 - val_binary_accuracy: 0.7778\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 774us/step - loss: 0.3135 - binary_accuracy: 0.8492 - val_loss: 0.4044 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 768us/step - loss: 0.3413 - binary_accuracy: 0.8770 - val_loss: 0.4119 - val_binary_accuracy: 0.7778\n",
      "18/18 [==============================] - 0s 766us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 52s 205ms/step - loss: 0.8171 - binary_accuracy: 0.5794 - val_loss: 0.5833 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 741us/step - loss: 0.6850 - binary_accuracy: 0.6548 - val_loss: 0.5700 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 736us/step - loss: 0.5664 - binary_accuracy: 0.7341 - val_loss: 0.5557 - val_binary_accuracy: 0.5556\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 717us/step - loss: 0.5139 - binary_accuracy: 0.8095 - val_loss: 0.5513 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 709us/step - loss: 0.5148 - binary_accuracy: 0.7817 - val_loss: 0.5355 - val_binary_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 737us/step - loss: 0.4704 - binary_accuracy: 0.7976 - val_loss: 0.5215 - val_binary_accuracy: 0.7222\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 711us/step - loss: 0.4556 - binary_accuracy: 0.7897 - val_loss: 0.5139 - val_binary_accuracy: 0.7222\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 713us/step - loss: 0.4840 - binary_accuracy: 0.7778 - val_loss: 0.4930 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 702us/step - loss: 0.4388 - binary_accuracy: 0.8175 - val_loss: 0.4721 - val_binary_accuracy: 0.7778\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 746us/step - loss: 0.4198 - binary_accuracy: 0.8056 - val_loss: 0.4452 - val_binary_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 720us/step - loss: 0.4310 - binary_accuracy: 0.8016 - val_loss: 0.4299 - val_binary_accuracy: 0.8333\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 697us/step - loss: 0.4023 - binary_accuracy: 0.8175 - val_loss: 0.4030 - val_binary_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 733us/step - loss: 0.3670 - binary_accuracy: 0.8452 - val_loss: 0.3947 - val_binary_accuracy: 0.7778\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 796us/step - loss: 0.4151 - binary_accuracy: 0.7976 - val_loss: 0.3931 - val_binary_accuracy: 0.8333\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 715us/step - loss: 0.3750 - binary_accuracy: 0.8571 - val_loss: 0.3926 - val_binary_accuracy: 0.7778\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 741us/step - loss: 0.3650 - binary_accuracy: 0.8651 - val_loss: 0.3986 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 754us/step - loss: 0.3872 - binary_accuracy: 0.8571 - val_loss: 0.3964 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 753us/step - loss: 0.3543 - binary_accuracy: 0.8532 - val_loss: 0.3852 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 779us/step - loss: 0.3316 - binary_accuracy: 0.8452 - val_loss: 0.3771 - val_binary_accuracy: 0.8333\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 736us/step - loss: 0.3260 - binary_accuracy: 0.8690 - val_loss: 0.3542 - val_binary_accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 674us/step\n",
      "Train on 252 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "252/252 [==============================] - 57s 226ms/step - loss: 0.8229 - binary_accuracy: 0.5556 - val_loss: 0.6223 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/20\n",
      "252/252 [==============================] - 0s 810us/step - loss: 0.6515 - binary_accuracy: 0.6944 - val_loss: 0.5622 - val_binary_accuracy: 0.6111\n",
      "Epoch 3/20\n",
      "252/252 [==============================] - 0s 774us/step - loss: 0.5899 - binary_accuracy: 0.7619 - val_loss: 0.5721 - val_binary_accuracy: 0.6111\n",
      "Epoch 4/20\n",
      "252/252 [==============================] - 0s 788us/step - loss: 0.5164 - binary_accuracy: 0.7897 - val_loss: 0.5795 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/20\n",
      "252/252 [==============================] - 0s 771us/step - loss: 0.4760 - binary_accuracy: 0.7897 - val_loss: 0.5799 - val_binary_accuracy: 0.6111\n",
      "Epoch 6/20\n",
      "252/252 [==============================] - 0s 759us/step - loss: 0.4480 - binary_accuracy: 0.8254 - val_loss: 0.5907 - val_binary_accuracy: 0.6111\n",
      "Epoch 7/20\n",
      "252/252 [==============================] - 0s 762us/step - loss: 0.4712 - binary_accuracy: 0.8095 - val_loss: 0.5716 - val_binary_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "252/252 [==============================] - 0s 795us/step - loss: 0.4964 - binary_accuracy: 0.7937 - val_loss: 0.5293 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "252/252 [==============================] - 0s 781us/step - loss: 0.4157 - binary_accuracy: 0.8016 - val_loss: 0.5205 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "252/252 [==============================] - 0s 767us/step - loss: 0.3985 - binary_accuracy: 0.8333 - val_loss: 0.5018 - val_binary_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "252/252 [==============================] - 0s 768us/step - loss: 0.4464 - binary_accuracy: 0.7857 - val_loss: 0.4879 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "252/252 [==============================] - 0s 759us/step - loss: 0.3660 - binary_accuracy: 0.8571 - val_loss: 0.4597 - val_binary_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "252/252 [==============================] - 0s 785us/step - loss: 0.4364 - binary_accuracy: 0.8333 - val_loss: 0.4334 - val_binary_accuracy: 0.8333\n",
      "Epoch 14/20\n",
      "252/252 [==============================] - 0s 826us/step - loss: 0.3888 - binary_accuracy: 0.8373 - val_loss: 0.4069 - val_binary_accuracy: 0.8333\n",
      "Epoch 15/20\n",
      "252/252 [==============================] - 0s 793us/step - loss: 0.3429 - binary_accuracy: 0.8373 - val_loss: 0.3988 - val_binary_accuracy: 0.7778\n",
      "Epoch 16/20\n",
      "252/252 [==============================] - 0s 804us/step - loss: 0.3496 - binary_accuracy: 0.8651 - val_loss: 0.3865 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "252/252 [==============================] - 0s 803us/step - loss: 0.3616 - binary_accuracy: 0.8611 - val_loss: 0.3815 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/20\n",
      "252/252 [==============================] - 0s 798us/step - loss: 0.3613 - binary_accuracy: 0.8651 - val_loss: 0.3776 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/20\n",
      "252/252 [==============================] - 0s 803us/step - loss: 0.3230 - binary_accuracy: 0.8611 - val_loss: 0.3662 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "252/252 [==============================] - 0s 772us/step - loss: 0.3035 - binary_accuracy: 0.8730 - val_loss: 0.3609 - val_binary_accuracy: 0.7222\n",
      "18/18 [==============================] - 0s 758us/step\n",
      "Mean loss: 0.3217837651570638\n",
      "Mean val_pred: 0.8666666607062022\n",
      "Mean pred: [0.41034813 0.10681037 0.97834922 0.29263243 0.9827021  0.14690767\n",
      " 0.80595184 0.99317165 0.13300972 0.24177785 0.7097801  0.70386635\n",
      " 0.10586856 0.98307906 0.09736705 0.20354109 0.13605277 0.12568479\n",
      " 0.99409736 0.13864687 0.97920821 0.26563346 0.33854739 0.09068589\n",
      " 0.35858971 0.9805508  0.38280207 0.4669187  0.92978163 0.12649552\n",
      " 0.87878219 0.36020085 0.52187751 0.80006055 0.18127779 0.17631173\n",
      " 0.27517672 0.11687843 0.30254266 0.34994437 0.88822326 0.09905552\n",
      " 0.97826959 0.21503927 0.61652023 0.14321505 0.1555639  0.25504623\n",
      " 0.24102856 0.99207331 0.68089202 0.23608101 0.99773418 0.08842624\n",
      " 0.27015339 0.07615001 0.95825435 0.58811706 0.33291635 0.32752975\n",
      " 0.19281745 0.96820142 0.07316927 0.99694997 0.12197319 0.88256614\n",
      " 0.8486757  0.30849302 0.53648065 0.48536959 0.097496   0.99658132\n",
      " 0.97881802 0.99275203 0.9894947  0.9707222  0.91733229 0.95811789\n",
      " 0.40793582 0.12830221 0.24579103 0.47783996 0.34565193 0.5846588\n",
      " 0.278162   0.26468009 0.8994511  0.4584169  0.20696907 0.155216  ]\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "K = 10\n",
    "runs_per_fold = 3\n",
    "loss_list=[]\n",
    "acc_list=[]\n",
    "val_pred_list = np.zeros((np.shape(x_test)[0],K))\n",
    "pred_list = np.zeros((np.shape(x_test)[0],K))\n",
    "\n",
    "x_test_f = preproc_input(x_test)\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = K, \n",
    "                            random_state = 1, \n",
    "                            shuffle = True)  \n",
    "for i, (train_idxs, val_indxs) in enumerate(kfold.split(x_train.values, y_train.values)):\n",
    "    print('\\nFold ', i + 1)\n",
    "    x_train_f = x_train.loc[train_idxs]\n",
    "    y_train_f = y_train.loc[train_idxs]\n",
    "\n",
    "    x_val_f = x_train.loc[val_indxs]\n",
    "    y_val_f = y_train.loc[val_indxs]\n",
    "    \n",
    "    # Upsampling\n",
    "    # Add positive samples\n",
    "    \n",
    "    positive_samples = y_train_f.query('heart_disease_present==True')\n",
    "    positive_samples = pd.Series(positive_samples['heart_disease_present'])\n",
    "\n",
    "    x_train_f = pd.concat([x_train, x_train.loc[positive_samples]], axis=0)\n",
    "    y_train_f = pd.concat([y_train, y_train.loc[positive_samples]], axis=0)\n",
    "    \n",
    "    # Shuffle data\n",
    "    idx = np.arange(len(x_train_f))\n",
    "    np.random.shuffle(idx)\n",
    "    x_train_f = x_train_f.iloc[idx]\n",
    "    y_train_f = y_train_f.iloc[idx]\n",
    "    \n",
    "    x_train_f = preproc_input(x_train_f)\n",
    "    x_val_f = preproc_input(x_val_f)\n",
    "    \n",
    "    for j in range(runs_per_fold):\n",
    "        model = create_model()\n",
    "        model.fit(\n",
    "            x_train_f,\n",
    "            y_train_f.values,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(x_val_f, y_val_f),\n",
    "            verbose=1,\n",
    "        )\n",
    "        model_eval = model.evaluate(x_val_f, y_val_f)\n",
    "        loss_list.append(model_eval[0])\n",
    "        val_pred_list[:, i] += model_eval[1] / runs_per_fold\n",
    "        pred_list[:, i] += model.predict(x_test_f)[:,0] / runs_per_fold\n",
    "\n",
    "mean_loss = np.mean(loss_list)\n",
    "mean_val_pred = np.mean(val_pred_list)\n",
    "mean_pred = np.mean(pred_list, axis = 1)\n",
    "print(\"Mean loss: {}\".format(mean_loss))\n",
    "print(\"Mean val_pred: {}\".format(mean_val_pred))\n",
    "print(\"Mean pred: {}\".format(mean_pred))\n",
    "\n",
    "## Save model and weights\n",
    "# save_dir=os.path.join(os.getcwd(), 'saved_models')\n",
    "# model_name= '{}.h5'.format(exp_stamp)\n",
    "# if not os.path.isdir(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "# model_path = os.path.join(save_dir, model_name)\n",
    "# model.save(model_path)\n",
    "# print('Saved  trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>heart_disease_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olalu7</td>\n",
       "      <td>0.410348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z9n6mx</td>\n",
       "      <td>0.106810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5k4413</td>\n",
       "      <td>0.978349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrg7q5</td>\n",
       "      <td>0.292632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uki4do</td>\n",
       "      <td>0.982702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kev1sk</td>\n",
       "      <td>0.146908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9n6let</td>\n",
       "      <td>0.805952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jxmtyg</td>\n",
       "      <td>0.993172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>51s2ff</td>\n",
       "      <td>0.133010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wi9mcs</td>\n",
       "      <td>0.241778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>741h4l</td>\n",
       "      <td>0.709780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1ef64a</td>\n",
       "      <td>0.703866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wa2ix6</td>\n",
       "      <td>0.105869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8167zl</td>\n",
       "      <td>0.983079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n6nldr</td>\n",
       "      <td>0.097367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ph85fp</td>\n",
       "      <td>0.203541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jfan5p</td>\n",
       "      <td>0.136053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7c4iz1</td>\n",
       "      <td>0.125685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ukigml</td>\n",
       "      <td>0.994097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flwvnq</td>\n",
       "      <td>0.138647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5i4fw2</td>\n",
       "      <td>0.979208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>du1pqf</td>\n",
       "      <td>0.265633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vs68qz</td>\n",
       "      <td>0.338547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pfyez0</td>\n",
       "      <td>0.090686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>azvkw2</td>\n",
       "      <td>0.358590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cird1i</td>\n",
       "      <td>0.980551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3bg32t</td>\n",
       "      <td>0.382802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xzd050</td>\n",
       "      <td>0.466919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>eyi8et</td>\n",
       "      <td>0.929782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ce4x2h</td>\n",
       "      <td>0.126496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sm91nr</td>\n",
       "      <td>0.878782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2il8hh</td>\n",
       "      <td>0.360201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>yq9cqg</td>\n",
       "      <td>0.521878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>520v5j</td>\n",
       "      <td>0.800061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ammgu2</td>\n",
       "      <td>0.181278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>jix8hj</td>\n",
       "      <td>0.176312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lj5zrq</td>\n",
       "      <td>0.275177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16ceba</td>\n",
       "      <td>0.116878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>93w44s</td>\n",
       "      <td>0.302543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bso17z</td>\n",
       "      <td>0.349944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>j2w2dc</td>\n",
       "      <td>0.888223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>74vwwl</td>\n",
       "      <td>0.099056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0z3fob</td>\n",
       "      <td>0.978270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>mr7zyz</td>\n",
       "      <td>0.215039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pp5n63</td>\n",
       "      <td>0.616520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>j0hix1</td>\n",
       "      <td>0.143215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rn209i</td>\n",
       "      <td>0.155564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>nfit8e</td>\n",
       "      <td>0.255046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>nb73sy</td>\n",
       "      <td>0.241029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>i79t3w</td>\n",
       "      <td>0.992073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>9nv2d9</td>\n",
       "      <td>0.680892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2xbeja</td>\n",
       "      <td>0.236081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>lwg3wq</td>\n",
       "      <td>0.997734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>lrvqwb</td>\n",
       "      <td>0.088426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>c6mepo</td>\n",
       "      <td>0.270153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6ued22</td>\n",
       "      <td>0.076150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>112e9h</td>\n",
       "      <td>0.958254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>8jc7h2</td>\n",
       "      <td>0.588117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>unykmj</td>\n",
       "      <td>0.332916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4yeztb</td>\n",
       "      <td>0.327530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tgpy9u</td>\n",
       "      <td>0.192817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pf5wp6</td>\n",
       "      <td>0.968201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>cj8vj2</td>\n",
       "      <td>0.073169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9w6d9j</td>\n",
       "      <td>0.996950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3l89wd</td>\n",
       "      <td>0.121973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>83a6x1</td>\n",
       "      <td>0.882566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>oua0gr</td>\n",
       "      <td>0.848676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>j0hl96</td>\n",
       "      <td>0.308493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>dlkzyg</td>\n",
       "      <td>0.536481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>r0w4a8</td>\n",
       "      <td>0.485370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>46dlca</td>\n",
       "      <td>0.097496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9fkefu</td>\n",
       "      <td>0.996581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6uk6kl</td>\n",
       "      <td>0.978818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>c7olxr</td>\n",
       "      <td>0.992752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>iiyx0q</td>\n",
       "      <td>0.989495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>25vetx</td>\n",
       "      <td>0.970722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>073vc5</td>\n",
       "      <td>0.917332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>18abn0</td>\n",
       "      <td>0.958118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>v5fsfs</td>\n",
       "      <td>0.407936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2ekoo7</td>\n",
       "      <td>0.128302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5bbknr</td>\n",
       "      <td>0.245791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>hr6pjx</td>\n",
       "      <td>0.477840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>r4hsar</td>\n",
       "      <td>0.345652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4cezdf</td>\n",
       "      <td>0.584659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>palhcc</td>\n",
       "      <td>0.278162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>bwoyg6</td>\n",
       "      <td>0.264680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>j8i7ve</td>\n",
       "      <td>0.899451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>t2zn1n</td>\n",
       "      <td>0.458417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>oxf8kj</td>\n",
       "      <td>0.206969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>aeiv0y</td>\n",
       "      <td>0.155216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  heart_disease_present\n",
       "0      olalu7               0.410348\n",
       "1      z9n6mx               0.106810\n",
       "2      5k4413               0.978349\n",
       "3      mrg7q5               0.292632\n",
       "4      uki4do               0.982702\n",
       "5      kev1sk               0.146908\n",
       "6      9n6let               0.805952\n",
       "7      jxmtyg               0.993172\n",
       "8      51s2ff               0.133010\n",
       "9      wi9mcs               0.241778\n",
       "10     741h4l               0.709780\n",
       "11     1ef64a               0.703866\n",
       "12     wa2ix6               0.105869\n",
       "13     8167zl               0.983079\n",
       "14     n6nldr               0.097367\n",
       "15     ph85fp               0.203541\n",
       "16     jfan5p               0.136053\n",
       "17     7c4iz1               0.125685\n",
       "18     ukigml               0.994097\n",
       "19     flwvnq               0.138647\n",
       "20     5i4fw2               0.979208\n",
       "21     du1pqf               0.265633\n",
       "22     vs68qz               0.338547\n",
       "23     pfyez0               0.090686\n",
       "24     azvkw2               0.358590\n",
       "25     cird1i               0.980551\n",
       "26     3bg32t               0.382802\n",
       "27     xzd050               0.466919\n",
       "28     eyi8et               0.929782\n",
       "29     ce4x2h               0.126496\n",
       "30     sm91nr               0.878782\n",
       "31     2il8hh               0.360201\n",
       "32     yq9cqg               0.521878\n",
       "33     520v5j               0.800061\n",
       "34     ammgu2               0.181278\n",
       "35     jix8hj               0.176312\n",
       "36     lj5zrq               0.275177\n",
       "37     16ceba               0.116878\n",
       "38     93w44s               0.302543\n",
       "39     bso17z               0.349944\n",
       "40     j2w2dc               0.888223\n",
       "41     74vwwl               0.099056\n",
       "42     0z3fob               0.978270\n",
       "43     mr7zyz               0.215039\n",
       "44     pp5n63               0.616520\n",
       "45     j0hix1               0.143215\n",
       "46     rn209i               0.155564\n",
       "47     nfit8e               0.255046\n",
       "48     nb73sy               0.241029\n",
       "49     i79t3w               0.992073\n",
       "50     9nv2d9               0.680892\n",
       "51     2xbeja               0.236081\n",
       "52     lwg3wq               0.997734\n",
       "53     lrvqwb               0.088426\n",
       "54     c6mepo               0.270153\n",
       "55     6ued22               0.076150\n",
       "56     112e9h               0.958254\n",
       "57     8jc7h2               0.588117\n",
       "58     unykmj               0.332916\n",
       "59     4yeztb               0.327530\n",
       "60     tgpy9u               0.192817\n",
       "61     pf5wp6               0.968201\n",
       "62     cj8vj2               0.073169\n",
       "63     9w6d9j               0.996950\n",
       "64     3l89wd               0.121973\n",
       "65     83a6x1               0.882566\n",
       "66     oua0gr               0.848676\n",
       "67     j0hl96               0.308493\n",
       "68     dlkzyg               0.536481\n",
       "69     r0w4a8               0.485370\n",
       "70     46dlca               0.097496\n",
       "71     9fkefu               0.996581\n",
       "72     6uk6kl               0.978818\n",
       "73     c7olxr               0.992752\n",
       "74     iiyx0q               0.989495\n",
       "75     25vetx               0.970722\n",
       "76     073vc5               0.917332\n",
       "77     18abn0               0.958118\n",
       "78     v5fsfs               0.407936\n",
       "79     2ekoo7               0.128302\n",
       "80     5bbknr               0.245791\n",
       "81     hr6pjx               0.477840\n",
       "82     r4hsar               0.345652\n",
       "83     4cezdf               0.584659\n",
       "84     palhcc               0.278162\n",
       "85     bwoyg6               0.264680\n",
       "86     j8i7ve               0.899451\n",
       "87     t2zn1n               0.458417\n",
       "88     oxf8kj               0.206969\n",
       "89     aeiv0y               0.155216"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_df = pd.DataFrame({\n",
    "    'patient_id': x_test['patient_id'],\n",
    "    'heart_disease_present': mean_pred[:]\n",
    "})\n",
    "out_df = out_df[['patient_id', 'heart_disease_present']]\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(out_df)\n",
    "\n",
    "out_dir = 'output'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "out_file = out_dir + '/' + experiment_name + '-' + 'out.csv'\n",
    "out_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
