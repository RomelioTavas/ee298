{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization, Embedding, Input, Reshape, Concatenate\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name='mlhw-mlp-with-preprocess'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('dataset/train_values.csv')\n",
    "y_train = pd.read_csv('dataset/train_labels.csv')\n",
    "x_test = pd.read_csv('dataset/test_values.csv')\n",
    "\n",
    "\n",
    "# Convert string values to integers\n",
    "x_train[\"thal\"] = x_train[\"thal\"].astype('category')\n",
    "x_train[\"thal\"] = x_train[\"thal\"].cat.codes\n",
    "\n",
    "x_test[\"thal\"] = x_test[\"thal\"].astype('category')\n",
    "x_test[\"thal\"] = x_test[\"thal\"].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "# Drop column\n",
    "x_train = x_train.drop(\"patient_id\", axis=1)\n",
    "y_train = y_train.drop(\"patient_id\", axis=1)\n",
    "\n",
    "xsize = x_train.shape[1]\n",
    "ysize = 1\n",
    "label_column = 'heart_disease_present'\n",
    "cols = list(x_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slope_of_peak_exercise_st_segment  thal  resting_blood_pressure  \\\n",
       "0                                  1     1                     128   \n",
       "1                                  2     1                     110   \n",
       "2                                  1     1                     125   \n",
       "3                                  1     2                     152   \n",
       "4                                  3     2                     178   \n",
       "\n",
       "   chest_pain_type  num_major_vessels  fasting_blood_sugar_gt_120_mg_per_dl  \\\n",
       "0                2                  0                                     0   \n",
       "1                3                  0                                     0   \n",
       "2                4                  3                                     0   \n",
       "3                4                  0                                     0   \n",
       "4                1                  0                                     0   \n",
       "\n",
       "   resting_ekg_results  serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  \\\n",
       "0                    2                          308                       0.0   \n",
       "1                    0                          214                       1.6   \n",
       "2                    2                          304                       0.0   \n",
       "3                    0                          223                       0.0   \n",
       "4                    2                          270                       4.2   \n",
       "\n",
       "   sex  age  max_heart_rate_achieved  exercise_induced_angina  \n",
       "0    1   45                      170                        0  \n",
       "1    0   54                      158                        0  \n",
       "2    1   77                      162                        1  \n",
       "3    1   40                      181                        0  \n",
       "4    1   59                      145                        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Whitening\n",
    "This will normalize our values so higher order values won't dominate other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.888762</td>\n",
       "      <td>-0.645259</td>\n",
       "      <td>-0.194652</td>\n",
       "      <td>-1.231340</td>\n",
       "      <td>-0.716404</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>0.951196</td>\n",
       "      <td>1.115158</td>\n",
       "      <td>-0.900694</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>-1.051032</td>\n",
       "      <td>0.929891</td>\n",
       "      <td>-0.678852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.727169</td>\n",
       "      <td>-0.645259</td>\n",
       "      <td>-1.252825</td>\n",
       "      <td>-0.165757</td>\n",
       "      <td>-0.716404</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>-1.051322</td>\n",
       "      <td>-0.667915</td>\n",
       "      <td>0.526148</td>\n",
       "      <td>-1.483908</td>\n",
       "      <td>-0.086892</td>\n",
       "      <td>0.386007</td>\n",
       "      <td>-0.678852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.888762</td>\n",
       "      <td>-0.645259</td>\n",
       "      <td>-0.371014</td>\n",
       "      <td>0.899825</td>\n",
       "      <td>2.378462</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>0.951196</td>\n",
       "      <td>1.039283</td>\n",
       "      <td>-0.900694</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>2.377024</td>\n",
       "      <td>0.567302</td>\n",
       "      <td>1.464891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.888762</td>\n",
       "      <td>1.114538</td>\n",
       "      <td>1.216246</td>\n",
       "      <td>0.899825</td>\n",
       "      <td>-0.716404</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>-1.051322</td>\n",
       "      <td>-0.497195</td>\n",
       "      <td>-0.900694</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>-1.586666</td>\n",
       "      <td>1.428452</td>\n",
       "      <td>-0.678852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.343100</td>\n",
       "      <td>1.114538</td>\n",
       "      <td>2.744719</td>\n",
       "      <td>-2.296923</td>\n",
       "      <td>-0.716404</td>\n",
       "      <td>-0.437019</td>\n",
       "      <td>0.951196</td>\n",
       "      <td>0.394342</td>\n",
       "      <td>2.844768</td>\n",
       "      <td>0.670152</td>\n",
       "      <td>0.448742</td>\n",
       "      <td>-0.203201</td>\n",
       "      <td>-0.678852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slope_of_peak_exercise_st_segment      thal  resting_blood_pressure  \\\n",
       "0                          -0.888762 -0.645259               -0.194652   \n",
       "1                           0.727169 -0.645259               -1.252825   \n",
       "2                          -0.888762 -0.645259               -0.371014   \n",
       "3                          -0.888762  1.114538                1.216246   \n",
       "4                           2.343100  1.114538                2.744719   \n",
       "\n",
       "   chest_pain_type  num_major_vessels  fasting_blood_sugar_gt_120_mg_per_dl  \\\n",
       "0        -1.231340          -0.716404                             -0.437019   \n",
       "1        -0.165757          -0.716404                             -0.437019   \n",
       "2         0.899825           2.378462                             -0.437019   \n",
       "3         0.899825          -0.716404                             -0.437019   \n",
       "4        -2.296923          -0.716404                             -0.437019   \n",
       "\n",
       "   resting_ekg_results  serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  \\\n",
       "0             0.951196                     1.115158                 -0.900694   \n",
       "1            -1.051322                    -0.667915                  0.526148   \n",
       "2             0.951196                     1.039283                 -0.900694   \n",
       "3            -1.051322                    -0.497195                 -0.900694   \n",
       "4             0.951196                     0.394342                  2.844768   \n",
       "\n",
       "        sex       age  max_heart_rate_achieved  exercise_induced_angina  \n",
       "0  0.670152 -1.051032                 0.929891                -0.678852  \n",
       "1 -1.483908 -0.086892                 0.386007                -0.678852  \n",
       "2  0.670152  2.377024                 0.567302                 1.464891  \n",
       "3  0.670152 -1.586666                 1.428452                -0.678852  \n",
       "4  0.670152  0.448742                -0.203201                -0.678852  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_mean = x_train[cols].mean(axis=0)\n",
    "x_train_std = x_train[cols].std(axis=0)\n",
    "x_train[cols] = (x_train[cols] - x_train_mean) / x_train_std\n",
    "\n",
    "x_test[cols] = (x_test[cols] - x_train_mean) / x_train_std\n",
    "\n",
    "\n",
    "display(x_train[cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-arrange Data for Categorical and Continous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = [\n",
    "    'thal',\n",
    "    'chest_pain_type',\n",
    "    'fasting_blood_sugar_gt_120_mg_per_dl',\n",
    "    'resting_ekg_results',\n",
    "    'sex',\n",
    "    'exercise_induced_angina'\n",
    "]\n",
    "cont_cols = [\n",
    "    'slope_of_peak_exercise_st_segment',\n",
    "    'num_major_vessels',\n",
    "    'resting_blood_pressure',\n",
    "    'serum_cholesterol_mg_per_dl',\n",
    "    'oldpeak_eq_st_depression',\n",
    "    'age',\n",
    "    'max_heart_rate_achieved',\n",
    "]\n",
    "\n",
    "\n",
    "def preproc_input(input_data):\n",
    "    input_list = []\n",
    "    for cat_col in cat_cols:\n",
    "        input_list.append(input_data[cat_col].values)\n",
    "\n",
    "    input_list.append(input_data[cont_cols].values)\n",
    "    return input_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_lr = 0.01\n",
    "opt_name = 'adam'\n",
    "# opt_name = 'rmsprop'\n",
    "\n",
    "def create_model():\n",
    "    inputs = []\n",
    "    embeddings = []\n",
    "\n",
    "    # For Categorical Variables\n",
    "    for cat_col in cat_cols :\n",
    "\n",
    "        no_of_unique_cat  = x_train[cat_col].nunique()\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50)\n",
    "        embedding_size = int(embedding_size)\n",
    "        vocab  = no_of_unique_cat + 1\n",
    "\n",
    "        emb_input = Input(shape=(1,))\n",
    "        emb = Embedding(vocab, embedding_size, input_length = 1)(emb_input)\n",
    "        emb = Dropout(.01)(emb)\n",
    "        emb = Reshape(target_shape=(embedding_size, ))(emb)\n",
    "        inputs.append(emb_input)\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    # Continuous variables\n",
    "    input_cont = Input(shape=(len(cont_cols),))\n",
    "    embedding_cont = BatchNormalization()(input_cont) \n",
    "    inputs.append(input_cont)\n",
    "    embeddings.append(embedding_cont)\n",
    "\n",
    "    x = Concatenate()(embeddings)\n",
    "    x = Dense(100)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.15)(x)\n",
    "\n",
    "    x = Dense(50)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.15)(x)\n",
    "\n",
    "    x = Dense(20)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.15)(x)\n",
    "\n",
    "    x = Dense(1)(x)\n",
    "    output = Activation('sigmoid')(x)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=inputs, \n",
    "        outputs=[output]\n",
    "    )\n",
    "\n",
    "\n",
    "#     opt = rmsprop(lr=initial_lr, decay=1e-6)\n",
    "\n",
    "    opt = Adam(lr=initial_lr)\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=[metrics.binary_accuracy]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  1\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 0.6887 - binary_accuracy: 0.6049 - val_loss: 1.1168 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 305us/step - loss: 0.5547 - binary_accuracy: 0.7469 - val_loss: 1.1211 - val_binary_accuracy: 0.7222\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 339us/step - loss: 0.4501 - binary_accuracy: 0.7778 - val_loss: 0.8716 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 299us/step - loss: 0.4882 - binary_accuracy: 0.7593 - val_loss: 0.6592 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 306us/step - loss: 0.4593 - binary_accuracy: 0.8086 - val_loss: 0.7046 - val_binary_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 297us/step - loss: 0.4006 - binary_accuracy: 0.8395 - val_loss: 0.7143 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 318us/step - loss: 0.3386 - binary_accuracy: 0.8457 - val_loss: 0.6384 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 337us/step - loss: 0.4006 - binary_accuracy: 0.8272 - val_loss: 0.5929 - val_binary_accuracy: 0.7778\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 316us/step - loss: 0.3254 - binary_accuracy: 0.8704 - val_loss: 0.6133 - val_binary_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 323us/step - loss: 0.3766 - binary_accuracy: 0.8333 - val_loss: 0.6569 - val_binary_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.3257 - binary_accuracy: 0.8519 - val_loss: 0.6508 - val_binary_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 304us/step - loss: 0.3799 - binary_accuracy: 0.8333 - val_loss: 0.6382 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 297us/step - loss: 0.2966 - binary_accuracy: 0.8704 - val_loss: 0.6054 - val_binary_accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 323us/step - loss: 0.3125 - binary_accuracy: 0.8889 - val_loss: 0.5813 - val_binary_accuracy: 0.7222\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 328us/step - loss: 0.2888 - binary_accuracy: 0.8951 - val_loss: 0.6363 - val_binary_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.2874 - binary_accuracy: 0.8951 - val_loss: 0.6365 - val_binary_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 288us/step - loss: 0.3012 - binary_accuracy: 0.8827 - val_loss: 0.6383 - val_binary_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.3414 - binary_accuracy: 0.8580 - val_loss: 0.6418 - val_binary_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.2592 - binary_accuracy: 0.8889 - val_loss: 0.5940 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.3032 - binary_accuracy: 0.8580 - val_loss: 0.6207 - val_binary_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.2733 - binary_accuracy: 0.8765 - val_loss: 0.7044 - val_binary_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.2297 - binary_accuracy: 0.9444 - val_loss: 0.6714 - val_binary_accuracy: 0.7778\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2472 - binary_accuracy: 0.9136 - val_loss: 0.6505 - val_binary_accuracy: 0.7222\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2517 - binary_accuracy: 0.8765 - val_loss: 0.6676 - val_binary_accuracy: 0.7778\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2948 - binary_accuracy: 0.8457 - val_loss: 0.6916 - val_binary_accuracy: 0.7778\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.2457 - binary_accuracy: 0.9074 - val_loss: 0.7229 - val_binary_accuracy: 0.7778\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.2435 - binary_accuracy: 0.9198 - val_loss: 0.7047 - val_binary_accuracy: 0.7222\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.2057 - binary_accuracy: 0.9259 - val_loss: 0.7173 - val_binary_accuracy: 0.7778\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 295us/step - loss: 0.2213 - binary_accuracy: 0.9198 - val_loss: 0.7496 - val_binary_accuracy: 0.7222\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.2266 - binary_accuracy: 0.9198 - val_loss: 0.7439 - val_binary_accuracy: 0.6111\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2199 - binary_accuracy: 0.9074 - val_loss: 0.7651 - val_binary_accuracy: 0.6111\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.1947 - binary_accuracy: 0.9383 - val_loss: 0.8106 - val_binary_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 295us/step - loss: 0.1941 - binary_accuracy: 0.9383 - val_loss: 0.8686 - val_binary_accuracy: 0.6111\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.2066 - binary_accuracy: 0.8951 - val_loss: 0.8029 - val_binary_accuracy: 0.6111\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.2085 - binary_accuracy: 0.9074 - val_loss: 0.7352 - val_binary_accuracy: 0.7222\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.2264 - binary_accuracy: 0.9012 - val_loss: 0.8597 - val_binary_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.3646 - binary_accuracy: 0.8457 - val_loss: 0.8771 - val_binary_accuracy: 0.7222\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.3338 - binary_accuracy: 0.8704 - val_loss: 0.7352 - val_binary_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.3376 - binary_accuracy: 0.8642 - val_loss: 0.7024 - val_binary_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2500 - binary_accuracy: 0.8889 - val_loss: 0.7175 - val_binary_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2593 - binary_accuracy: 0.8765 - val_loss: 0.7817 - val_binary_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.2225 - binary_accuracy: 0.9012 - val_loss: 0.9194 - val_binary_accuracy: 0.7222\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.2498 - binary_accuracy: 0.9012 - val_loss: 1.0924 - val_binary_accuracy: 0.7222\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.2452 - binary_accuracy: 0.9136 - val_loss: 1.0506 - val_binary_accuracy: 0.6111\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.2094 - binary_accuracy: 0.9321 - val_loss: 1.0059 - val_binary_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.2431 - binary_accuracy: 0.9136 - val_loss: 0.9848 - val_binary_accuracy: 0.7222\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 296us/step - loss: 0.2186 - binary_accuracy: 0.9012 - val_loss: 0.9617 - val_binary_accuracy: 0.7222\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1988 - binary_accuracy: 0.9321 - val_loss: 0.9693 - val_binary_accuracy: 0.7222\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.2199 - binary_accuracy: 0.9012 - val_loss: 1.0031 - val_binary_accuracy: 0.7222\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.2828 - binary_accuracy: 0.8889 - val_loss: 1.0268 - val_binary_accuracy: 0.7222\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.2341 - binary_accuracy: 0.9074 - val_loss: 1.0416 - val_binary_accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.1661 - binary_accuracy: 0.9506 - val_loss: 0.9763 - val_binary_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.2521 - binary_accuracy: 0.9012 - val_loss: 0.8462 - val_binary_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.2289 - binary_accuracy: 0.9074 - val_loss: 0.7529 - val_binary_accuracy: 0.7222\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.2131 - binary_accuracy: 0.9321 - val_loss: 0.7316 - val_binary_accuracy: 0.7778\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.1967 - binary_accuracy: 0.9383 - val_loss: 0.7416 - val_binary_accuracy: 0.7222\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.1857 - binary_accuracy: 0.9321 - val_loss: 0.7034 - val_binary_accuracy: 0.7778\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.2085 - binary_accuracy: 0.9198 - val_loss: 0.7129 - val_binary_accuracy: 0.7778\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1937 - binary_accuracy: 0.9259 - val_loss: 0.7286 - val_binary_accuracy: 0.7222\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.2178 - binary_accuracy: 0.9074 - val_loss: 0.8693 - val_binary_accuracy: 0.7222\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.2003 - binary_accuracy: 0.9444 - val_loss: 0.8992 - val_binary_accuracy: 0.7222\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.2537 - binary_accuracy: 0.8889 - val_loss: 0.8348 - val_binary_accuracy: 0.7222\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.2334 - binary_accuracy: 0.8827 - val_loss: 0.7504 - val_binary_accuracy: 0.7222\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1968 - binary_accuracy: 0.9444 - val_loss: 0.6910 - val_binary_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2932 - binary_accuracy: 0.8827 - val_loss: 0.6458 - val_binary_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2127 - binary_accuracy: 0.9259 - val_loss: 0.6244 - val_binary_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.1898 - binary_accuracy: 0.9321 - val_loss: 0.6203 - val_binary_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.1726 - binary_accuracy: 0.9444 - val_loss: 0.6196 - val_binary_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.2236 - binary_accuracy: 0.9321 - val_loss: 0.6207 - val_binary_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 302us/step - loss: 0.2623 - binary_accuracy: 0.8951 - val_loss: 0.5640 - val_binary_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.2408 - binary_accuracy: 0.9136 - val_loss: 0.5659 - val_binary_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.1875 - binary_accuracy: 0.9506 - val_loss: 0.5694 - val_binary_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 307us/step - loss: 0.1986 - binary_accuracy: 0.9259 - val_loss: 0.5801 - val_binary_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.1614 - binary_accuracy: 0.9568 - val_loss: 0.6143 - val_binary_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.1626 - binary_accuracy: 0.9444 - val_loss: 0.5963 - val_binary_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.1774 - binary_accuracy: 0.9321 - val_loss: 0.6206 - val_binary_accuracy: 0.7778\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.1990 - binary_accuracy: 0.9444 - val_loss: 0.6602 - val_binary_accuracy: 0.7778\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 284us/step - loss: 0.1726 - binary_accuracy: 0.9506 - val_loss: 0.7087 - val_binary_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2195 - binary_accuracy: 0.9259 - val_loss: 0.7618 - val_binary_accuracy: 0.7778\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.2460 - binary_accuracy: 0.9012 - val_loss: 0.7770 - val_binary_accuracy: 0.7778\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.2484 - binary_accuracy: 0.9136 - val_loss: 0.7693 - val_binary_accuracy: 0.7778\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2475 - binary_accuracy: 0.9198 - val_loss: 0.7398 - val_binary_accuracy: 0.7778\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.2896 - binary_accuracy: 0.8704 - val_loss: 0.7369 - val_binary_accuracy: 0.7222\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.2670 - binary_accuracy: 0.9074 - val_loss: 0.6990 - val_binary_accuracy: 0.7222\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.2966 - binary_accuracy: 0.8704 - val_loss: 0.6943 - val_binary_accuracy: 0.7222\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.2575 - binary_accuracy: 0.9012 - val_loss: 0.7255 - val_binary_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.2195 - binary_accuracy: 0.9136 - val_loss: 0.7307 - val_binary_accuracy: 0.7222\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2935 - binary_accuracy: 0.8765 - val_loss: 0.7217 - val_binary_accuracy: 0.7778\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.1940 - binary_accuracy: 0.9259 - val_loss: 0.6991 - val_binary_accuracy: 0.7778\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 247us/step - loss: 0.2328 - binary_accuracy: 0.9074 - val_loss: 0.7108 - val_binary_accuracy: 0.7778\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 302us/step - loss: 0.2133 - binary_accuracy: 0.9198 - val_loss: 0.7538 - val_binary_accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.1848 - binary_accuracy: 0.9321 - val_loss: 0.7721 - val_binary_accuracy: 0.7222\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.2376 - binary_accuracy: 0.8951 - val_loss: 0.7763 - val_binary_accuracy: 0.7222\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2035 - binary_accuracy: 0.9074 - val_loss: 0.7955 - val_binary_accuracy: 0.7222\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2412 - binary_accuracy: 0.9012 - val_loss: 0.8161 - val_binary_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.1940 - binary_accuracy: 0.9074 - val_loss: 0.8777 - val_binary_accuracy: 0.7222\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 304us/step - loss: 0.2594 - binary_accuracy: 0.9074 - val_loss: 0.8496 - val_binary_accuracy: 0.6111\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.1925 - binary_accuracy: 0.9383 - val_loss: 0.7627 - val_binary_accuracy: 0.6111\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2141 - binary_accuracy: 0.9198 - val_loss: 0.6790 - val_binary_accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1995 - binary_accuracy: 0.9506 - val_loss: 0.6143 - val_binary_accuracy: 0.6667\n",
      "18/18 [==============================] - 0s 93us/step\n",
      "\n",
      "Fold  2\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 2s 11ms/step - loss: 0.8562 - binary_accuracy: 0.5617 - val_loss: 0.5355 - val_binary_accuracy: 0.7778\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.5514 - binary_accuracy: 0.7469 - val_loss: 0.4259 - val_binary_accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.5109 - binary_accuracy: 0.7531 - val_loss: 0.4171 - val_binary_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 306us/step - loss: 0.4834 - binary_accuracy: 0.7346 - val_loss: 0.4057 - val_binary_accuracy: 0.8889\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.4513 - binary_accuracy: 0.7716 - val_loss: 0.4198 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 216us/step - loss: 0.3819 - binary_accuracy: 0.8333 - val_loss: 0.4612 - val_binary_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.3505 - binary_accuracy: 0.8395 - val_loss: 0.5284 - val_binary_accuracy: 0.7222\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.3403 - binary_accuracy: 0.8519 - val_loss: 0.5942 - val_binary_accuracy: 0.7778\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 219us/step - loss: 0.3322 - binary_accuracy: 0.8580 - val_loss: 0.6352 - val_binary_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.2833 - binary_accuracy: 0.8704 - val_loss: 0.6173 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.2835 - binary_accuracy: 0.8827 - val_loss: 0.6129 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.2927 - binary_accuracy: 0.8765 - val_loss: 0.6542 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.2421 - binary_accuracy: 0.8889 - val_loss: 0.6183 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.2816 - binary_accuracy: 0.9012 - val_loss: 0.5786 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.2666 - binary_accuracy: 0.8951 - val_loss: 0.5559 - val_binary_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2964 - binary_accuracy: 0.8580 - val_loss: 0.4377 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.3023 - binary_accuracy: 0.8827 - val_loss: 0.4656 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.2863 - binary_accuracy: 0.8704 - val_loss: 0.5352 - val_binary_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2379 - binary_accuracy: 0.9136 - val_loss: 0.5604 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.2436 - binary_accuracy: 0.9012 - val_loss: 0.5298 - val_binary_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 296us/step - loss: 0.2617 - binary_accuracy: 0.9012 - val_loss: 0.4232 - val_binary_accuracy: 0.7778\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.2692 - binary_accuracy: 0.8889 - val_loss: 0.3981 - val_binary_accuracy: 0.7778\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2450 - binary_accuracy: 0.9321 - val_loss: 0.4567 - val_binary_accuracy: 0.7778\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.2477 - binary_accuracy: 0.9074 - val_loss: 0.4912 - val_binary_accuracy: 0.7778\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.2358 - binary_accuracy: 0.9136 - val_loss: 0.5440 - val_binary_accuracy: 0.7778\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.2572 - binary_accuracy: 0.9074 - val_loss: 0.5792 - val_binary_accuracy: 0.7778\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.2257 - binary_accuracy: 0.9136 - val_loss: 0.5806 - val_binary_accuracy: 0.7778\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2170 - binary_accuracy: 0.9259 - val_loss: 0.5612 - val_binary_accuracy: 0.7778\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.2193 - binary_accuracy: 0.9074 - val_loss: 0.5732 - val_binary_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.2008 - binary_accuracy: 0.9259 - val_loss: 0.6206 - val_binary_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.2362 - binary_accuracy: 0.9198 - val_loss: 0.7349 - val_binary_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.2758 - binary_accuracy: 0.8889 - val_loss: 0.7497 - val_binary_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.2168 - binary_accuracy: 0.9198 - val_loss: 0.6942 - val_binary_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.2809 - binary_accuracy: 0.8765 - val_loss: 0.6857 - val_binary_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.2502 - binary_accuracy: 0.8889 - val_loss: 0.7026 - val_binary_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 236us/step - loss: 0.1982 - binary_accuracy: 0.9383 - val_loss: 0.7347 - val_binary_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.2386 - binary_accuracy: 0.9198 - val_loss: 0.7639 - val_binary_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.2166 - binary_accuracy: 0.9198 - val_loss: 0.8259 - val_binary_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2199 - binary_accuracy: 0.9136 - val_loss: 0.7949 - val_binary_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 300us/step - loss: 0.2360 - binary_accuracy: 0.9074 - val_loss: 0.7934 - val_binary_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.2247 - binary_accuracy: 0.9198 - val_loss: 0.8079 - val_binary_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.2529 - binary_accuracy: 0.8951 - val_loss: 0.7905 - val_binary_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 284us/step - loss: 0.2134 - binary_accuracy: 0.9136 - val_loss: 0.7599 - val_binary_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.2397 - binary_accuracy: 0.8889 - val_loss: 0.7935 - val_binary_accuracy: 0.7778\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.1725 - binary_accuracy: 0.9444 - val_loss: 0.8014 - val_binary_accuracy: 0.7778\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.1443 - binary_accuracy: 0.9568 - val_loss: 0.7952 - val_binary_accuracy: 0.7778\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 302us/step - loss: 0.1685 - binary_accuracy: 0.9568 - val_loss: 0.7902 - val_binary_accuracy: 0.7778\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.2453 - binary_accuracy: 0.8889 - val_loss: 0.7631 - val_binary_accuracy: 0.7778\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.1881 - binary_accuracy: 0.9444 - val_loss: 0.7584 - val_binary_accuracy: 0.7778\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2489 - binary_accuracy: 0.9012 - val_loss: 0.7126 - val_binary_accuracy: 0.7778\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 288us/step - loss: 0.2308 - binary_accuracy: 0.9198 - val_loss: 0.6951 - val_binary_accuracy: 0.7778\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2247 - binary_accuracy: 0.9259 - val_loss: 0.6839 - val_binary_accuracy: 0.7778\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 256us/step - loss: 0.2185 - binary_accuracy: 0.9259 - val_loss: 0.7056 - val_binary_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.2068 - binary_accuracy: 0.9198 - val_loss: 0.7128 - val_binary_accuracy: 0.7778\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 292us/step - loss: 0.2215 - binary_accuracy: 0.9198 - val_loss: 0.7788 - val_binary_accuracy: 0.7778\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 288us/step - loss: 0.2048 - binary_accuracy: 0.9074 - val_loss: 0.7584 - val_binary_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.1712 - binary_accuracy: 0.9444 - val_loss: 0.7561 - val_binary_accuracy: 0.7778\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.1555 - binary_accuracy: 0.9568 - val_loss: 0.7374 - val_binary_accuracy: 0.7778\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.1599 - binary_accuracy: 0.9321 - val_loss: 0.7059 - val_binary_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.1621 - binary_accuracy: 0.9506 - val_loss: 0.6781 - val_binary_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.1394 - binary_accuracy: 0.9568 - val_loss: 0.7124 - val_binary_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.1400 - binary_accuracy: 0.9630 - val_loss: 0.8126 - val_binary_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 286us/step - loss: 0.1379 - binary_accuracy: 0.9568 - val_loss: 0.8975 - val_binary_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 297us/step - loss: 0.1737 - binary_accuracy: 0.9444 - val_loss: 1.0586 - val_binary_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 292us/step - loss: 0.1937 - binary_accuracy: 0.9321 - val_loss: 0.9556 - val_binary_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.1719 - binary_accuracy: 0.9198 - val_loss: 0.8909 - val_binary_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.1779 - binary_accuracy: 0.9506 - val_loss: 0.8345 - val_binary_accuracy: 0.7778\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.1702 - binary_accuracy: 0.9444 - val_loss: 0.7257 - val_binary_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 293us/step - loss: 0.1904 - binary_accuracy: 0.9321 - val_loss: 0.6715 - val_binary_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.1933 - binary_accuracy: 0.9444 - val_loss: 0.6809 - val_binary_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.2144 - binary_accuracy: 0.9321 - val_loss: 0.6625 - val_binary_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.1515 - binary_accuracy: 0.9568 - val_loss: 0.6460 - val_binary_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 305us/step - loss: 0.1578 - binary_accuracy: 0.9383 - val_loss: 0.6627 - val_binary_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.1610 - binary_accuracy: 0.9568 - val_loss: 0.7067 - val_binary_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.1690 - binary_accuracy: 0.9383 - val_loss: 0.7429 - val_binary_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.1066 - binary_accuracy: 0.9753 - val_loss: 0.7655 - val_binary_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.1815 - binary_accuracy: 0.9383 - val_loss: 0.8253 - val_binary_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.1067 - binary_accuracy: 0.9815 - val_loss: 0.8819 - val_binary_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.1603 - binary_accuracy: 0.9630 - val_loss: 0.9210 - val_binary_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.1814 - binary_accuracy: 0.9321 - val_loss: 0.9072 - val_binary_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.1371 - binary_accuracy: 0.9568 - val_loss: 0.9058 - val_binary_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 304us/step - loss: 0.0962 - binary_accuracy: 0.9815 - val_loss: 0.9193 - val_binary_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.1851 - binary_accuracy: 0.9198 - val_loss: 0.9607 - val_binary_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.0896 - binary_accuracy: 0.9753 - val_loss: 0.9270 - val_binary_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.1363 - binary_accuracy: 0.9444 - val_loss: 0.9256 - val_binary_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.1601 - binary_accuracy: 0.9444 - val_loss: 0.9292 - val_binary_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 292us/step - loss: 0.1383 - binary_accuracy: 0.9568 - val_loss: 0.9353 - val_binary_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 297us/step - loss: 0.1250 - binary_accuracy: 0.9753 - val_loss: 0.9418 - val_binary_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.1382 - binary_accuracy: 0.9506 - val_loss: 0.8927 - val_binary_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.1514 - binary_accuracy: 0.9506 - val_loss: 0.8653 - val_binary_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.1214 - binary_accuracy: 0.9444 - val_loss: 0.8904 - val_binary_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.0960 - binary_accuracy: 0.9630 - val_loss: 0.9260 - val_binary_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.1150 - binary_accuracy: 0.9753 - val_loss: 0.9677 - val_binary_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.0990 - binary_accuracy: 0.9506 - val_loss: 0.9647 - val_binary_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.1281 - binary_accuracy: 0.9444 - val_loss: 0.9662 - val_binary_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 300us/step - loss: 0.1013 - binary_accuracy: 0.9506 - val_loss: 0.9751 - val_binary_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.1714 - binary_accuracy: 0.9321 - val_loss: 0.9645 - val_binary_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.0994 - binary_accuracy: 0.9753 - val_loss: 0.9235 - val_binary_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.1562 - binary_accuracy: 0.9568 - val_loss: 0.9236 - val_binary_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.1028 - binary_accuracy: 0.9815 - val_loss: 0.9095 - val_binary_accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 127us/step\n",
      "\n",
      "Fold  3\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 2s 12ms/step - loss: 0.7972 - binary_accuracy: 0.5864 - val_loss: 1.3095 - val_binary_accuracy: 0.6111\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.5303 - binary_accuracy: 0.7469 - val_loss: 1.2404 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.4955 - binary_accuracy: 0.7593 - val_loss: 1.1475 - val_binary_accuracy: 0.6111\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 224us/step - loss: 0.4992 - binary_accuracy: 0.7716 - val_loss: 1.1518 - val_binary_accuracy: 0.6111\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 232us/step - loss: 0.4635 - binary_accuracy: 0.7716 - val_loss: 1.0772 - val_binary_accuracy: 0.6111\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.4006 - binary_accuracy: 0.8395 - val_loss: 0.9420 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 294us/step - loss: 0.3787 - binary_accuracy: 0.8395 - val_loss: 0.9491 - val_binary_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.3467 - binary_accuracy: 0.8827 - val_loss: 0.9185 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.3260 - binary_accuracy: 0.8642 - val_loss: 0.8832 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 336us/step - loss: 0.3343 - binary_accuracy: 0.8519 - val_loss: 0.8407 - val_binary_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.2900 - binary_accuracy: 0.8951 - val_loss: 0.6816 - val_binary_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.2584 - binary_accuracy: 0.9074 - val_loss: 0.6450 - val_binary_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.3177 - binary_accuracy: 0.8765 - val_loss: 0.7001 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 295us/step - loss: 0.2987 - binary_accuracy: 0.8642 - val_loss: 0.7082 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 288us/step - loss: 0.3421 - binary_accuracy: 0.8519 - val_loss: 0.6976 - val_binary_accuracy: 0.7222\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2866 - binary_accuracy: 0.8889 - val_loss: 0.7076 - val_binary_accuracy: 0.7222\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.3433 - binary_accuracy: 0.8580 - val_loss: 0.7445 - val_binary_accuracy: 0.6111\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2830 - binary_accuracy: 0.8889 - val_loss: 0.7523 - val_binary_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 318us/step - loss: 0.2449 - binary_accuracy: 0.9074 - val_loss: 0.8018 - val_binary_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.2712 - binary_accuracy: 0.9136 - val_loss: 0.8438 - val_binary_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2258 - binary_accuracy: 0.9321 - val_loss: 0.7889 - val_binary_accuracy: 0.7222\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.2201 - binary_accuracy: 0.9198 - val_loss: 0.7847 - val_binary_accuracy: 0.7222\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 329us/step - loss: 0.2578 - binary_accuracy: 0.9259 - val_loss: 0.8011 - val_binary_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.2243 - binary_accuracy: 0.8951 - val_loss: 0.9126 - val_binary_accuracy: 0.7778\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.2682 - binary_accuracy: 0.8765 - val_loss: 0.8823 - val_binary_accuracy: 0.7222\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.2767 - binary_accuracy: 0.8704 - val_loss: 0.8879 - val_binary_accuracy: 0.7222\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 292us/step - loss: 0.2232 - binary_accuracy: 0.9198 - val_loss: 0.8225 - val_binary_accuracy: 0.7222\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 297us/step - loss: 0.2813 - binary_accuracy: 0.8704 - val_loss: 0.8355 - val_binary_accuracy: 0.7222\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.2268 - binary_accuracy: 0.9074 - val_loss: 0.8317 - val_binary_accuracy: 0.7222\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.2568 - binary_accuracy: 0.8951 - val_loss: 0.8595 - val_binary_accuracy: 0.7222\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.2580 - binary_accuracy: 0.8951 - val_loss: 0.8382 - val_binary_accuracy: 0.7222\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 334us/step - loss: 0.1980 - binary_accuracy: 0.9321 - val_loss: 0.7884 - val_binary_accuracy: 0.7778\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.2488 - binary_accuracy: 0.9074 - val_loss: 0.8248 - val_binary_accuracy: 0.7778\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.2171 - binary_accuracy: 0.9074 - val_loss: 0.8924 - val_binary_accuracy: 0.7778\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 252us/step - loss: 0.2172 - binary_accuracy: 0.9198 - val_loss: 0.8590 - val_binary_accuracy: 0.7222\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 304us/step - loss: 0.2891 - binary_accuracy: 0.8827 - val_loss: 0.8164 - val_binary_accuracy: 0.7778\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.1759 - binary_accuracy: 0.9506 - val_loss: 0.8040 - val_binary_accuracy: 0.7778\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.2239 - binary_accuracy: 0.8889 - val_loss: 0.7800 - val_binary_accuracy: 0.7778\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.2011 - binary_accuracy: 0.9259 - val_loss: 0.8069 - val_binary_accuracy: 0.7778\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 308us/step - loss: 0.2003 - binary_accuracy: 0.9136 - val_loss: 0.9062 - val_binary_accuracy: 0.6111\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.2279 - binary_accuracy: 0.9074 - val_loss: 0.9090 - val_binary_accuracy: 0.6111\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.1521 - binary_accuracy: 0.9506 - val_loss: 0.8734 - val_binary_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.1848 - binary_accuracy: 0.9198 - val_loss: 0.8921 - val_binary_accuracy: 0.7222\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 298us/step - loss: 0.2651 - binary_accuracy: 0.9012 - val_loss: 0.9419 - val_binary_accuracy: 0.7222\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.1996 - binary_accuracy: 0.9321 - val_loss: 0.9148 - val_binary_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1909 - binary_accuracy: 0.9383 - val_loss: 0.9112 - val_binary_accuracy: 0.7222\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.1971 - binary_accuracy: 0.9383 - val_loss: 0.8917 - val_binary_accuracy: 0.7222\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.1705 - binary_accuracy: 0.9691 - val_loss: 0.8711 - val_binary_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 296us/step - loss: 0.2392 - binary_accuracy: 0.8889 - val_loss: 0.8112 - val_binary_accuracy: 0.7222\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 312us/step - loss: 0.1846 - binary_accuracy: 0.9383 - val_loss: 0.7775 - val_binary_accuracy: 0.7222\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.2074 - binary_accuracy: 0.9074 - val_loss: 0.8250 - val_binary_accuracy: 0.7222\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.1844 - binary_accuracy: 0.9321 - val_loss: 0.8485 - val_binary_accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 307us/step - loss: 0.2055 - binary_accuracy: 0.9321 - val_loss: 0.8555 - val_binary_accuracy: 0.7222\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 268us/step - loss: 0.2038 - binary_accuracy: 0.9136 - val_loss: 0.8381 - val_binary_accuracy: 0.7222\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2115 - binary_accuracy: 0.9321 - val_loss: 0.8777 - val_binary_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1993 - binary_accuracy: 0.9321 - val_loss: 0.8634 - val_binary_accuracy: 0.7222\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.1764 - binary_accuracy: 0.9383 - val_loss: 0.8424 - val_binary_accuracy: 0.7222\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.1961 - binary_accuracy: 0.9074 - val_loss: 0.8544 - val_binary_accuracy: 0.7222\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.1431 - binary_accuracy: 0.9753 - val_loss: 0.9295 - val_binary_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.1597 - binary_accuracy: 0.9444 - val_loss: 0.9481 - val_binary_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.1761 - binary_accuracy: 0.9383 - val_loss: 0.9323 - val_binary_accuracy: 0.6111\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.1680 - binary_accuracy: 0.9630 - val_loss: 0.8412 - val_binary_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.1999 - binary_accuracy: 0.9136 - val_loss: 0.8316 - val_binary_accuracy: 0.7222\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1925 - binary_accuracy: 0.9198 - val_loss: 0.8616 - val_binary_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.1623 - binary_accuracy: 0.9568 - val_loss: 0.8965 - val_binary_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2330 - binary_accuracy: 0.9198 - val_loss: 0.9463 - val_binary_accuracy: 0.6111\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.1985 - binary_accuracy: 0.9444 - val_loss: 1.0024 - val_binary_accuracy: 0.6111\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2374 - binary_accuracy: 0.9136 - val_loss: 0.9760 - val_binary_accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.2254 - binary_accuracy: 0.9074 - val_loss: 0.8446 - val_binary_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.1968 - binary_accuracy: 0.9259 - val_loss: 0.8098 - val_binary_accuracy: 0.7222\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.2096 - binary_accuracy: 0.9444 - val_loss: 0.8430 - val_binary_accuracy: 0.7222\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.2213 - binary_accuracy: 0.9136 - val_loss: 0.9136 - val_binary_accuracy: 0.6111\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.2327 - binary_accuracy: 0.9136 - val_loss: 0.9124 - val_binary_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.2046 - binary_accuracy: 0.9383 - val_loss: 0.8407 - val_binary_accuracy: 0.7222\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.2011 - binary_accuracy: 0.9444 - val_loss: 0.8566 - val_binary_accuracy: 0.7222\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.2569 - binary_accuracy: 0.8951 - val_loss: 0.8759 - val_binary_accuracy: 0.7222\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 291us/step - loss: 0.2477 - binary_accuracy: 0.9074 - val_loss: 0.8335 - val_binary_accuracy: 0.7222\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 292us/step - loss: 0.2516 - binary_accuracy: 0.9074 - val_loss: 0.8516 - val_binary_accuracy: 0.7222\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 260us/step - loss: 0.2470 - binary_accuracy: 0.8951 - val_loss: 0.9009 - val_binary_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.2273 - binary_accuracy: 0.9259 - val_loss: 0.9546 - val_binary_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.1969 - binary_accuracy: 0.9383 - val_loss: 0.9995 - val_binary_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 306us/step - loss: 0.2276 - binary_accuracy: 0.8951 - val_loss: 0.9808 - val_binary_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 328us/step - loss: 0.2374 - binary_accuracy: 0.9321 - val_loss: 1.0367 - val_binary_accuracy: 0.7222\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.2029 - binary_accuracy: 0.9259 - val_loss: 0.9773 - val_binary_accuracy: 0.7222\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 294us/step - loss: 0.2373 - binary_accuracy: 0.8827 - val_loss: 1.0140 - val_binary_accuracy: 0.7222\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.1999 - binary_accuracy: 0.9198 - val_loss: 1.0365 - val_binary_accuracy: 0.7222\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 330us/step - loss: 0.1772 - binary_accuracy: 0.9321 - val_loss: 1.0922 - val_binary_accuracy: 0.7222\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.2042 - binary_accuracy: 0.9259 - val_loss: 1.1860 - val_binary_accuracy: 0.7222\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.1703 - binary_accuracy: 0.9630 - val_loss: 1.1583 - val_binary_accuracy: 0.7222\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.2260 - binary_accuracy: 0.9136 - val_loss: 1.1056 - val_binary_accuracy: 0.7222\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 320us/step - loss: 0.2287 - binary_accuracy: 0.9198 - val_loss: 1.0250 - val_binary_accuracy: 0.7222\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 260us/step - loss: 0.1672 - binary_accuracy: 0.9383 - val_loss: 0.8368 - val_binary_accuracy: 0.7222\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.2069 - binary_accuracy: 0.9136 - val_loss: 0.8661 - val_binary_accuracy: 0.7222\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.2176 - binary_accuracy: 0.9074 - val_loss: 0.9401 - val_binary_accuracy: 0.7222\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.1692 - binary_accuracy: 0.9444 - val_loss: 1.0020 - val_binary_accuracy: 0.7222\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.1935 - binary_accuracy: 0.9259 - val_loss: 1.0732 - val_binary_accuracy: 0.7222\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.2027 - binary_accuracy: 0.9259 - val_loss: 1.0928 - val_binary_accuracy: 0.7222\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.1366 - binary_accuracy: 0.9568 - val_loss: 1.0634 - val_binary_accuracy: 0.7222\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2339 - binary_accuracy: 0.9259 - val_loss: 1.0284 - val_binary_accuracy: 0.7222\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.1674 - binary_accuracy: 0.9444 - val_loss: 0.9972 - val_binary_accuracy: 0.7222\n",
      "18/18 [==============================] - 0s 87us/step\n",
      "\n",
      "Fold  4\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 2s 14ms/step - loss: 0.7195 - binary_accuracy: 0.6296 - val_loss: 0.7812 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.5351 - binary_accuracy: 0.7778 - val_loss: 0.7566 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.5350 - binary_accuracy: 0.7593 - val_loss: 0.6524 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 310us/step - loss: 0.4361 - binary_accuracy: 0.8148 - val_loss: 0.6198 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.4031 - binary_accuracy: 0.8210 - val_loss: 0.6593 - val_binary_accuracy: 0.6111\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.3673 - binary_accuracy: 0.8333 - val_loss: 0.6862 - val_binary_accuracy: 0.6111\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.3609 - binary_accuracy: 0.8395 - val_loss: 0.6426 - val_binary_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 300us/step - loss: 0.3674 - binary_accuracy: 0.8333 - val_loss: 0.5767 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.4078 - binary_accuracy: 0.8210 - val_loss: 0.5897 - val_binary_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 284us/step - loss: 0.3078 - binary_accuracy: 0.8889 - val_loss: 0.6240 - val_binary_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.3002 - binary_accuracy: 0.8827 - val_loss: 0.6495 - val_binary_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 325us/step - loss: 0.2540 - binary_accuracy: 0.9136 - val_loss: 0.6671 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 252us/step - loss: 0.3121 - binary_accuracy: 0.8704 - val_loss: 0.6556 - val_binary_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.2484 - binary_accuracy: 0.9074 - val_loss: 0.6302 - val_binary_accuracy: 0.7222\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2743 - binary_accuracy: 0.9074 - val_loss: 0.5773 - val_binary_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 308us/step - loss: 0.2529 - binary_accuracy: 0.9198 - val_loss: 0.5333 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2823 - binary_accuracy: 0.8889 - val_loss: 0.5742 - val_binary_accuracy: 0.7222\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.3059 - binary_accuracy: 0.8704 - val_loss: 0.5719 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.2952 - binary_accuracy: 0.9012 - val_loss: 0.5438 - val_binary_accuracy: 0.7222\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 283us/step - loss: 0.2638 - binary_accuracy: 0.9259 - val_loss: 0.5257 - val_binary_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 252us/step - loss: 0.2700 - binary_accuracy: 0.9321 - val_loss: 0.4889 - val_binary_accuracy: 0.7778\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2576 - binary_accuracy: 0.9383 - val_loss: 0.4901 - val_binary_accuracy: 0.7778\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.2597 - binary_accuracy: 0.9321 - val_loss: 0.5940 - val_binary_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.2906 - binary_accuracy: 0.9074 - val_loss: 0.6528 - val_binary_accuracy: 0.7222\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.3090 - binary_accuracy: 0.8765 - val_loss: 0.6978 - val_binary_accuracy: 0.7222\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.2941 - binary_accuracy: 0.8951 - val_loss: 0.6881 - val_binary_accuracy: 0.7222\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.2711 - binary_accuracy: 0.9074 - val_loss: 0.6647 - val_binary_accuracy: 0.7222\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.2987 - binary_accuracy: 0.9074 - val_loss: 0.6583 - val_binary_accuracy: 0.7222\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.2779 - binary_accuracy: 0.8827 - val_loss: 0.6893 - val_binary_accuracy: 0.7222\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 299us/step - loss: 0.2741 - binary_accuracy: 0.8951 - val_loss: 0.7039 - val_binary_accuracy: 0.7222\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 300us/step - loss: 0.2873 - binary_accuracy: 0.8889 - val_loss: 0.7020 - val_binary_accuracy: 0.7222\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.2755 - binary_accuracy: 0.8827 - val_loss: 0.6506 - val_binary_accuracy: 0.7222\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 304us/step - loss: 0.2530 - binary_accuracy: 0.9012 - val_loss: 0.6308 - val_binary_accuracy: 0.7222\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.2488 - binary_accuracy: 0.9136 - val_loss: 0.6249 - val_binary_accuracy: 0.7778\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.2346 - binary_accuracy: 0.9198 - val_loss: 0.6297 - val_binary_accuracy: 0.7778\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.2334 - binary_accuracy: 0.9259 - val_loss: 0.6711 - val_binary_accuracy: 0.7778\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.2204 - binary_accuracy: 0.9383 - val_loss: 0.7316 - val_binary_accuracy: 0.7222\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 292us/step - loss: 0.2352 - binary_accuracy: 0.9259 - val_loss: 0.7487 - val_binary_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 297us/step - loss: 0.2443 - binary_accuracy: 0.9198 - val_loss: 0.7525 - val_binary_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.2081 - binary_accuracy: 0.9383 - val_loss: 0.7564 - val_binary_accuracy: 0.7222\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.2126 - binary_accuracy: 0.9444 - val_loss: 0.7600 - val_binary_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.1945 - binary_accuracy: 0.9444 - val_loss: 0.7445 - val_binary_accuracy: 0.7222\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 301us/step - loss: 0.1848 - binary_accuracy: 0.9506 - val_loss: 0.7594 - val_binary_accuracy: 0.7222\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.1951 - binary_accuracy: 0.9506 - val_loss: 0.7568 - val_binary_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.1753 - binary_accuracy: 0.9444 - val_loss: 0.7419 - val_binary_accuracy: 0.7222\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 331us/step - loss: 0.1467 - binary_accuracy: 0.9321 - val_loss: 0.7521 - val_binary_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.2062 - binary_accuracy: 0.9136 - val_loss: 0.7636 - val_binary_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.1756 - binary_accuracy: 0.9506 - val_loss: 0.7597 - val_binary_accuracy: 0.7778\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.2051 - binary_accuracy: 0.9383 - val_loss: 0.7168 - val_binary_accuracy: 0.7778\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 306us/step - loss: 0.1998 - binary_accuracy: 0.9383 - val_loss: 0.7056 - val_binary_accuracy: 0.7222\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.1835 - binary_accuracy: 0.9568 - val_loss: 0.6563 - val_binary_accuracy: 0.7222\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.2313 - binary_accuracy: 0.9259 - val_loss: 0.6413 - val_binary_accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.2028 - binary_accuracy: 0.9321 - val_loss: 0.6353 - val_binary_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.1637 - binary_accuracy: 0.9568 - val_loss: 0.6466 - val_binary_accuracy: 0.7222\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 311us/step - loss: 0.2094 - binary_accuracy: 0.9321 - val_loss: 0.6512 - val_binary_accuracy: 0.7222\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2204 - binary_accuracy: 0.9136 - val_loss: 0.6431 - val_binary_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.1680 - binary_accuracy: 0.9506 - val_loss: 0.6861 - val_binary_accuracy: 0.7222\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.1612 - binary_accuracy: 0.9444 - val_loss: 0.7405 - val_binary_accuracy: 0.7222\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 291us/step - loss: 0.1524 - binary_accuracy: 0.9568 - val_loss: 0.8059 - val_binary_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.1446 - binary_accuracy: 0.9630 - val_loss: 0.8305 - val_binary_accuracy: 0.6111\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.1639 - binary_accuracy: 0.9506 - val_loss: 0.8194 - val_binary_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 286us/step - loss: 0.1013 - binary_accuracy: 0.9815 - val_loss: 0.8930 - val_binary_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.1495 - binary_accuracy: 0.9506 - val_loss: 0.9553 - val_binary_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.1539 - binary_accuracy: 0.9383 - val_loss: 0.9279 - val_binary_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.1336 - binary_accuracy: 0.9444 - val_loss: 0.8481 - val_binary_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.1293 - binary_accuracy: 0.9568 - val_loss: 0.7897 - val_binary_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 293us/step - loss: 0.1698 - binary_accuracy: 0.9444 - val_loss: 0.7112 - val_binary_accuracy: 0.7222\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.1317 - binary_accuracy: 0.9630 - val_loss: 0.7364 - val_binary_accuracy: 0.7778\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.1602 - binary_accuracy: 0.9321 - val_loss: 0.8537 - val_binary_accuracy: 0.7778\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.1331 - binary_accuracy: 0.9321 - val_loss: 0.8576 - val_binary_accuracy: 0.7778\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.1900 - binary_accuracy: 0.9321 - val_loss: 0.8305 - val_binary_accuracy: 0.7778\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 283us/step - loss: 0.1564 - binary_accuracy: 0.9444 - val_loss: 0.8101 - val_binary_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.1843 - binary_accuracy: 0.9198 - val_loss: 0.7353 - val_binary_accuracy: 0.7222\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.1322 - binary_accuracy: 0.9753 - val_loss: 0.7464 - val_binary_accuracy: 0.7222\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.2262 - binary_accuracy: 0.9321 - val_loss: 0.8224 - val_binary_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.1924 - binary_accuracy: 0.9136 - val_loss: 0.8701 - val_binary_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.1755 - binary_accuracy: 0.9444 - val_loss: 0.8985 - val_binary_accuracy: 0.7222\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 232us/step - loss: 0.2415 - binary_accuracy: 0.8827 - val_loss: 0.8055 - val_binary_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.1717 - binary_accuracy: 0.9506 - val_loss: 0.7814 - val_binary_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.2476 - binary_accuracy: 0.8827 - val_loss: 0.7976 - val_binary_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.2110 - binary_accuracy: 0.9012 - val_loss: 0.7945 - val_binary_accuracy: 0.7778\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.1731 - binary_accuracy: 0.9444 - val_loss: 0.8016 - val_binary_accuracy: 0.7778\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 224us/step - loss: 0.2202 - binary_accuracy: 0.9444 - val_loss: 0.8352 - val_binary_accuracy: 0.7778\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.1290 - binary_accuracy: 0.9568 - val_loss: 0.8640 - val_binary_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.1286 - binary_accuracy: 0.9691 - val_loss: 0.8297 - val_binary_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.1295 - binary_accuracy: 0.9568 - val_loss: 0.8176 - val_binary_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.1165 - binary_accuracy: 0.9753 - val_loss: 0.7464 - val_binary_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.1851 - binary_accuracy: 0.9321 - val_loss: 0.7452 - val_binary_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.1696 - binary_accuracy: 0.9444 - val_loss: 0.8839 - val_binary_accuracy: 0.7778\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.1671 - binary_accuracy: 0.9444 - val_loss: 0.8965 - val_binary_accuracy: 0.7222\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.2185 - binary_accuracy: 0.9136 - val_loss: 0.8411 - val_binary_accuracy: 0.7778\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.0952 - binary_accuracy: 0.9815 - val_loss: 0.8278 - val_binary_accuracy: 0.7778\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1588 - binary_accuracy: 0.9506 - val_loss: 0.8399 - val_binary_accuracy: 0.7778\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.1395 - binary_accuracy: 0.9444 - val_loss: 0.8519 - val_binary_accuracy: 0.7222\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.1186 - binary_accuracy: 0.9691 - val_loss: 0.8561 - val_binary_accuracy: 0.7222\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.0988 - binary_accuracy: 0.9753 - val_loss: 0.8711 - val_binary_accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.1440 - binary_accuracy: 0.9630 - val_loss: 0.8828 - val_binary_accuracy: 0.7222\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.0897 - binary_accuracy: 0.9815 - val_loss: 1.0937 - val_binary_accuracy: 0.7222\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.0871 - binary_accuracy: 0.9815 - val_loss: 1.1786 - val_binary_accuracy: 0.7222\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.1240 - binary_accuracy: 0.9630 - val_loss: 1.1148 - val_binary_accuracy: 0.7222\n",
      "18/18 [==============================] - 0s 74us/step\n",
      "\n",
      "Fold  5\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 2s 15ms/step - loss: 0.7559 - binary_accuracy: 0.5802 - val_loss: 0.3098 - val_binary_accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.5666 - binary_accuracy: 0.7531 - val_loss: 0.2464 - val_binary_accuracy: 0.9444\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.5907 - binary_accuracy: 0.7284 - val_loss: 0.1790 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 209us/step - loss: 0.4865 - binary_accuracy: 0.7963 - val_loss: 0.1995 - val_binary_accuracy: 0.9444\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 199us/step - loss: 0.4788 - binary_accuracy: 0.7716 - val_loss: 0.1841 - val_binary_accuracy: 0.9444\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.4640 - binary_accuracy: 0.7716 - val_loss: 0.1525 - val_binary_accuracy: 0.9444\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.4716 - binary_accuracy: 0.7840 - val_loss: 0.1352 - val_binary_accuracy: 0.9444\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 214us/step - loss: 0.4532 - binary_accuracy: 0.7778 - val_loss: 0.1551 - val_binary_accuracy: 0.9444\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 208us/step - loss: 0.4075 - binary_accuracy: 0.8210 - val_loss: 0.1719 - val_binary_accuracy: 0.9444\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 219us/step - loss: 0.3969 - binary_accuracy: 0.8395 - val_loss: 0.1716 - val_binary_accuracy: 0.9444\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.4199 - binary_accuracy: 0.8272 - val_loss: 0.1682 - val_binary_accuracy: 0.9444\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.3996 - binary_accuracy: 0.8580 - val_loss: 0.1830 - val_binary_accuracy: 0.9444\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 209us/step - loss: 0.3751 - binary_accuracy: 0.8457 - val_loss: 0.2421 - val_binary_accuracy: 0.8889\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 222us/step - loss: 0.3859 - binary_accuracy: 0.8210 - val_loss: 0.2173 - val_binary_accuracy: 0.9444\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2903 - binary_accuracy: 0.8889 - val_loss: 0.2039 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.2935 - binary_accuracy: 0.8951 - val_loss: 0.1814 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 205us/step - loss: 0.2935 - binary_accuracy: 0.8580 - val_loss: 0.2296 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 219us/step - loss: 0.2540 - binary_accuracy: 0.8889 - val_loss: 0.2925 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.3181 - binary_accuracy: 0.8333 - val_loss: 0.2700 - val_binary_accuracy: 0.7778\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2963 - binary_accuracy: 0.8642 - val_loss: 0.1762 - val_binary_accuracy: 0.9444\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 217us/step - loss: 0.2899 - binary_accuracy: 0.8642 - val_loss: 0.1969 - val_binary_accuracy: 0.8889\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 224us/step - loss: 0.3051 - binary_accuracy: 0.8765 - val_loss: 0.2578 - val_binary_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2782 - binary_accuracy: 0.8827 - val_loss: 0.2361 - val_binary_accuracy: 0.8889\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.2676 - binary_accuracy: 0.8889 - val_loss: 0.1880 - val_binary_accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 220us/step - loss: 0.2609 - binary_accuracy: 0.8765 - val_loss: 0.1949 - val_binary_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.2429 - binary_accuracy: 0.9321 - val_loss: 0.2327 - val_binary_accuracy: 0.8889\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.3060 - binary_accuracy: 0.8889 - val_loss: 0.3278 - val_binary_accuracy: 0.7222\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 252us/step - loss: 0.2794 - binary_accuracy: 0.8951 - val_loss: 0.3218 - val_binary_accuracy: 0.7222\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 221us/step - loss: 0.2783 - binary_accuracy: 0.8827 - val_loss: 0.3145 - val_binary_accuracy: 0.7778\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.3114 - binary_accuracy: 0.8580 - val_loss: 0.3326 - val_binary_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2690 - binary_accuracy: 0.8765 - val_loss: 0.4052 - val_binary_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.2517 - binary_accuracy: 0.8765 - val_loss: 0.3922 - val_binary_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.2461 - binary_accuracy: 0.9012 - val_loss: 0.3349 - val_binary_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 218us/step - loss: 0.2559 - binary_accuracy: 0.8951 - val_loss: 0.2561 - val_binary_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 212us/step - loss: 0.2332 - binary_accuracy: 0.9321 - val_loss: 0.2551 - val_binary_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.2536 - binary_accuracy: 0.9074 - val_loss: 0.2867 - val_binary_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2217 - binary_accuracy: 0.9136 - val_loss: 0.3405 - val_binary_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 212us/step - loss: 0.2201 - binary_accuracy: 0.9074 - val_loss: 0.3170 - val_binary_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.1990 - binary_accuracy: 0.9259 - val_loss: 0.3065 - val_binary_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.1939 - binary_accuracy: 0.9383 - val_loss: 0.3034 - val_binary_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.2381 - binary_accuracy: 0.9074 - val_loss: 0.3378 - val_binary_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 220us/step - loss: 0.1922 - binary_accuracy: 0.9383 - val_loss: 0.4086 - val_binary_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 221us/step - loss: 0.2420 - binary_accuracy: 0.9198 - val_loss: 0.4421 - val_binary_accuracy: 0.7778\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2239 - binary_accuracy: 0.9012 - val_loss: 0.4435 - val_binary_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2505 - binary_accuracy: 0.9012 - val_loss: 0.4657 - val_binary_accuracy: 0.7778\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 217us/step - loss: 0.2233 - binary_accuracy: 0.9136 - val_loss: 0.4696 - val_binary_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.2192 - binary_accuracy: 0.9074 - val_loss: 0.4723 - val_binary_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.2185 - binary_accuracy: 0.9012 - val_loss: 0.4284 - val_binary_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 210us/step - loss: 0.2417 - binary_accuracy: 0.9198 - val_loss: 0.4348 - val_binary_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 196us/step - loss: 0.2662 - binary_accuracy: 0.8951 - val_loss: 0.4551 - val_binary_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 198us/step - loss: 0.2145 - binary_accuracy: 0.9198 - val_loss: 0.4294 - val_binary_accuracy: 0.8333\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 213us/step - loss: 0.2060 - binary_accuracy: 0.9321 - val_loss: 0.4315 - val_binary_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 215us/step - loss: 0.2520 - binary_accuracy: 0.9074 - val_loss: 0.3848 - val_binary_accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 199us/step - loss: 0.2219 - binary_accuracy: 0.9012 - val_loss: 0.3762 - val_binary_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 207us/step - loss: 0.2130 - binary_accuracy: 0.9136 - val_loss: 0.3958 - val_binary_accuracy: 0.8333\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 252us/step - loss: 0.1776 - binary_accuracy: 0.9383 - val_loss: 0.3715 - val_binary_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.2535 - binary_accuracy: 0.9136 - val_loss: 0.3503 - val_binary_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.1817 - binary_accuracy: 0.9444 - val_loss: 0.3741 - val_binary_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2204 - binary_accuracy: 0.9136 - val_loss: 0.3394 - val_binary_accuracy: 0.8889\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.2432 - binary_accuracy: 0.8889 - val_loss: 0.3394 - val_binary_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.1658 - binary_accuracy: 0.9506 - val_loss: 0.3016 - val_binary_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.2266 - binary_accuracy: 0.9074 - val_loss: 0.3204 - val_binary_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.1913 - binary_accuracy: 0.9383 - val_loss: 0.3137 - val_binary_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1937 - binary_accuracy: 0.9383 - val_loss: 0.2794 - val_binary_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 295us/step - loss: 0.1594 - binary_accuracy: 0.9444 - val_loss: 0.3221 - val_binary_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.1774 - binary_accuracy: 0.9444 - val_loss: 0.3325 - val_binary_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.1937 - binary_accuracy: 0.9198 - val_loss: 0.2823 - val_binary_accuracy: 0.8889\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.1497 - binary_accuracy: 0.9568 - val_loss: 0.2976 - val_binary_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.1581 - binary_accuracy: 0.9321 - val_loss: 0.3007 - val_binary_accuracy: 0.8889\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.1468 - binary_accuracy: 0.9568 - val_loss: 0.2905 - val_binary_accuracy: 0.8889\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.1427 - binary_accuracy: 0.9383 - val_loss: 0.2776 - val_binary_accuracy: 0.8889\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.2098 - binary_accuracy: 0.9198 - val_loss: 0.3071 - val_binary_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 260us/step - loss: 0.1389 - binary_accuracy: 0.9506 - val_loss: 0.2894 - val_binary_accuracy: 0.8889\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.1950 - binary_accuracy: 0.9074 - val_loss: 0.3963 - val_binary_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 220us/step - loss: 0.3235 - binary_accuracy: 0.8951 - val_loss: 0.4098 - val_binary_accuracy: 0.8889\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.3224 - binary_accuracy: 0.8704 - val_loss: 0.3032 - val_binary_accuracy: 0.8889\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.2883 - binary_accuracy: 0.8827 - val_loss: 0.2543 - val_binary_accuracy: 0.8889\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.2488 - binary_accuracy: 0.9074 - val_loss: 0.2363 - val_binary_accuracy: 0.8889\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 230us/step - loss: 0.3194 - binary_accuracy: 0.8642 - val_loss: 0.2745 - val_binary_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.2640 - binary_accuracy: 0.9074 - val_loss: 0.2330 - val_binary_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.2801 - binary_accuracy: 0.9012 - val_loss: 0.2596 - val_binary_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.2035 - binary_accuracy: 0.9259 - val_loss: 0.3253 - val_binary_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.2228 - binary_accuracy: 0.9012 - val_loss: 0.3709 - val_binary_accuracy: 0.7778\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.1862 - binary_accuracy: 0.9383 - val_loss: 0.3539 - val_binary_accuracy: 0.7778\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.2368 - binary_accuracy: 0.9012 - val_loss: 0.3844 - val_binary_accuracy: 0.7778\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.2192 - binary_accuracy: 0.9259 - val_loss: 0.4728 - val_binary_accuracy: 0.7778\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 230us/step - loss: 0.2597 - binary_accuracy: 0.8951 - val_loss: 0.4481 - val_binary_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 217us/step - loss: 0.2040 - binary_accuracy: 0.9136 - val_loss: 0.3055 - val_binary_accuracy: 0.8889\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.2237 - binary_accuracy: 0.9259 - val_loss: 0.2976 - val_binary_accuracy: 0.8889\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.2215 - binary_accuracy: 0.9198 - val_loss: 0.2216 - val_binary_accuracy: 0.8889\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.2388 - binary_accuracy: 0.9012 - val_loss: 0.1500 - val_binary_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.3469 - binary_accuracy: 0.8580 - val_loss: 0.1660 - val_binary_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.3314 - binary_accuracy: 0.8519 - val_loss: 0.2033 - val_binary_accuracy: 0.8889\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.3612 - binary_accuracy: 0.8519 - val_loss: 0.2152 - val_binary_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 292us/step - loss: 0.3551 - binary_accuracy: 0.8333 - val_loss: 0.2544 - val_binary_accuracy: 0.8889\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.3326 - binary_accuracy: 0.8642 - val_loss: 0.2855 - val_binary_accuracy: 0.8889\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.3036 - binary_accuracy: 0.8827 - val_loss: 0.2975 - val_binary_accuracy: 0.8889\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 247us/step - loss: 0.3497 - binary_accuracy: 0.8642 - val_loss: 0.3060 - val_binary_accuracy: 0.8889\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.3193 - binary_accuracy: 0.8889 - val_loss: 0.2940 - val_binary_accuracy: 0.8889\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 291us/step - loss: 0.3005 - binary_accuracy: 0.8642 - val_loss: 0.2891 - val_binary_accuracy: 0.8889\n",
      "18/18 [==============================] - 0s 156us/step\n",
      "\n",
      "Fold  6\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.7106 - binary_accuracy: 0.5988 - val_loss: 0.6258 - val_binary_accuracy: 0.7222\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 312us/step - loss: 0.5908 - binary_accuracy: 0.7160 - val_loss: 0.4823 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 335us/step - loss: 0.4663 - binary_accuracy: 0.7593 - val_loss: 0.3951 - val_binary_accuracy: 0.7778\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 312us/step - loss: 0.4726 - binary_accuracy: 0.7654 - val_loss: 0.3951 - val_binary_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 322us/step - loss: 0.4482 - binary_accuracy: 0.8086 - val_loss: 0.4281 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.3865 - binary_accuracy: 0.8210 - val_loss: 0.4291 - val_binary_accuracy: 0.8889\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 307us/step - loss: 0.3685 - binary_accuracy: 0.8704 - val_loss: 0.3912 - val_binary_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 343us/step - loss: 0.3487 - binary_accuracy: 0.8765 - val_loss: 0.3662 - val_binary_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 334us/step - loss: 0.2970 - binary_accuracy: 0.8642 - val_loss: 0.3512 - val_binary_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 309us/step - loss: 0.4089 - binary_accuracy: 0.7963 - val_loss: 0.3852 - val_binary_accuracy: 0.8889\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.3430 - binary_accuracy: 0.8395 - val_loss: 0.3517 - val_binary_accuracy: 0.8889\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 301us/step - loss: 0.2752 - binary_accuracy: 0.8827 - val_loss: 0.3439 - val_binary_accuracy: 0.8889\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 314us/step - loss: 0.2729 - binary_accuracy: 0.8827 - val_loss: 0.4020 - val_binary_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 311us/step - loss: 0.2848 - binary_accuracy: 0.8765 - val_loss: 0.3994 - val_binary_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 318us/step - loss: 0.2677 - binary_accuracy: 0.8827 - val_loss: 0.3779 - val_binary_accuracy: 0.8889\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 354us/step - loss: 0.3004 - binary_accuracy: 0.8642 - val_loss: 0.4344 - val_binary_accuracy: 0.8889\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 323us/step - loss: 0.2261 - binary_accuracy: 0.9012 - val_loss: 0.4918 - val_binary_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 343us/step - loss: 0.2735 - binary_accuracy: 0.9074 - val_loss: 0.4283 - val_binary_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 300us/step - loss: 0.2547 - binary_accuracy: 0.8580 - val_loss: 0.3149 - val_binary_accuracy: 0.8889\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 330us/step - loss: 0.2354 - binary_accuracy: 0.9074 - val_loss: 0.3151 - val_binary_accuracy: 0.8889\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 320us/step - loss: 0.2521 - binary_accuracy: 0.8951 - val_loss: 0.1996 - val_binary_accuracy: 0.9444\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.2395 - binary_accuracy: 0.8889 - val_loss: 0.1167 - val_binary_accuracy: 0.9444\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.2505 - binary_accuracy: 0.9136 - val_loss: 0.1891 - val_binary_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 299us/step - loss: 0.2779 - binary_accuracy: 0.8642 - val_loss: 0.3345 - val_binary_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 303us/step - loss: 0.2526 - binary_accuracy: 0.9012 - val_loss: 0.3096 - val_binary_accuracy: 0.8889\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.2538 - binary_accuracy: 0.9198 - val_loss: 0.2865 - val_binary_accuracy: 0.8889\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 293us/step - loss: 0.2565 - binary_accuracy: 0.9074 - val_loss: 0.3461 - val_binary_accuracy: 0.8889\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 299us/step - loss: 0.2347 - binary_accuracy: 0.8951 - val_loss: 0.3561 - val_binary_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 301us/step - loss: 0.2726 - binary_accuracy: 0.9012 - val_loss: 0.3478 - val_binary_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.2756 - binary_accuracy: 0.9012 - val_loss: 0.3128 - val_binary_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.2224 - binary_accuracy: 0.9383 - val_loss: 0.2969 - val_binary_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2546 - binary_accuracy: 0.9074 - val_loss: 0.3236 - val_binary_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 297us/step - loss: 0.1788 - binary_accuracy: 0.9444 - val_loss: 0.3415 - val_binary_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.2036 - binary_accuracy: 0.9136 - val_loss: 0.3046 - val_binary_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.1596 - binary_accuracy: 0.9568 - val_loss: 0.2712 - val_binary_accuracy: 0.8889\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 280us/step - loss: 0.2449 - binary_accuracy: 0.8889 - val_loss: 0.3523 - val_binary_accuracy: 0.8889\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.1819 - binary_accuracy: 0.9259 - val_loss: 0.4382 - val_binary_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.1909 - binary_accuracy: 0.9136 - val_loss: 0.3624 - val_binary_accuracy: 0.8889\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.2046 - binary_accuracy: 0.9136 - val_loss: 0.3329 - val_binary_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.1994 - binary_accuracy: 0.9383 - val_loss: 0.3110 - val_binary_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 306us/step - loss: 0.1973 - binary_accuracy: 0.9506 - val_loss: 0.2986 - val_binary_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 402us/step - loss: 0.1867 - binary_accuracy: 0.9321 - val_loss: 0.3283 - val_binary_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.2484 - binary_accuracy: 0.8889 - val_loss: 0.3670 - val_binary_accuracy: 0.8889\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 301us/step - loss: 0.1935 - binary_accuracy: 0.9321 - val_loss: 0.4126 - val_binary_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 286us/step - loss: 0.2163 - binary_accuracy: 0.9198 - val_loss: 0.3851 - val_binary_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 295us/step - loss: 0.1700 - binary_accuracy: 0.9444 - val_loss: 0.3103 - val_binary_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.2104 - binary_accuracy: 0.9198 - val_loss: 0.2225 - val_binary_accuracy: 0.9444\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 291us/step - loss: 0.1925 - binary_accuracy: 0.9259 - val_loss: 0.2068 - val_binary_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 325us/step - loss: 0.1686 - binary_accuracy: 0.9506 - val_loss: 0.2276 - val_binary_accuracy: 0.9444\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.1455 - binary_accuracy: 0.9568 - val_loss: 0.2566 - val_binary_accuracy: 0.8889\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.1516 - binary_accuracy: 0.9506 - val_loss: 0.2568 - val_binary_accuracy: 0.8889\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.1420 - binary_accuracy: 0.9444 - val_loss: 0.2573 - val_binary_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 284us/step - loss: 0.1012 - binary_accuracy: 0.9753 - val_loss: 0.4646 - val_binary_accuracy: 0.7778\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 286us/step - loss: 0.2582 - binary_accuracy: 0.9012 - val_loss: 0.5496 - val_binary_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 260us/step - loss: 0.1344 - binary_accuracy: 0.9506 - val_loss: 0.5336 - val_binary_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.1651 - binary_accuracy: 0.9506 - val_loss: 0.4739 - val_binary_accuracy: 0.8333\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 273us/step - loss: 0.1728 - binary_accuracy: 0.9444 - val_loss: 0.5108 - val_binary_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 293us/step - loss: 0.2138 - binary_accuracy: 0.9259 - val_loss: 0.4706 - val_binary_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.1625 - binary_accuracy: 0.9321 - val_loss: 0.4226 - val_binary_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.1543 - binary_accuracy: 0.9444 - val_loss: 0.3855 - val_binary_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.1184 - binary_accuracy: 0.9568 - val_loss: 0.3974 - val_binary_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 294us/step - loss: 0.1429 - binary_accuracy: 0.9568 - val_loss: 0.4244 - val_binary_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 352us/step - loss: 0.0928 - binary_accuracy: 0.9691 - val_loss: 0.5048 - val_binary_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.1634 - binary_accuracy: 0.9506 - val_loss: 0.5199 - val_binary_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.1148 - binary_accuracy: 0.9691 - val_loss: 0.5484 - val_binary_accuracy: 0.7778\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 323us/step - loss: 0.1152 - binary_accuracy: 0.9568 - val_loss: 0.5241 - val_binary_accuracy: 0.7778\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.1110 - binary_accuracy: 0.9691 - val_loss: 0.4893 - val_binary_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.1137 - binary_accuracy: 0.9630 - val_loss: 0.4474 - val_binary_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.1013 - binary_accuracy: 0.9691 - val_loss: 0.4523 - val_binary_accuracy: 0.8889\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 314us/step - loss: 0.2171 - binary_accuracy: 0.8889 - val_loss: 0.4245 - val_binary_accuracy: 0.8889\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 299us/step - loss: 0.1877 - binary_accuracy: 0.9444 - val_loss: 0.4456 - val_binary_accuracy: 0.8889\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.1985 - binary_accuracy: 0.9074 - val_loss: 0.4038 - val_binary_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 286us/step - loss: 0.1559 - binary_accuracy: 0.9321 - val_loss: 0.4013 - val_binary_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 300us/step - loss: 0.1553 - binary_accuracy: 0.9568 - val_loss: 0.3968 - val_binary_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 312us/step - loss: 0.1450 - binary_accuracy: 0.9568 - val_loss: 0.3764 - val_binary_accuracy: 0.7778\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.1162 - binary_accuracy: 0.9691 - val_loss: 0.3483 - val_binary_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.1048 - binary_accuracy: 0.9630 - val_loss: 0.3702 - val_binary_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 291us/step - loss: 0.1501 - binary_accuracy: 0.9506 - val_loss: 0.4285 - val_binary_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 311us/step - loss: 0.1290 - binary_accuracy: 0.9630 - val_loss: 0.4480 - val_binary_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.1785 - binary_accuracy: 0.9259 - val_loss: 0.3394 - val_binary_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.1336 - binary_accuracy: 0.9568 - val_loss: 0.3035 - val_binary_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.1848 - binary_accuracy: 0.9198 - val_loss: 0.3206 - val_binary_accuracy: 0.8889\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 283us/step - loss: 0.1295 - binary_accuracy: 0.9568 - val_loss: 0.3424 - val_binary_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.1158 - binary_accuracy: 0.9568 - val_loss: 0.3531 - val_binary_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.1061 - binary_accuracy: 0.9877 - val_loss: 0.3403 - val_binary_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 301us/step - loss: 0.1724 - binary_accuracy: 0.9321 - val_loss: 0.3863 - val_binary_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.1113 - binary_accuracy: 0.9753 - val_loss: 0.4871 - val_binary_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 307us/step - loss: 0.1226 - binary_accuracy: 0.9506 - val_loss: 0.4629 - val_binary_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.1328 - binary_accuracy: 0.9691 - val_loss: 0.4458 - val_binary_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 286us/step - loss: 0.1673 - binary_accuracy: 0.9506 - val_loss: 0.4962 - val_binary_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 312us/step - loss: 0.1422 - binary_accuracy: 0.9568 - val_loss: 0.4874 - val_binary_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 308us/step - loss: 0.1467 - binary_accuracy: 0.9198 - val_loss: 0.4235 - val_binary_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.2265 - binary_accuracy: 0.9321 - val_loss: 0.4084 - val_binary_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 304us/step - loss: 0.1235 - binary_accuracy: 0.9815 - val_loss: 0.4116 - val_binary_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 299us/step - loss: 0.1908 - binary_accuracy: 0.9383 - val_loss: 0.3819 - val_binary_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.1504 - binary_accuracy: 0.9630 - val_loss: 0.3179 - val_binary_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.1595 - binary_accuracy: 0.9444 - val_loss: 0.3016 - val_binary_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.1100 - binary_accuracy: 0.9815 - val_loss: 0.2622 - val_binary_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 345us/step - loss: 0.1308 - binary_accuracy: 0.9753 - val_loss: 0.2496 - val_binary_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.2094 - binary_accuracy: 0.9444 - val_loss: 0.2541 - val_binary_accuracy: 0.8333\n",
      "18/18 [==============================] - 0s 143us/step\n",
      "\n",
      "Fold  7\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6725 - binary_accuracy: 0.5679 - val_loss: 0.8352 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 313us/step - loss: 0.5343 - binary_accuracy: 0.7840 - val_loss: 0.6841 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 288us/step - loss: 0.5400 - binary_accuracy: 0.7469 - val_loss: 0.5409 - val_binary_accuracy: 0.7222\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.4766 - binary_accuracy: 0.7963 - val_loss: 0.4895 - val_binary_accuracy: 0.7222\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.4418 - binary_accuracy: 0.8025 - val_loss: 0.4729 - val_binary_accuracy: 0.7222\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.4886 - binary_accuracy: 0.7716 - val_loss: 0.5151 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 283us/step - loss: 0.4242 - binary_accuracy: 0.8333 - val_loss: 0.6246 - val_binary_accuracy: 0.7222\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.4338 - binary_accuracy: 0.8210 - val_loss: 0.6678 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 310us/step - loss: 0.4096 - binary_accuracy: 0.8272 - val_loss: 0.5809 - val_binary_accuracy: 0.7778\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.4717 - binary_accuracy: 0.7716 - val_loss: 0.5921 - val_binary_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.4129 - binary_accuracy: 0.8210 - val_loss: 0.6594 - val_binary_accuracy: 0.5556\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.4059 - binary_accuracy: 0.8395 - val_loss: 0.7241 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 294us/step - loss: 0.4020 - binary_accuracy: 0.8457 - val_loss: 0.6197 - val_binary_accuracy: 0.5556\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 294us/step - loss: 0.4088 - binary_accuracy: 0.8272 - val_loss: 0.5576 - val_binary_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.3633 - binary_accuracy: 0.8704 - val_loss: 0.5350 - val_binary_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.3628 - binary_accuracy: 0.8272 - val_loss: 0.5061 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 297us/step - loss: 0.3619 - binary_accuracy: 0.8395 - val_loss: 0.5005 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 295us/step - loss: 0.3071 - binary_accuracy: 0.8704 - val_loss: 0.4752 - val_binary_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.2944 - binary_accuracy: 0.8889 - val_loss: 0.4112 - val_binary_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.3059 - binary_accuracy: 0.8765 - val_loss: 0.3922 - val_binary_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 284us/step - loss: 0.2418 - binary_accuracy: 0.9012 - val_loss: 0.4411 - val_binary_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 292us/step - loss: 0.3038 - binary_accuracy: 0.8580 - val_loss: 0.5006 - val_binary_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.2128 - binary_accuracy: 0.9074 - val_loss: 0.4379 - val_binary_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 309us/step - loss: 0.2241 - binary_accuracy: 0.9198 - val_loss: 0.4684 - val_binary_accuracy: 0.7778\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 293us/step - loss: 0.2797 - binary_accuracy: 0.8951 - val_loss: 0.4464 - val_binary_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 306us/step - loss: 0.2324 - binary_accuracy: 0.9012 - val_loss: 0.4179 - val_binary_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 286us/step - loss: 0.2254 - binary_accuracy: 0.9136 - val_loss: 0.5380 - val_binary_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 291us/step - loss: 0.3061 - binary_accuracy: 0.8889 - val_loss: 0.6941 - val_binary_accuracy: 0.7778\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 298us/step - loss: 0.3108 - binary_accuracy: 0.8642 - val_loss: 0.5657 - val_binary_accuracy: 0.7222\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 309us/step - loss: 0.3234 - binary_accuracy: 0.8580 - val_loss: 0.5333 - val_binary_accuracy: 0.7778\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 294us/step - loss: 0.2989 - binary_accuracy: 0.8951 - val_loss: 0.5267 - val_binary_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2503 - binary_accuracy: 0.9259 - val_loss: 0.5168 - val_binary_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 291us/step - loss: 0.2615 - binary_accuracy: 0.8889 - val_loss: 0.4955 - val_binary_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.3051 - binary_accuracy: 0.8765 - val_loss: 0.4583 - val_binary_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 278us/step - loss: 0.2569 - binary_accuracy: 0.8951 - val_loss: 0.4417 - val_binary_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 270us/step - loss: 0.2936 - binary_accuracy: 0.8704 - val_loss: 0.4369 - val_binary_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.2614 - binary_accuracy: 0.8889 - val_loss: 0.4453 - val_binary_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.2955 - binary_accuracy: 0.8765 - val_loss: 0.4159 - val_binary_accuracy: 0.8333\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2726 - binary_accuracy: 0.9012 - val_loss: 0.3854 - val_binary_accuracy: 0.7778\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 285us/step - loss: 0.2593 - binary_accuracy: 0.9321 - val_loss: 0.4093 - val_binary_accuracy: 0.7778\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 311us/step - loss: 0.2558 - binary_accuracy: 0.9259 - val_loss: 0.4073 - val_binary_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 333us/step - loss: 0.2335 - binary_accuracy: 0.8951 - val_loss: 0.4309 - val_binary_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 277us/step - loss: 0.2918 - binary_accuracy: 0.8827 - val_loss: 0.4362 - val_binary_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 293us/step - loss: 0.2178 - binary_accuracy: 0.9383 - val_loss: 0.4368 - val_binary_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.2262 - binary_accuracy: 0.9259 - val_loss: 0.4178 - val_binary_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 304us/step - loss: 0.3296 - binary_accuracy: 0.8704 - val_loss: 0.4262 - val_binary_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.2474 - binary_accuracy: 0.9136 - val_loss: 0.4841 - val_binary_accuracy: 0.7222\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 305us/step - loss: 0.2476 - binary_accuracy: 0.9198 - val_loss: 0.4507 - val_binary_accuracy: 0.7222\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.2272 - binary_accuracy: 0.8951 - val_loss: 0.4090 - val_binary_accuracy: 0.7778\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 299us/step - loss: 0.2361 - binary_accuracy: 0.9136 - val_loss: 0.4219 - val_binary_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 312us/step - loss: 0.2344 - binary_accuracy: 0.9012 - val_loss: 0.5214 - val_binary_accuracy: 0.7778\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.1801 - binary_accuracy: 0.9444 - val_loss: 0.5807 - val_binary_accuracy: 0.7778\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.2091 - binary_accuracy: 0.9444 - val_loss: 0.5187 - val_binary_accuracy: 0.7778\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 288us/step - loss: 0.2021 - binary_accuracy: 0.9259 - val_loss: 0.4948 - val_binary_accuracy: 0.7778\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 306us/step - loss: 0.1464 - binary_accuracy: 0.9444 - val_loss: 0.4798 - val_binary_accuracy: 0.7778\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.2135 - binary_accuracy: 0.9198 - val_loss: 0.4427 - val_binary_accuracy: 0.7778\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 293us/step - loss: 0.2770 - binary_accuracy: 0.8642 - val_loss: 0.3633 - val_binary_accuracy: 0.8889\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 265us/step - loss: 0.2123 - binary_accuracy: 0.9321 - val_loss: 0.3323 - val_binary_accuracy: 0.8889\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.1714 - binary_accuracy: 0.9506 - val_loss: 0.3575 - val_binary_accuracy: 0.7778\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2003 - binary_accuracy: 0.9136 - val_loss: 0.3993 - val_binary_accuracy: 0.7778\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2014 - binary_accuracy: 0.9198 - val_loss: 0.4648 - val_binary_accuracy: 0.7778\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.1982 - binary_accuracy: 0.9259 - val_loss: 0.5759 - val_binary_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 260us/step - loss: 0.2395 - binary_accuracy: 0.9259 - val_loss: 0.5331 - val_binary_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.1746 - binary_accuracy: 0.9444 - val_loss: 0.4601 - val_binary_accuracy: 0.7222\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 236us/step - loss: 0.1774 - binary_accuracy: 0.9259 - val_loss: 0.4694 - val_binary_accuracy: 0.7222\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.2221 - binary_accuracy: 0.9321 - val_loss: 0.5105 - val_binary_accuracy: 0.7222\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 302us/step - loss: 0.1866 - binary_accuracy: 0.9383 - val_loss: 0.4917 - val_binary_accuracy: 0.7222\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1791 - binary_accuracy: 0.9630 - val_loss: 0.4546 - val_binary_accuracy: 0.8333\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.1862 - binary_accuracy: 0.9383 - val_loss: 0.4529 - val_binary_accuracy: 0.8889\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 284us/step - loss: 0.1753 - binary_accuracy: 0.9383 - val_loss: 0.4583 - val_binary_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.1415 - binary_accuracy: 0.9630 - val_loss: 0.4568 - val_binary_accuracy: 0.7778\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.2017 - binary_accuracy: 0.9259 - val_loss: 0.4926 - val_binary_accuracy: 0.7222\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 236us/step - loss: 0.1526 - binary_accuracy: 0.9383 - val_loss: 0.5034 - val_binary_accuracy: 0.7222\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.1352 - binary_accuracy: 0.9630 - val_loss: 0.4871 - val_binary_accuracy: 0.7778\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.1711 - binary_accuracy: 0.9444 - val_loss: 0.4891 - val_binary_accuracy: 0.7222\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.1692 - binary_accuracy: 0.9321 - val_loss: 0.4348 - val_binary_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.1602 - binary_accuracy: 0.9506 - val_loss: 0.3784 - val_binary_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.1341 - binary_accuracy: 0.9630 - val_loss: 0.3587 - val_binary_accuracy: 0.8889\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 295us/step - loss: 0.1940 - binary_accuracy: 0.9321 - val_loss: 0.3898 - val_binary_accuracy: 0.8889\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.1550 - binary_accuracy: 0.9506 - val_loss: 0.4085 - val_binary_accuracy: 0.8889\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.1374 - binary_accuracy: 0.9444 - val_loss: 0.4121 - val_binary_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.1000 - binary_accuracy: 0.9753 - val_loss: 0.4485 - val_binary_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.1253 - binary_accuracy: 0.9691 - val_loss: 0.4407 - val_binary_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.1578 - binary_accuracy: 0.9630 - val_loss: 0.4865 - val_binary_accuracy: 0.7778\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.1564 - binary_accuracy: 0.9506 - val_loss: 0.4412 - val_binary_accuracy: 0.7778\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.1421 - binary_accuracy: 0.9444 - val_loss: 0.4285 - val_binary_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.1763 - binary_accuracy: 0.9444 - val_loss: 0.4607 - val_binary_accuracy: 0.7778\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.1848 - binary_accuracy: 0.9383 - val_loss: 0.4213 - val_binary_accuracy: 0.7778\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.2078 - binary_accuracy: 0.9383 - val_loss: 0.4112 - val_binary_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2070 - binary_accuracy: 0.9012 - val_loss: 0.4087 - val_binary_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 291us/step - loss: 0.1815 - binary_accuracy: 0.9506 - val_loss: 0.3968 - val_binary_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.2089 - binary_accuracy: 0.9383 - val_loss: 0.3949 - val_binary_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2113 - binary_accuracy: 0.9444 - val_loss: 0.4256 - val_binary_accuracy: 0.7778\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.2360 - binary_accuracy: 0.9259 - val_loss: 0.3723 - val_binary_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.2021 - binary_accuracy: 0.9321 - val_loss: 0.3430 - val_binary_accuracy: 0.7778\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.1703 - binary_accuracy: 0.9630 - val_loss: 0.3458 - val_binary_accuracy: 0.7778\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.1733 - binary_accuracy: 0.9506 - val_loss: 0.3837 - val_binary_accuracy: 0.7778\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.2527 - binary_accuracy: 0.9074 - val_loss: 0.6215 - val_binary_accuracy: 0.7222\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 282us/step - loss: 0.3109 - binary_accuracy: 0.8519 - val_loss: 0.5986 - val_binary_accuracy: 0.7778\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2771 - binary_accuracy: 0.8704 - val_loss: 0.5269 - val_binary_accuracy: 0.7778\n",
      "18/18 [==============================] - 0s 135us/step\n",
      "\n",
      "Fold  8\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6991 - binary_accuracy: 0.6605 - val_loss: 0.4973 - val_binary_accuracy: 0.7778\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.5413 - binary_accuracy: 0.7284 - val_loss: 0.4374 - val_binary_accuracy: 0.7778\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.5403 - binary_accuracy: 0.7160 - val_loss: 0.4549 - val_binary_accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.4675 - binary_accuracy: 0.7901 - val_loss: 0.5126 - val_binary_accuracy: 0.7778\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.4629 - binary_accuracy: 0.7716 - val_loss: 0.4995 - val_binary_accuracy: 0.7778\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.4359 - binary_accuracy: 0.8333 - val_loss: 0.4880 - val_binary_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.3785 - binary_accuracy: 0.8457 - val_loss: 0.4908 - val_binary_accuracy: 0.7778\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.3748 - binary_accuracy: 0.8704 - val_loss: 0.5083 - val_binary_accuracy: 0.7778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 201us/step - loss: 0.3421 - binary_accuracy: 0.8642 - val_loss: 0.5416 - val_binary_accuracy: 0.7222\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 209us/step - loss: 0.3226 - binary_accuracy: 0.8827 - val_loss: 0.5111 - val_binary_accuracy: 0.7222\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 217us/step - loss: 0.2909 - binary_accuracy: 0.9012 - val_loss: 0.5531 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.3082 - binary_accuracy: 0.8704 - val_loss: 0.5666 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2687 - binary_accuracy: 0.8827 - val_loss: 0.5615 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2787 - binary_accuracy: 0.8889 - val_loss: 0.5219 - val_binary_accuracy: 0.7222\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.2776 - binary_accuracy: 0.8889 - val_loss: 0.5402 - val_binary_accuracy: 0.7222\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.2600 - binary_accuracy: 0.9259 - val_loss: 0.5787 - val_binary_accuracy: 0.7222\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.2750 - binary_accuracy: 0.8951 - val_loss: 0.5756 - val_binary_accuracy: 0.7222\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.2952 - binary_accuracy: 0.8704 - val_loss: 0.6027 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2862 - binary_accuracy: 0.8889 - val_loss: 0.6273 - val_binary_accuracy: 0.7222\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.2453 - binary_accuracy: 0.9136 - val_loss: 0.6139 - val_binary_accuracy: 0.7222\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.2240 - binary_accuracy: 0.9259 - val_loss: 0.5621 - val_binary_accuracy: 0.7222\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.2476 - binary_accuracy: 0.9136 - val_loss: 0.5645 - val_binary_accuracy: 0.7222\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.2723 - binary_accuracy: 0.8765 - val_loss: 0.6012 - val_binary_accuracy: 0.7222\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.2302 - binary_accuracy: 0.9074 - val_loss: 0.6562 - val_binary_accuracy: 0.7222\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.3044 - binary_accuracy: 0.8642 - val_loss: 0.8403 - val_binary_accuracy: 0.7222\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.2131 - binary_accuracy: 0.9198 - val_loss: 0.7760 - val_binary_accuracy: 0.7222\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.2292 - binary_accuracy: 0.9259 - val_loss: 0.6258 - val_binary_accuracy: 0.7222\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.1894 - binary_accuracy: 0.9259 - val_loss: 0.5828 - val_binary_accuracy: 0.7778\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.2060 - binary_accuracy: 0.9198 - val_loss: 0.5641 - val_binary_accuracy: 0.7778\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.2043 - binary_accuracy: 0.9198 - val_loss: 0.5410 - val_binary_accuracy: 0.7222\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.1747 - binary_accuracy: 0.9321 - val_loss: 0.5290 - val_binary_accuracy: 0.7222\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.1857 - binary_accuracy: 0.9383 - val_loss: 0.6054 - val_binary_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 287us/step - loss: 0.1592 - binary_accuracy: 0.9506 - val_loss: 0.6879 - val_binary_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.1789 - binary_accuracy: 0.9198 - val_loss: 0.7384 - val_binary_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.1518 - binary_accuracy: 0.9691 - val_loss: 0.8694 - val_binary_accuracy: 0.6111\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1785 - binary_accuracy: 0.9321 - val_loss: 0.6827 - val_binary_accuracy: 0.7222\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.1963 - binary_accuracy: 0.9321 - val_loss: 0.5432 - val_binary_accuracy: 0.7222\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.2523 - binary_accuracy: 0.9012 - val_loss: 0.4732 - val_binary_accuracy: 0.7778\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.2042 - binary_accuracy: 0.9506 - val_loss: 0.5201 - val_binary_accuracy: 0.7778\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.2416 - binary_accuracy: 0.8642 - val_loss: 0.4129 - val_binary_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.2064 - binary_accuracy: 0.9012 - val_loss: 0.4074 - val_binary_accuracy: 0.7778\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.1908 - binary_accuracy: 0.9444 - val_loss: 0.4590 - val_binary_accuracy: 0.7222\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 284us/step - loss: 0.2036 - binary_accuracy: 0.9321 - val_loss: 0.4202 - val_binary_accuracy: 0.7778\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.1370 - binary_accuracy: 0.9630 - val_loss: 0.3665 - val_binary_accuracy: 0.7778\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.1709 - binary_accuracy: 0.9383 - val_loss: 0.4613 - val_binary_accuracy: 0.7778\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.1574 - binary_accuracy: 0.9506 - val_loss: 0.4358 - val_binary_accuracy: 0.7778\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 218us/step - loss: 0.2069 - binary_accuracy: 0.9136 - val_loss: 0.2615 - val_binary_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2254 - binary_accuracy: 0.9136 - val_loss: 0.3239 - val_binary_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.1834 - binary_accuracy: 0.9259 - val_loss: 0.3704 - val_binary_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.2095 - binary_accuracy: 0.9198 - val_loss: 0.4459 - val_binary_accuracy: 0.7778\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.1424 - binary_accuracy: 0.9630 - val_loss: 0.5520 - val_binary_accuracy: 0.7222\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.1556 - binary_accuracy: 0.9568 - val_loss: 0.6518 - val_binary_accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.2012 - binary_accuracy: 0.9321 - val_loss: 0.5925 - val_binary_accuracy: 0.7222\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.1888 - binary_accuracy: 0.9198 - val_loss: 0.5260 - val_binary_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1954 - binary_accuracy: 0.9259 - val_loss: 0.4874 - val_binary_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.1609 - binary_accuracy: 0.9691 - val_loss: 0.4796 - val_binary_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2127 - binary_accuracy: 0.9383 - val_loss: 0.5140 - val_binary_accuracy: 0.7778\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 260us/step - loss: 0.1484 - binary_accuracy: 0.9506 - val_loss: 0.5807 - val_binary_accuracy: 0.7222\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.1667 - binary_accuracy: 0.9383 - val_loss: 0.6099 - val_binary_accuracy: 0.7222\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.1777 - binary_accuracy: 0.9321 - val_loss: 0.5736 - val_binary_accuracy: 0.7778\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 283us/step - loss: 0.1871 - binary_accuracy: 0.9444 - val_loss: 0.5909 - val_binary_accuracy: 0.7222\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 289us/step - loss: 0.1777 - binary_accuracy: 0.9506 - val_loss: 0.6254 - val_binary_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.2159 - binary_accuracy: 0.8951 - val_loss: 0.6911 - val_binary_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.1674 - binary_accuracy: 0.9568 - val_loss: 0.7655 - val_binary_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.1770 - binary_accuracy: 0.9506 - val_loss: 0.8289 - val_binary_accuracy: 0.5556\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 284us/step - loss: 0.1586 - binary_accuracy: 0.9506 - val_loss: 0.9487 - val_binary_accuracy: 0.5556\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.1353 - binary_accuracy: 0.9691 - val_loss: 1.0388 - val_binary_accuracy: 0.5556\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.2038 - binary_accuracy: 0.9074 - val_loss: 1.2191 - val_binary_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.2545 - binary_accuracy: 0.9074 - val_loss: 1.1829 - val_binary_accuracy: 0.5556\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.1512 - binary_accuracy: 0.9568 - val_loss: 1.0799 - val_binary_accuracy: 0.5556\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 262us/step - loss: 0.2120 - binary_accuracy: 0.9012 - val_loss: 0.9545 - val_binary_accuracy: 0.6111\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.1967 - binary_accuracy: 0.9198 - val_loss: 0.8693 - val_binary_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2009 - binary_accuracy: 0.9383 - val_loss: 0.9442 - val_binary_accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.1468 - binary_accuracy: 0.9444 - val_loss: 0.9756 - val_binary_accuracy: 0.6111\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.1786 - binary_accuracy: 0.9198 - val_loss: 0.9543 - val_binary_accuracy: 0.5556\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.2208 - binary_accuracy: 0.9321 - val_loss: 0.9654 - val_binary_accuracy: 0.6111\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 265us/step - loss: 0.1694 - binary_accuracy: 0.9691 - val_loss: 0.8987 - val_binary_accuracy: 0.6111\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.2182 - binary_accuracy: 0.9321 - val_loss: 0.8890 - val_binary_accuracy: 0.5556\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.1896 - binary_accuracy: 0.9630 - val_loss: 0.9336 - val_binary_accuracy: 0.5556\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.1468 - binary_accuracy: 0.9630 - val_loss: 0.9653 - val_binary_accuracy: 0.5556\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.2111 - binary_accuracy: 0.9321 - val_loss: 0.9720 - val_binary_accuracy: 0.5556\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.1620 - binary_accuracy: 0.9630 - val_loss: 0.9550 - val_binary_accuracy: 0.6111\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.1750 - binary_accuracy: 0.9383 - val_loss: 0.9545 - val_binary_accuracy: 0.5556\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 225us/step - loss: 0.1744 - binary_accuracy: 0.9506 - val_loss: 0.9304 - val_binary_accuracy: 0.5556\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.1848 - binary_accuracy: 0.9568 - val_loss: 0.9227 - val_binary_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.2146 - binary_accuracy: 0.9198 - val_loss: 0.9103 - val_binary_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.1618 - binary_accuracy: 0.9568 - val_loss: 0.8778 - val_binary_accuracy: 0.5556\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.1669 - binary_accuracy: 0.9506 - val_loss: 0.8656 - val_binary_accuracy: 0.5556\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.2022 - binary_accuracy: 0.9444 - val_loss: 0.8898 - val_binary_accuracy: 0.6111\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.1355 - binary_accuracy: 0.9506 - val_loss: 0.9083 - val_binary_accuracy: 0.5556\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 275us/step - loss: 0.1292 - binary_accuracy: 0.9630 - val_loss: 0.9351 - val_binary_accuracy: 0.5556\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.1179 - binary_accuracy: 0.9691 - val_loss: 0.9775 - val_binary_accuracy: 0.5556\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.0979 - binary_accuracy: 0.9815 - val_loss: 0.9876 - val_binary_accuracy: 0.5556\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 274us/step - loss: 0.1044 - binary_accuracy: 0.9753 - val_loss: 1.0192 - val_binary_accuracy: 0.5556\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.1350 - binary_accuracy: 0.9506 - val_loss: 1.0696 - val_binary_accuracy: 0.5556\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1413 - binary_accuracy: 0.9568 - val_loss: 1.0779 - val_binary_accuracy: 0.5556\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1418 - binary_accuracy: 0.9753 - val_loss: 0.9950 - val_binary_accuracy: 0.6667\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.1203 - binary_accuracy: 0.9506 - val_loss: 0.7708 - val_binary_accuracy: 0.7778\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 300us/step - loss: 0.1773 - binary_accuracy: 0.9259 - val_loss: 0.6983 - val_binary_accuracy: 0.7222\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 266us/step - loss: 0.1663 - binary_accuracy: 0.9444 - val_loss: 0.6999 - val_binary_accuracy: 0.6667\n",
      "18/18 [==============================] - 0s 110us/step\n",
      "\n",
      "Fold  9\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.7683 - binary_accuracy: 0.6049 - val_loss: 0.8823 - val_binary_accuracy: 0.7778\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 305us/step - loss: 0.5014 - binary_accuracy: 0.7037 - val_loss: 0.8657 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 276us/step - loss: 0.4743 - binary_accuracy: 0.7716 - val_loss: 0.8070 - val_binary_accuracy: 0.7778\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 286us/step - loss: 0.4568 - binary_accuracy: 0.7901 - val_loss: 0.7552 - val_binary_accuracy: 0.7778\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 329us/step - loss: 0.4370 - binary_accuracy: 0.7840 - val_loss: 0.8435 - val_binary_accuracy: 0.7778\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 312us/step - loss: 0.4179 - binary_accuracy: 0.8210 - val_loss: 0.8980 - val_binary_accuracy: 0.7222\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 290us/step - loss: 0.3491 - binary_accuracy: 0.8210 - val_loss: 0.8694 - val_binary_accuracy: 0.7222\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 279us/step - loss: 0.3627 - binary_accuracy: 0.8457 - val_loss: 0.8240 - val_binary_accuracy: 0.7222\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.3480 - binary_accuracy: 0.8704 - val_loss: 0.7591 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.3759 - binary_accuracy: 0.8827 - val_loss: 0.7448 - val_binary_accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 272us/step - loss: 0.3311 - binary_accuracy: 0.8642 - val_loss: 0.7658 - val_binary_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 281us/step - loss: 0.3202 - binary_accuracy: 0.8951 - val_loss: 0.8543 - val_binary_accuracy: 0.7222\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.3575 - binary_accuracy: 0.8704 - val_loss: 0.8155 - val_binary_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.3411 - binary_accuracy: 0.8704 - val_loss: 0.8052 - val_binary_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.3137 - binary_accuracy: 0.8827 - val_loss: 0.7593 - val_binary_accuracy: 0.7222\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2854 - binary_accuracy: 0.8951 - val_loss: 0.7448 - val_binary_accuracy: 0.7222\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.2796 - binary_accuracy: 0.8951 - val_loss: 0.7904 - val_binary_accuracy: 0.7222\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.2321 - binary_accuracy: 0.9074 - val_loss: 0.8667 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.3325 - binary_accuracy: 0.8580 - val_loss: 0.8985 - val_binary_accuracy: 0.7222\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.3031 - binary_accuracy: 0.8642 - val_loss: 0.9326 - val_binary_accuracy: 0.7222\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.3073 - binary_accuracy: 0.8889 - val_loss: 0.9543 - val_binary_accuracy: 0.7222\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2492 - binary_accuracy: 0.9136 - val_loss: 0.8840 - val_binary_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2571 - binary_accuracy: 0.8951 - val_loss: 0.7804 - val_binary_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.3181 - binary_accuracy: 0.8580 - val_loss: 0.7492 - val_binary_accuracy: 0.7222\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.2670 - binary_accuracy: 0.9012 - val_loss: 0.7404 - val_binary_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.2778 - binary_accuracy: 0.8827 - val_loss: 0.8007 - val_binary_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.2727 - binary_accuracy: 0.8889 - val_loss: 0.9129 - val_binary_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2444 - binary_accuracy: 0.8889 - val_loss: 1.0015 - val_binary_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.2773 - binary_accuracy: 0.8765 - val_loss: 1.0654 - val_binary_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.2675 - binary_accuracy: 0.9198 - val_loss: 1.0759 - val_binary_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.2504 - binary_accuracy: 0.8827 - val_loss: 1.0883 - val_binary_accuracy: 0.7222\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 260us/step - loss: 0.3251 - binary_accuracy: 0.8395 - val_loss: 1.0831 - val_binary_accuracy: 0.7222\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.2562 - binary_accuracy: 0.8951 - val_loss: 1.0200 - val_binary_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 230us/step - loss: 0.2219 - binary_accuracy: 0.9198 - val_loss: 0.9952 - val_binary_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.2163 - binary_accuracy: 0.9321 - val_loss: 1.0130 - val_binary_accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.2330 - binary_accuracy: 0.9259 - val_loss: 1.0893 - val_binary_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 271us/step - loss: 0.1879 - binary_accuracy: 0.9198 - val_loss: 1.1159 - val_binary_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 268us/step - loss: 0.2347 - binary_accuracy: 0.9012 - val_loss: 1.1025 - val_binary_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.2226 - binary_accuracy: 0.9259 - val_loss: 1.0579 - val_binary_accuracy: 0.6111\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.1970 - binary_accuracy: 0.9136 - val_loss: 1.0047 - val_binary_accuracy: 0.6111\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 221us/step - loss: 0.2039 - binary_accuracy: 0.9383 - val_loss: 0.9667 - val_binary_accuracy: 0.6111\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.1949 - binary_accuracy: 0.9383 - val_loss: 0.9747 - val_binary_accuracy: 0.6111\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 254us/step - loss: 0.1901 - binary_accuracy: 0.9259 - val_loss: 0.9563 - val_binary_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.2153 - binary_accuracy: 0.9198 - val_loss: 1.0378 - val_binary_accuracy: 0.6111\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.2196 - binary_accuracy: 0.9136 - val_loss: 1.1180 - val_binary_accuracy: 0.6111\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.1796 - binary_accuracy: 0.9444 - val_loss: 1.1581 - val_binary_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.2539 - binary_accuracy: 0.8951 - val_loss: 1.0724 - val_binary_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2586 - binary_accuracy: 0.9012 - val_loss: 1.0634 - val_binary_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2466 - binary_accuracy: 0.8889 - val_loss: 0.9734 - val_binary_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.2356 - binary_accuracy: 0.9074 - val_loss: 0.9431 - val_binary_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.2393 - binary_accuracy: 0.9074 - val_loss: 1.0756 - val_binary_accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 264us/step - loss: 0.2665 - binary_accuracy: 0.9012 - val_loss: 1.1547 - val_binary_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 269us/step - loss: 0.2820 - binary_accuracy: 0.8704 - val_loss: 1.1798 - val_binary_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.2016 - binary_accuracy: 0.9383 - val_loss: 1.1425 - val_binary_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.2089 - binary_accuracy: 0.9321 - val_loss: 1.1540 - val_binary_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 230us/step - loss: 0.2091 - binary_accuracy: 0.9321 - val_loss: 1.1687 - val_binary_accuracy: 0.6111\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.2132 - binary_accuracy: 0.8889 - val_loss: 1.1788 - val_binary_accuracy: 0.6111\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 256us/step - loss: 0.1990 - binary_accuracy: 0.9074 - val_loss: 1.1385 - val_binary_accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2377 - binary_accuracy: 0.9074 - val_loss: 1.1764 - val_binary_accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 241us/step - loss: 0.1909 - binary_accuracy: 0.9321 - val_loss: 1.2032 - val_binary_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 273us/step - loss: 0.1575 - binary_accuracy: 0.9568 - val_loss: 1.2103 - val_binary_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.1594 - binary_accuracy: 0.9383 - val_loss: 1.2234 - val_binary_accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1928 - binary_accuracy: 0.9321 - val_loss: 1.2744 - val_binary_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.1993 - binary_accuracy: 0.9259 - val_loss: 1.3546 - val_binary_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1425 - binary_accuracy: 0.9444 - val_loss: 1.3361 - val_binary_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.1839 - binary_accuracy: 0.9444 - val_loss: 1.2791 - val_binary_accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.1990 - binary_accuracy: 0.9506 - val_loss: 1.2041 - val_binary_accuracy: 0.5556\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.2309 - binary_accuracy: 0.8951 - val_loss: 1.1506 - val_binary_accuracy: 0.6111\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 247us/step - loss: 0.1028 - binary_accuracy: 0.9691 - val_loss: 1.1680 - val_binary_accuracy: 0.6111\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 233us/step - loss: 0.1469 - binary_accuracy: 0.9568 - val_loss: 1.1841 - val_binary_accuracy: 0.6111\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.1554 - binary_accuracy: 0.9630 - val_loss: 1.1760 - val_binary_accuracy: 0.6111\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.1857 - binary_accuracy: 0.9321 - val_loss: 1.1371 - val_binary_accuracy: 0.6111\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.1764 - binary_accuracy: 0.9383 - val_loss: 1.0971 - val_binary_accuracy: 0.6111\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 247us/step - loss: 0.1687 - binary_accuracy: 0.9321 - val_loss: 1.0687 - val_binary_accuracy: 0.6111\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.1480 - binary_accuracy: 0.9568 - val_loss: 1.0383 - val_binary_accuracy: 0.5556\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 230us/step - loss: 0.1493 - binary_accuracy: 0.9506 - val_loss: 1.0431 - val_binary_accuracy: 0.6111\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 305us/step - loss: 0.1632 - binary_accuracy: 0.9506 - val_loss: 1.0612 - val_binary_accuracy: 0.5556\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.1403 - binary_accuracy: 0.9691 - val_loss: 1.0455 - val_binary_accuracy: 0.5556\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.1409 - binary_accuracy: 0.9630 - val_loss: 1.0338 - val_binary_accuracy: 0.6111\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.1331 - binary_accuracy: 0.9630 - val_loss: 1.0608 - val_binary_accuracy: 0.6111\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 224us/step - loss: 0.1622 - binary_accuracy: 0.9321 - val_loss: 1.0923 - val_binary_accuracy: 0.5556\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 213us/step - loss: 0.1630 - binary_accuracy: 0.9753 - val_loss: 1.1106 - val_binary_accuracy: 0.5556\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 224us/step - loss: 0.1124 - binary_accuracy: 0.9691 - val_loss: 1.0856 - val_binary_accuracy: 0.5556\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.1637 - binary_accuracy: 0.9383 - val_loss: 1.0570 - val_binary_accuracy: 0.6111\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 247us/step - loss: 0.1868 - binary_accuracy: 0.9321 - val_loss: 1.0718 - val_binary_accuracy: 0.6111\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.1905 - binary_accuracy: 0.9383 - val_loss: 1.1020 - val_binary_accuracy: 0.5556\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 219us/step - loss: 0.2143 - binary_accuracy: 0.9321 - val_loss: 1.1327 - val_binary_accuracy: 0.5556\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 210us/step - loss: 0.2388 - binary_accuracy: 0.9136 - val_loss: 0.9840 - val_binary_accuracy: 0.5556\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.2735 - binary_accuracy: 0.8889 - val_loss: 0.9503 - val_binary_accuracy: 0.5556\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.2202 - binary_accuracy: 0.9136 - val_loss: 0.9503 - val_binary_accuracy: 0.5556\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.2691 - binary_accuracy: 0.8827 - val_loss: 0.8706 - val_binary_accuracy: 0.5556\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 225us/step - loss: 0.3220 - binary_accuracy: 0.8519 - val_loss: 0.9419 - val_binary_accuracy: 0.6111\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 230us/step - loss: 0.3133 - binary_accuracy: 0.8827 - val_loss: 1.0521 - val_binary_accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.3092 - binary_accuracy: 0.8580 - val_loss: 1.1159 - val_binary_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.2681 - binary_accuracy: 0.8704 - val_loss: 1.1356 - val_binary_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.3213 - binary_accuracy: 0.8889 - val_loss: 1.0938 - val_binary_accuracy: 0.6111\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 217us/step - loss: 0.2656 - binary_accuracy: 0.9012 - val_loss: 1.0578 - val_binary_accuracy: 0.6111\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.2653 - binary_accuracy: 0.9012 - val_loss: 1.0526 - val_binary_accuracy: 0.6111\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.2342 - binary_accuracy: 0.9259 - val_loss: 1.0566 - val_binary_accuracy: 0.6111\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 236us/step - loss: 0.2613 - binary_accuracy: 0.8889 - val_loss: 1.0843 - val_binary_accuracy: 0.5556\n",
      "18/18 [==============================] - 0s 144us/step\n",
      "\n",
      "Fold  10\n",
      "Train on 162 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.6659 - binary_accuracy: 0.6543 - val_loss: 0.6712 - val_binary_accuracy: 0.5556\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.5089 - binary_accuracy: 0.7531 - val_loss: 0.6682 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 0s 252us/step - loss: 0.5054 - binary_accuracy: 0.7469 - val_loss: 0.7658 - val_binary_accuracy: 0.6111\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 0s 267us/step - loss: 0.4994 - binary_accuracy: 0.7531 - val_loss: 0.7398 - val_binary_accuracy: 0.6111\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.4629 - binary_accuracy: 0.7840 - val_loss: 0.6466 - val_binary_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.4542 - binary_accuracy: 0.7963 - val_loss: 0.5872 - val_binary_accuracy: 0.6111\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.4392 - binary_accuracy: 0.8086 - val_loss: 0.6204 - val_binary_accuracy: 0.6111\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.4248 - binary_accuracy: 0.8086 - val_loss: 0.6415 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.3837 - binary_accuracy: 0.8333 - val_loss: 0.6726 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 0s 236us/step - loss: 0.3822 - binary_accuracy: 0.8272 - val_loss: 0.6682 - val_binary_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.3972 - binary_accuracy: 0.8210 - val_loss: 0.5714 - val_binary_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 0s 236us/step - loss: 0.3420 - binary_accuracy: 0.8704 - val_loss: 0.6483 - val_binary_accuracy: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.3467 - binary_accuracy: 0.8333 - val_loss: 0.6869 - val_binary_accuracy: 0.7222\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.3890 - binary_accuracy: 0.8210 - val_loss: 0.6965 - val_binary_accuracy: 0.7222\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.3223 - binary_accuracy: 0.8642 - val_loss: 0.6952 - val_binary_accuracy: 0.7222\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 0s 261us/step - loss: 0.3153 - binary_accuracy: 0.8951 - val_loss: 0.6286 - val_binary_accuracy: 0.7778\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.2944 - binary_accuracy: 0.8951 - val_loss: 0.6249 - val_binary_accuracy: 0.7778\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.2933 - binary_accuracy: 0.8765 - val_loss: 0.6376 - val_binary_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2747 - binary_accuracy: 0.8951 - val_loss: 0.6808 - val_binary_accuracy: 0.7222\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 0s 253us/step - loss: 0.2320 - binary_accuracy: 0.9136 - val_loss: 0.7204 - val_binary_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "162/162 [==============================] - 0s 249us/step - loss: 0.2861 - binary_accuracy: 0.8827 - val_loss: 0.7040 - val_binary_accuracy: 0.7222\n",
      "Epoch 22/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.2473 - binary_accuracy: 0.9074 - val_loss: 0.7243 - val_binary_accuracy: 0.7778\n",
      "Epoch 23/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.2773 - binary_accuracy: 0.8642 - val_loss: 0.7758 - val_binary_accuracy: 0.7778\n",
      "Epoch 24/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2670 - binary_accuracy: 0.8765 - val_loss: 0.7445 - val_binary_accuracy: 0.7222\n",
      "Epoch 25/100\n",
      "162/162 [==============================] - 0s 255us/step - loss: 0.2709 - binary_accuracy: 0.8889 - val_loss: 0.7634 - val_binary_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.2726 - binary_accuracy: 0.8765 - val_loss: 0.8232 - val_binary_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.2047 - binary_accuracy: 0.9321 - val_loss: 0.8545 - val_binary_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.2362 - binary_accuracy: 0.9012 - val_loss: 0.8301 - val_binary_accuracy: 0.7222\n",
      "Epoch 29/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.2835 - binary_accuracy: 0.8889 - val_loss: 0.8919 - val_binary_accuracy: 0.7222\n",
      "Epoch 30/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.2391 - binary_accuracy: 0.8889 - val_loss: 0.8057 - val_binary_accuracy: 0.7222\n",
      "Epoch 31/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.2100 - binary_accuracy: 0.9321 - val_loss: 0.7000 - val_binary_accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "162/162 [==============================] - 0s 234us/step - loss: 0.2684 - binary_accuracy: 0.8889 - val_loss: 0.6954 - val_binary_accuracy: 0.7222\n",
      "Epoch 33/100\n",
      "162/162 [==============================] - 0s 224us/step - loss: 0.2438 - binary_accuracy: 0.8889 - val_loss: 0.7249 - val_binary_accuracy: 0.7222\n",
      "Epoch 34/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.2219 - binary_accuracy: 0.9012 - val_loss: 0.7489 - val_binary_accuracy: 0.7222\n",
      "Epoch 35/100\n",
      "162/162 [==============================] - 0s 251us/step - loss: 0.1948 - binary_accuracy: 0.9198 - val_loss: 0.7977 - val_binary_accuracy: 0.7222\n",
      "Epoch 36/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.2043 - binary_accuracy: 0.9198 - val_loss: 0.7676 - val_binary_accuracy: 0.7222\n",
      "Epoch 37/100\n",
      "162/162 [==============================] - 0s 259us/step - loss: 0.1938 - binary_accuracy: 0.9321 - val_loss: 0.7219 - val_binary_accuracy: 0.7222\n",
      "Epoch 38/100\n",
      "162/162 [==============================] - 0s 222us/step - loss: 0.2141 - binary_accuracy: 0.9259 - val_loss: 0.7097 - val_binary_accuracy: 0.7222\n",
      "Epoch 39/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.2223 - binary_accuracy: 0.9136 - val_loss: 0.6983 - val_binary_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "162/162 [==============================] - 0s 257us/step - loss: 0.2180 - binary_accuracy: 0.9198 - val_loss: 0.6062 - val_binary_accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "162/162 [==============================] - 0s 263us/step - loss: 0.3196 - binary_accuracy: 0.8765 - val_loss: 0.6445 - val_binary_accuracy: 0.7222\n",
      "Epoch 42/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2724 - binary_accuracy: 0.8951 - val_loss: 0.7208 - val_binary_accuracy: 0.6111\n",
      "Epoch 43/100\n",
      "162/162 [==============================] - 0s 246us/step - loss: 0.2648 - binary_accuracy: 0.9012 - val_loss: 0.7632 - val_binary_accuracy: 0.6111\n",
      "Epoch 44/100\n",
      "162/162 [==============================] - 0s 220us/step - loss: 0.2611 - binary_accuracy: 0.9074 - val_loss: 0.7013 - val_binary_accuracy: 0.7222\n",
      "Epoch 45/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.2641 - binary_accuracy: 0.9074 - val_loss: 0.6953 - val_binary_accuracy: 0.7222\n",
      "Epoch 46/100\n",
      "162/162 [==============================] - 0s 219us/step - loss: 0.2721 - binary_accuracy: 0.9012 - val_loss: 0.6931 - val_binary_accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "162/162 [==============================] - 0s 258us/step - loss: 0.2017 - binary_accuracy: 0.9321 - val_loss: 0.6942 - val_binary_accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.2338 - binary_accuracy: 0.9198 - val_loss: 0.6853 - val_binary_accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.1983 - binary_accuracy: 0.9383 - val_loss: 0.6791 - val_binary_accuracy: 0.7222\n",
      "Epoch 50/100\n",
      "162/162 [==============================] - 0s 225us/step - loss: 0.2228 - binary_accuracy: 0.9012 - val_loss: 0.7345 - val_binary_accuracy: 0.7222\n",
      "Epoch 51/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.2576 - binary_accuracy: 0.8951 - val_loss: 0.7778 - val_binary_accuracy: 0.7222\n",
      "Epoch 52/100\n",
      "162/162 [==============================] - 0s 247us/step - loss: 0.1993 - binary_accuracy: 0.9136 - val_loss: 0.8554 - val_binary_accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "162/162 [==============================] - 0s 224us/step - loss: 0.2291 - binary_accuracy: 0.9198 - val_loss: 0.8941 - val_binary_accuracy: 0.6111\n",
      "Epoch 54/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.2467 - binary_accuracy: 0.8951 - val_loss: 0.8690 - val_binary_accuracy: 0.6111\n",
      "Epoch 55/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1948 - binary_accuracy: 0.9321 - val_loss: 0.7957 - val_binary_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "162/162 [==============================] - 0s 250us/step - loss: 0.1970 - binary_accuracy: 0.9444 - val_loss: 0.7647 - val_binary_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "162/162 [==============================] - 0s 237us/step - loss: 0.1805 - binary_accuracy: 0.9444 - val_loss: 0.7780 - val_binary_accuracy: 0.7222\n",
      "Epoch 58/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.1896 - binary_accuracy: 0.9321 - val_loss: 0.9001 - val_binary_accuracy: 0.6111\n",
      "Epoch 59/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.1989 - binary_accuracy: 0.9383 - val_loss: 1.0962 - val_binary_accuracy: 0.6111\n",
      "Epoch 60/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.2177 - binary_accuracy: 0.9259 - val_loss: 1.1029 - val_binary_accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1996 - binary_accuracy: 0.9383 - val_loss: 1.0445 - val_binary_accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.2197 - binary_accuracy: 0.9259 - val_loss: 1.0016 - val_binary_accuracy: 0.6111\n",
      "Epoch 63/100\n",
      "162/162 [==============================] - 0s 220us/step - loss: 0.1697 - binary_accuracy: 0.9506 - val_loss: 0.9748 - val_binary_accuracy: 0.6111\n",
      "Epoch 64/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.2011 - binary_accuracy: 0.9321 - val_loss: 1.0096 - val_binary_accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "162/162 [==============================] - 0s 235us/step - loss: 0.1912 - binary_accuracy: 0.9259 - val_loss: 1.0609 - val_binary_accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.2184 - binary_accuracy: 0.8827 - val_loss: 1.0796 - val_binary_accuracy: 0.6111\n",
      "Epoch 67/100\n",
      "162/162 [==============================] - 0s 225us/step - loss: 0.1932 - binary_accuracy: 0.9444 - val_loss: 1.0282 - val_binary_accuracy: 0.6111\n",
      "Epoch 68/100\n",
      "162/162 [==============================] - 0s 220us/step - loss: 0.2015 - binary_accuracy: 0.9136 - val_loss: 0.9241 - val_binary_accuracy: 0.6111\n",
      "Epoch 69/100\n",
      "162/162 [==============================] - 0s 217us/step - loss: 0.1958 - binary_accuracy: 0.9198 - val_loss: 0.9208 - val_binary_accuracy: 0.6111\n",
      "Epoch 70/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.1463 - binary_accuracy: 0.9630 - val_loss: 0.9900 - val_binary_accuracy: 0.6111\n",
      "Epoch 71/100\n",
      "162/162 [==============================] - 0s 239us/step - loss: 0.1670 - binary_accuracy: 0.9568 - val_loss: 0.9508 - val_binary_accuracy: 0.6111\n",
      "Epoch 72/100\n",
      "162/162 [==============================] - 0s 225us/step - loss: 0.1801 - binary_accuracy: 0.9444 - val_loss: 0.9290 - val_binary_accuracy: 0.6111\n",
      "Epoch 73/100\n",
      "162/162 [==============================] - 0s 247us/step - loss: 0.1385 - binary_accuracy: 0.9630 - val_loss: 0.9228 - val_binary_accuracy: 0.6111\n",
      "Epoch 74/100\n",
      "162/162 [==============================] - 0s 222us/step - loss: 0.2124 - binary_accuracy: 0.9259 - val_loss: 0.9329 - val_binary_accuracy: 0.6111\n",
      "Epoch 75/100\n",
      "162/162 [==============================] - 0s 244us/step - loss: 0.1546 - binary_accuracy: 0.9568 - val_loss: 0.9216 - val_binary_accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.1583 - binary_accuracy: 0.9444 - val_loss: 0.9241 - val_binary_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.1472 - binary_accuracy: 0.9383 - val_loss: 0.9377 - val_binary_accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.1599 - binary_accuracy: 0.9321 - val_loss: 0.9086 - val_binary_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.2035 - binary_accuracy: 0.9198 - val_loss: 0.8801 - val_binary_accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.1637 - binary_accuracy: 0.9321 - val_loss: 0.8832 - val_binary_accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "162/162 [==============================] - 0s 213us/step - loss: 0.1161 - binary_accuracy: 0.9753 - val_loss: 0.9098 - val_binary_accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "162/162 [==============================] - 0s 227us/step - loss: 0.1355 - binary_accuracy: 0.9321 - val_loss: 0.9410 - val_binary_accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "162/162 [==============================] - 0s 245us/step - loss: 0.1294 - binary_accuracy: 0.9753 - val_loss: 0.9765 - val_binary_accuracy: 0.6667\n",
      "Epoch 84/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.1744 - binary_accuracy: 0.9444 - val_loss: 1.0529 - val_binary_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "162/162 [==============================] - 0s 225us/step - loss: 0.1319 - binary_accuracy: 0.9630 - val_loss: 0.9674 - val_binary_accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "162/162 [==============================] - 0s 223us/step - loss: 0.1658 - binary_accuracy: 0.9321 - val_loss: 0.9320 - val_binary_accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "162/162 [==============================] - 0s 240us/step - loss: 0.1814 - binary_accuracy: 0.9444 - val_loss: 0.9572 - val_binary_accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.1881 - binary_accuracy: 0.9383 - val_loss: 1.0475 - val_binary_accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "162/162 [==============================] - 0s 238us/step - loss: 0.1802 - binary_accuracy: 0.9444 - val_loss: 1.2594 - val_binary_accuracy: 0.5556\n",
      "Epoch 90/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.2014 - binary_accuracy: 0.9321 - val_loss: 1.2873 - val_binary_accuracy: 0.5556\n",
      "Epoch 91/100\n",
      "162/162 [==============================] - 0s 243us/step - loss: 0.1558 - binary_accuracy: 0.9568 - val_loss: 1.1103 - val_binary_accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "162/162 [==============================] - 0s 230us/step - loss: 0.1690 - binary_accuracy: 0.9444 - val_loss: 1.0070 - val_binary_accuracy: 0.6667\n",
      "Epoch 93/100\n",
      "162/162 [==============================] - 0s 231us/step - loss: 0.1642 - binary_accuracy: 0.9506 - val_loss: 0.9935 - val_binary_accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "162/162 [==============================] - 0s 242us/step - loss: 0.1485 - binary_accuracy: 0.9568 - val_loss: 1.0539 - val_binary_accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.1848 - binary_accuracy: 0.9259 - val_loss: 1.0729 - val_binary_accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "162/162 [==============================] - 0s 228us/step - loss: 0.2201 - binary_accuracy: 0.9321 - val_loss: 1.0605 - val_binary_accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "162/162 [==============================] - 0s 229us/step - loss: 0.1173 - binary_accuracy: 0.9815 - val_loss: 1.0917 - val_binary_accuracy: 0.6667\n",
      "Epoch 98/100\n",
      "162/162 [==============================] - 0s 226us/step - loss: 0.1917 - binary_accuracy: 0.9074 - val_loss: 1.0732 - val_binary_accuracy: 0.6667\n",
      "Epoch 99/100\n",
      "162/162 [==============================] - 0s 248us/step - loss: 0.1487 - binary_accuracy: 0.9506 - val_loss: 1.0159 - val_binary_accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "162/162 [==============================] - 0s 232us/step - loss: 0.1656 - binary_accuracy: 0.9383 - val_loss: 1.0212 - val_binary_accuracy: 0.6667\n",
      "18/18 [==============================] - 0s 116us/step\n",
      "Mean loss: 0.7511240899562835\n",
      "Mean acc: 0.7333333373069764\n",
      "Mean pred: [0.44749301 0.02873544 0.94716402 0.14728832 0.9312057  0.03530263\n",
      " 0.11855103 0.96933662 0.27338877 0.14890229 0.17381632 0.9617355\n",
      " 0.24012525 0.60023575 0.01743642 0.03851529 0.11335722 0.01035033\n",
      " 0.96730279 0.05558803 0.97510791 0.05059483 0.12190891 0.00781997\n",
      " 0.61401353 0.94143249 0.66542074 0.50357822 0.83178782 0.0431465\n",
      " 0.93062535 0.42237989 0.68819303 0.24876907 0.21472925 0.06148937\n",
      " 0.18699786 0.2021371  0.21220029 0.17173642 0.945742   0.15700178\n",
      " 0.95470856 0.12862069 0.85707183 0.03764187 0.04104702 0.28247066\n",
      " 0.0798364  0.77399609 0.51860597 0.13426324 0.83686784 0.01295162\n",
      " 0.31639114 0.06027819 0.93954394 0.22271694 0.22201092 0.54712744\n",
      " 0.10967058 0.9224564  0.173586   0.9226244  0.02559233 0.72973846\n",
      " 0.81932158 0.375027   0.89800612 0.48404212 0.04634568 0.97001688\n",
      " 0.96317998 0.97928879 0.9696047  0.9726397  0.78874169 0.87527497\n",
      " 0.46163859 0.50596073 0.36922845 0.17939184 0.26997775 0.74763976\n",
      " 0.18359015 0.23832465 0.86252152 0.26787373 0.05936074 0.02547301]\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "K = 10\n",
    "loss_list=[]\n",
    "acc_list=[]\n",
    "pred_list = np.zeros((np.shape(x_test)[0],K))\n",
    "\n",
    "x_test_f = preproc_input(x_test)\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = K, \n",
    "                            random_state = 1, \n",
    "                            shuffle = True)  \n",
    "for i, (train_idxs, val_indxs) in enumerate(kfold.split(x_train.values, y_train.values)):\n",
    "    print('\\nFold ', i + 1)\n",
    "    x_train_f = x_train.loc[train_idxs]\n",
    "    y_train_f = y_train.loc[train_idxs]\n",
    "\n",
    "    x_val_f = x_train.loc[val_indxs]\n",
    "    y_val_f = y_train.loc[val_indxs]\n",
    "    \n",
    "    \n",
    "    x_train_f = preproc_input(x_train_f)\n",
    "    x_val_f = preproc_input(x_val_f)\n",
    "    \n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        x_train_f,\n",
    "        y_train_f.values,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_val_f, y_val_f),\n",
    "        verbose=1,\n",
    "    )\n",
    "    model_eval = model.evaluate(x_val_f, y_val_f)\n",
    "    loss_list.append(model_eval[0])\n",
    "    acc_list.append(model_eval[1])\n",
    "    pred_list[:, i] += model.predict(x_test_f)[:,0]\n",
    "    \n",
    "mean_loss = np.mean(loss_list)\n",
    "mean_acc = np.mean(acc_list)\n",
    "mean_pred = np.mean(pred_list, axis = 1)\n",
    "print(\"Mean loss: {}\".format(mean_loss))\n",
    "print(\"Mean acc: {}\".format(mean_acc))\n",
    "print(\"Mean pred: {}\".format(mean_pred))\n",
    "\n",
    "## Save model and weights\n",
    "# save_dir=os.path.join(os.getcwd(), 'saved_models')\n",
    "# model_name= '{}.h5'.format(exp_stamp)\n",
    "# if not os.path.isdir(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "# model_path = os.path.join(save_dir, model_name)\n",
    "# model.save(model_path)\n",
    "# print('Saved  trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>heart_disease_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>olalu7</td>\n",
       "      <td>0.447493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z9n6mx</td>\n",
       "      <td>0.028735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5k4413</td>\n",
       "      <td>0.947164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrg7q5</td>\n",
       "      <td>0.147288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uki4do</td>\n",
       "      <td>0.931206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kev1sk</td>\n",
       "      <td>0.035303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9n6let</td>\n",
       "      <td>0.118551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jxmtyg</td>\n",
       "      <td>0.969337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>51s2ff</td>\n",
       "      <td>0.273389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wi9mcs</td>\n",
       "      <td>0.148902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>741h4l</td>\n",
       "      <td>0.173816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1ef64a</td>\n",
       "      <td>0.961736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wa2ix6</td>\n",
       "      <td>0.240125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8167zl</td>\n",
       "      <td>0.600236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n6nldr</td>\n",
       "      <td>0.017436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ph85fp</td>\n",
       "      <td>0.038515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jfan5p</td>\n",
       "      <td>0.113357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7c4iz1</td>\n",
       "      <td>0.010350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ukigml</td>\n",
       "      <td>0.967303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flwvnq</td>\n",
       "      <td>0.055588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5i4fw2</td>\n",
       "      <td>0.975108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>du1pqf</td>\n",
       "      <td>0.050595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vs68qz</td>\n",
       "      <td>0.121909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pfyez0</td>\n",
       "      <td>0.007820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>azvkw2</td>\n",
       "      <td>0.614014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cird1i</td>\n",
       "      <td>0.941432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3bg32t</td>\n",
       "      <td>0.665421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xzd050</td>\n",
       "      <td>0.503578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>eyi8et</td>\n",
       "      <td>0.831788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ce4x2h</td>\n",
       "      <td>0.043146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sm91nr</td>\n",
       "      <td>0.930625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2il8hh</td>\n",
       "      <td>0.422380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>yq9cqg</td>\n",
       "      <td>0.688193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>520v5j</td>\n",
       "      <td>0.248769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ammgu2</td>\n",
       "      <td>0.214729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>jix8hj</td>\n",
       "      <td>0.061489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lj5zrq</td>\n",
       "      <td>0.186998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16ceba</td>\n",
       "      <td>0.202137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>93w44s</td>\n",
       "      <td>0.212200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bso17z</td>\n",
       "      <td>0.171736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>j2w2dc</td>\n",
       "      <td>0.945742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>74vwwl</td>\n",
       "      <td>0.157002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0z3fob</td>\n",
       "      <td>0.954709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>mr7zyz</td>\n",
       "      <td>0.128621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pp5n63</td>\n",
       "      <td>0.857072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>j0hix1</td>\n",
       "      <td>0.037642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>rn209i</td>\n",
       "      <td>0.041047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>nfit8e</td>\n",
       "      <td>0.282471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>nb73sy</td>\n",
       "      <td>0.079836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>i79t3w</td>\n",
       "      <td>0.773996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>9nv2d9</td>\n",
       "      <td>0.518606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2xbeja</td>\n",
       "      <td>0.134263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>lwg3wq</td>\n",
       "      <td>0.836868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>lrvqwb</td>\n",
       "      <td>0.012952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>c6mepo</td>\n",
       "      <td>0.316391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6ued22</td>\n",
       "      <td>0.060278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>112e9h</td>\n",
       "      <td>0.939544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>8jc7h2</td>\n",
       "      <td>0.222717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>unykmj</td>\n",
       "      <td>0.222011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4yeztb</td>\n",
       "      <td>0.547127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>tgpy9u</td>\n",
       "      <td>0.109671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>pf5wp6</td>\n",
       "      <td>0.922456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>cj8vj2</td>\n",
       "      <td>0.173586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9w6d9j</td>\n",
       "      <td>0.922624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3l89wd</td>\n",
       "      <td>0.025592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>83a6x1</td>\n",
       "      <td>0.729738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>oua0gr</td>\n",
       "      <td>0.819322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>j0hl96</td>\n",
       "      <td>0.375027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>dlkzyg</td>\n",
       "      <td>0.898006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>r0w4a8</td>\n",
       "      <td>0.484042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>46dlca</td>\n",
       "      <td>0.046346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9fkefu</td>\n",
       "      <td>0.970017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6uk6kl</td>\n",
       "      <td>0.963180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>c7olxr</td>\n",
       "      <td>0.979289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>iiyx0q</td>\n",
       "      <td>0.969605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>25vetx</td>\n",
       "      <td>0.972640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>073vc5</td>\n",
       "      <td>0.788742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>18abn0</td>\n",
       "      <td>0.875275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>v5fsfs</td>\n",
       "      <td>0.461639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2ekoo7</td>\n",
       "      <td>0.505961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5bbknr</td>\n",
       "      <td>0.369228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>hr6pjx</td>\n",
       "      <td>0.179392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>r4hsar</td>\n",
       "      <td>0.269978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4cezdf</td>\n",
       "      <td>0.747640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>palhcc</td>\n",
       "      <td>0.183590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>bwoyg6</td>\n",
       "      <td>0.238325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>j8i7ve</td>\n",
       "      <td>0.862522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>t2zn1n</td>\n",
       "      <td>0.267874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>oxf8kj</td>\n",
       "      <td>0.059361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>aeiv0y</td>\n",
       "      <td>0.025473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  heart_disease_present\n",
       "0      olalu7               0.447493\n",
       "1      z9n6mx               0.028735\n",
       "2      5k4413               0.947164\n",
       "3      mrg7q5               0.147288\n",
       "4      uki4do               0.931206\n",
       "5      kev1sk               0.035303\n",
       "6      9n6let               0.118551\n",
       "7      jxmtyg               0.969337\n",
       "8      51s2ff               0.273389\n",
       "9      wi9mcs               0.148902\n",
       "10     741h4l               0.173816\n",
       "11     1ef64a               0.961736\n",
       "12     wa2ix6               0.240125\n",
       "13     8167zl               0.600236\n",
       "14     n6nldr               0.017436\n",
       "15     ph85fp               0.038515\n",
       "16     jfan5p               0.113357\n",
       "17     7c4iz1               0.010350\n",
       "18     ukigml               0.967303\n",
       "19     flwvnq               0.055588\n",
       "20     5i4fw2               0.975108\n",
       "21     du1pqf               0.050595\n",
       "22     vs68qz               0.121909\n",
       "23     pfyez0               0.007820\n",
       "24     azvkw2               0.614014\n",
       "25     cird1i               0.941432\n",
       "26     3bg32t               0.665421\n",
       "27     xzd050               0.503578\n",
       "28     eyi8et               0.831788\n",
       "29     ce4x2h               0.043146\n",
       "30     sm91nr               0.930625\n",
       "31     2il8hh               0.422380\n",
       "32     yq9cqg               0.688193\n",
       "33     520v5j               0.248769\n",
       "34     ammgu2               0.214729\n",
       "35     jix8hj               0.061489\n",
       "36     lj5zrq               0.186998\n",
       "37     16ceba               0.202137\n",
       "38     93w44s               0.212200\n",
       "39     bso17z               0.171736\n",
       "40     j2w2dc               0.945742\n",
       "41     74vwwl               0.157002\n",
       "42     0z3fob               0.954709\n",
       "43     mr7zyz               0.128621\n",
       "44     pp5n63               0.857072\n",
       "45     j0hix1               0.037642\n",
       "46     rn209i               0.041047\n",
       "47     nfit8e               0.282471\n",
       "48     nb73sy               0.079836\n",
       "49     i79t3w               0.773996\n",
       "50     9nv2d9               0.518606\n",
       "51     2xbeja               0.134263\n",
       "52     lwg3wq               0.836868\n",
       "53     lrvqwb               0.012952\n",
       "54     c6mepo               0.316391\n",
       "55     6ued22               0.060278\n",
       "56     112e9h               0.939544\n",
       "57     8jc7h2               0.222717\n",
       "58     unykmj               0.222011\n",
       "59     4yeztb               0.547127\n",
       "60     tgpy9u               0.109671\n",
       "61     pf5wp6               0.922456\n",
       "62     cj8vj2               0.173586\n",
       "63     9w6d9j               0.922624\n",
       "64     3l89wd               0.025592\n",
       "65     83a6x1               0.729738\n",
       "66     oua0gr               0.819322\n",
       "67     j0hl96               0.375027\n",
       "68     dlkzyg               0.898006\n",
       "69     r0w4a8               0.484042\n",
       "70     46dlca               0.046346\n",
       "71     9fkefu               0.970017\n",
       "72     6uk6kl               0.963180\n",
       "73     c7olxr               0.979289\n",
       "74     iiyx0q               0.969605\n",
       "75     25vetx               0.972640\n",
       "76     073vc5               0.788742\n",
       "77     18abn0               0.875275\n",
       "78     v5fsfs               0.461639\n",
       "79     2ekoo7               0.505961\n",
       "80     5bbknr               0.369228\n",
       "81     hr6pjx               0.179392\n",
       "82     r4hsar               0.269978\n",
       "83     4cezdf               0.747640\n",
       "84     palhcc               0.183590\n",
       "85     bwoyg6               0.238325\n",
       "86     j8i7ve               0.862522\n",
       "87     t2zn1n               0.267874\n",
       "88     oxf8kj               0.059361\n",
       "89     aeiv0y               0.025473"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_df = pd.DataFrame({\n",
    "    'patient_id': x_test['patient_id'],\n",
    "    'heart_disease_present': mean_pred[:]\n",
    "})\n",
    "out_df = out_df[['patient_id', 'heart_disease_present']]\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(out_df)\n",
    "\n",
    "out_dir = 'output'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "out_file = out_dir + '/' + experiment_name + '-' + 'out.csv'\n",
    "out_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
